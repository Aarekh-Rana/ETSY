{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import io\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=Path(\"data/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir=data_dir /\"2024\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=target_dir/\"train\"\n",
    "test_dir=target_dir/\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filenames,columns=None):\n",
    "    \"\"\" Read parquet data from mutiple files \"\"\"\n",
    "\n",
    "    dataframes = [ \n",
    "        \n",
    "        pd.read_parquet(filenames, columns=columns)\n",
    "    ]\n",
    "    \n",
    "    return pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = ['title', 'description', 'tags','bottom_category_id','type']\n",
    "\n",
    "df_train = read_data(train_dir, columns=relevant_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229624"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bottom_category_id\n",
       "2070     98\n",
       "46       98\n",
       "1046     98\n",
       "12186    98\n",
       "2371     98\n",
       "         ..\n",
       "12405    44\n",
       "11220    44\n",
       "12356    43\n",
       "6796     42\n",
       "2101     42\n",
       "Name: count, Length: 2609, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['bottom_category_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['combined_text'] = df_train['title'] + \" \" + df_train['description'] + \" \" + df_train['tags']\n",
    "y = df_train['bottom_category_id']\n",
    "X = df_train[['combined_text', 'type']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer([\n",
    "        ('text', TfidfVectorizer(max_features=1000), 'combined_text'),\n",
    "        ('type', OneHotEncoder(), ['type'])\n",
    "    ])),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'clf__C': [1],\n",
    "    'clf__penalty': ['l2']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1_macro', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                                         TfidfVectorizer(max_features=1000),\n",
       "                                                                         &#x27;combined_text&#x27;),\n",
       "                                                                        (&#x27;type&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [&#x27;type&#x27;])])),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(random_state=42,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             param_grid={&#x27;clf__C&#x27;: [1], &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                                         TfidfVectorizer(max_features=1000),\n",
       "                                                                         &#x27;combined_text&#x27;),\n",
       "                                                                        (&#x27;type&#x27;,\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         [&#x27;type&#x27;])])),\n",
       "                                       (&#x27;clf&#x27;,\n",
       "                                        LogisticRegression(random_state=42,\n",
       "                                                           solver=&#x27;liblinear&#x27;))]),\n",
       "             param_grid={&#x27;clf__C&#x27;: [1], &#x27;clf__penalty&#x27;: [&#x27;l2&#x27;]},\n",
       "             scoring=&#x27;f1_macro&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;text&#x27;,\n",
       "                                                  TfidfVectorizer(max_features=1000),\n",
       "                                                  &#x27;combined_text&#x27;),\n",
       "                                                 (&#x27;type&#x27;, OneHotEncoder(),\n",
       "                                                  [&#x27;type&#x27;])])),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text&#x27;, TfidfVectorizer(max_features=1000),\n",
       "                                 &#x27;combined_text&#x27;),\n",
       "                                (&#x27;type&#x27;, OneHotEncoder(), [&#x27;type&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text</label><div class=\"sk-toggleable__content\"><pre>combined_text</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=1000)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">type</label><div class=\"sk-toggleable__content\"><pre>[&#x27;type&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('text',\n",
       "                                                                         TfidfVectorizer(max_features=1000),\n",
       "                                                                         'combined_text'),\n",
       "                                                                        ('type',\n",
       "                                                                         OneHotEncoder(),\n",
       "                                                                         ['type'])])),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(random_state=42,\n",
       "                                                           solver='liblinear'))]),\n",
       "             param_grid={'clf__C': [1], 'clf__penalty': ['l2']},\n",
       "             scoring='f1_macro', verbose=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found: {'clf__C': 1, 'clf__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best parameters found:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.03      0.06        32\n",
      "           2       0.56      0.18      0.27        28\n",
      "           3       0.40      0.57      0.47        30\n",
      "           4       0.33      0.54      0.41        26\n",
      "           5       0.54      0.37      0.44        35\n",
      "           6       0.50      0.18      0.26        17\n",
      "           7       0.67      0.07      0.12        30\n",
      "           8       0.24      0.55      0.33        22\n",
      "           9       0.00      0.00      0.00        19\n",
      "          10       0.33      0.04      0.07        24\n",
      "          11       0.64      0.64      0.64        25\n",
      "          12       0.20      0.14      0.16        29\n",
      "          13       0.70      0.70      0.70        30\n",
      "          14       0.19      0.23      0.21        26\n",
      "          15       0.38      0.64      0.47        33\n",
      "          16       0.17      0.23      0.19        26\n",
      "          17       0.36      0.19      0.25        26\n",
      "          18       0.46      0.50      0.48        22\n",
      "          19       0.46      0.84      0.59        19\n",
      "          20       0.31      0.48      0.37        23\n",
      "          22       0.26      0.36      0.30        25\n",
      "          23       0.62      0.31      0.42        32\n",
      "          24       0.36      0.25      0.30        32\n",
      "          25       0.33      0.09      0.14        23\n",
      "          26       0.57      0.50      0.53        24\n",
      "          27       0.62      0.37      0.47        27\n",
      "          28       0.19      0.76      0.30        17\n",
      "          29       0.38      0.42      0.40        26\n",
      "          30       0.39      0.27      0.32        26\n",
      "          31       0.26      0.29      0.27        31\n",
      "          32       0.21      0.09      0.13        33\n",
      "          33       0.18      0.60      0.28        20\n",
      "          34       0.40      0.10      0.16        20\n",
      "          35       0.25      0.06      0.10        32\n",
      "          36       0.17      0.15      0.16        26\n",
      "          37       0.43      0.10      0.16        30\n",
      "          38       0.54      0.65      0.59        23\n",
      "          39       0.85      0.52      0.65        21\n",
      "          40       0.33      0.52      0.41        23\n",
      "          41       0.21      0.32      0.25        25\n",
      "          42       0.75      0.23      0.35        26\n",
      "          43       0.25      0.12      0.16        25\n",
      "          44       0.46      0.46      0.46        26\n",
      "          45       0.26      0.18      0.21        28\n",
      "          46       0.06      0.07      0.07        28\n",
      "          47       0.24      0.17      0.20        23\n",
      "          48       0.45      0.20      0.28        25\n",
      "          49       0.67      0.37      0.48        27\n",
      "          50       0.44      0.76      0.56        21\n",
      "          51       0.33      0.83      0.47        23\n",
      "          52       0.14      0.15      0.15        26\n",
      "          53       0.93      0.44      0.60        32\n",
      "          54       0.22      0.67      0.33        21\n",
      "          55       0.34      0.70      0.46        30\n",
      "          56       0.40      0.43      0.41        28\n",
      "          57       0.17      0.04      0.06        26\n",
      "          58       0.75      0.55      0.63        22\n",
      "          59       0.63      0.63      0.63        30\n",
      "          60       0.66      0.84      0.74        25\n",
      "          61       0.85      0.85      0.85        33\n",
      "          62       0.48      0.80      0.60        25\n",
      "          63       0.14      0.04      0.06        24\n",
      "          64       0.40      0.54      0.46        26\n",
      "          65       0.75      0.69      0.72        26\n",
      "          66       0.00      0.00      0.00        24\n",
      "          67       1.00      0.04      0.07        27\n",
      "          68       0.00      0.00      0.00        28\n",
      "          69       0.00      0.00      0.00        31\n",
      "          70       0.75      0.10      0.18        30\n",
      "          71       0.00      0.00      0.00        28\n",
      "          72       0.00      0.00      0.00        30\n",
      "          73       0.40      0.06      0.11        33\n",
      "          74       0.30      0.50      0.37        26\n",
      "          75       0.67      0.08      0.14        26\n",
      "          76       0.03      0.06      0.04        17\n",
      "          77       0.18      0.07      0.10        29\n",
      "          78       0.15      0.09      0.11        23\n",
      "          79       0.50      0.31      0.38        26\n",
      "          80       0.15      0.10      0.12        21\n",
      "          81       0.13      0.07      0.09        28\n",
      "          82       0.13      0.07      0.10        27\n",
      "          83       0.33      0.65      0.44        23\n",
      "          84       0.37      0.57      0.45        23\n",
      "          85       0.32      0.73      0.44        26\n",
      "          86       0.21      0.35      0.26        34\n",
      "          87       0.50      0.82      0.62        22\n",
      "          88       0.30      0.41      0.34        27\n",
      "          89       0.24      0.62      0.34        24\n",
      "          90       0.33      0.08      0.12        26\n",
      "          91       0.21      0.50      0.29        24\n",
      "          92       0.54      0.29      0.38        24\n",
      "          93       0.42      0.37      0.39        30\n",
      "          94       0.69      0.31      0.43        35\n",
      "          96       0.10      0.04      0.05        28\n",
      "          97       0.13      0.43      0.20        23\n",
      "          98       0.50      0.15      0.23        27\n",
      "          99       0.38      0.10      0.16        29\n",
      "         100       0.10      0.11      0.11        28\n",
      "         101       0.06      0.04      0.05        25\n",
      "         102       0.08      0.04      0.05        25\n",
      "         103       0.44      0.13      0.21        30\n",
      "         104       0.24      0.37      0.29        30\n",
      "         105       0.50      0.03      0.05        37\n",
      "         106       0.35      0.51      0.41        35\n",
      "         107       0.29      0.07      0.11        29\n",
      "         108       0.58      0.76      0.66        29\n",
      "         109       0.13      0.33      0.19        21\n",
      "         110       0.12      0.13      0.12        23\n",
      "         111       0.14      0.04      0.06        27\n",
      "         112       0.35      0.86      0.50        28\n",
      "         113       0.39      0.73      0.51        15\n",
      "         114       0.33      0.25      0.29        28\n",
      "         115       0.38      0.48      0.42        29\n",
      "         116       0.29      0.43      0.35        21\n",
      "         117       0.50      0.19      0.28        26\n",
      "         118       0.39      0.30      0.34        30\n",
      "         119       0.31      0.17      0.22        24\n",
      "         120       0.38      0.53      0.44        19\n",
      "         121       0.13      0.56      0.21        16\n",
      "         122       0.64      0.78      0.71        23\n",
      "         123       0.20      0.42      0.27        24\n",
      "         124       0.42      0.70      0.53        27\n",
      "         125       0.23      0.12      0.16        25\n",
      "         126       0.32      0.52      0.40        21\n",
      "         127       0.40      0.75      0.53        28\n",
      "         128       0.00      0.00      0.00        28\n",
      "         129       0.00      0.00      0.00        31\n",
      "         130       0.00      0.00      0.00        29\n",
      "         131       0.30      0.12      0.18        24\n",
      "         132       0.00      0.00      0.00        20\n",
      "         133       0.33      0.11      0.17        27\n",
      "         134       0.30      0.52      0.38        27\n",
      "         135       0.36      0.17      0.24        23\n",
      "         136       0.43      0.38      0.40        24\n",
      "         137       1.00      0.33      0.50        33\n",
      "         138       0.63      0.76      0.69        29\n",
      "         139       0.25      0.32      0.28        31\n",
      "         140       0.72      0.97      0.83        30\n",
      "         141       0.12      0.14      0.12        22\n",
      "         142       0.38      0.78      0.51        23\n",
      "         143       0.11      0.24      0.15        21\n",
      "         144       0.09      0.05      0.06        21\n",
      "         145       0.14      0.03      0.05        35\n",
      "         147       0.61      0.55      0.58        31\n",
      "         148       0.23      0.11      0.15        27\n",
      "         149       0.54      0.64      0.58        22\n",
      "         150       0.55      0.78      0.64        23\n",
      "         151       0.06      0.05      0.06        19\n",
      "         152       0.38      0.21      0.27        24\n",
      "         153       0.19      0.36      0.25        22\n",
      "         154       0.40      0.07      0.12        27\n",
      "         155       0.70      0.70      0.70        27\n",
      "         156       0.00      0.00      0.00        28\n",
      "         157       0.14      0.07      0.10        28\n",
      "         158       0.15      0.17      0.16        23\n",
      "         159       0.30      0.24      0.27        29\n",
      "         160       0.83      0.69      0.75        29\n",
      "         161       0.10      0.09      0.10        22\n",
      "         162       0.22      0.07      0.11        27\n",
      "         163       0.50      0.35      0.42        31\n",
      "         164       0.21      0.17      0.19        24\n",
      "         165       0.09      0.12      0.11        24\n",
      "         166       0.57      0.46      0.51        26\n",
      "         167       0.55      0.62      0.58        29\n",
      "         168       0.62      0.60      0.61        25\n",
      "         169       0.18      0.18      0.18        28\n",
      "         170       0.40      0.68      0.50        28\n",
      "         171       0.71      0.33      0.45        30\n",
      "         172       0.94      0.54      0.68        28\n",
      "         173       0.29      1.00      0.45        19\n",
      "         174       0.62      0.42      0.50        43\n",
      "         175       0.37      0.65      0.47        26\n",
      "         176       0.42      0.42      0.42        19\n",
      "         177       0.28      0.32      0.30        22\n",
      "         178       0.30      0.76      0.43        29\n",
      "         179       0.35      0.45      0.39        33\n",
      "         180       0.24      0.44      0.32        27\n",
      "         181       0.17      0.28      0.21        25\n",
      "         182       0.16      0.28      0.21        25\n",
      "         183       0.88      0.73      0.80        30\n",
      "         184       0.90      0.59      0.72        32\n",
      "         185       0.72      0.90      0.80        20\n",
      "         186       0.29      0.41      0.34        29\n",
      "         187       0.61      0.41      0.49        34\n",
      "         189       0.87      0.87      0.87        23\n",
      "         190       0.32      0.37      0.34        27\n",
      "         191       0.65      0.58      0.61        26\n",
      "         192       0.56      0.69      0.62        29\n",
      "         193       0.52      0.55      0.53        29\n",
      "         194       0.76      0.79      0.77        28\n",
      "         195       0.62      0.68      0.65        31\n",
      "         196       0.47      0.90      0.62        21\n",
      "         197       0.24      0.70      0.35        20\n",
      "         199       0.89      0.57      0.70        28\n",
      "         200       0.57      0.46      0.51        28\n",
      "         201       0.33      0.08      0.12        26\n",
      "         202       0.77      0.66      0.71        35\n",
      "         203       0.27      0.14      0.19        28\n",
      "         204       0.31      0.16      0.21        25\n",
      "         205       0.44      0.44      0.44        16\n",
      "         206       0.56      0.74      0.63        27\n",
      "         207       0.26      0.33      0.30        27\n",
      "         208       0.39      0.48      0.43        29\n",
      "         210       0.67      0.08      0.14        25\n",
      "         211       0.44      0.31      0.36        26\n",
      "         212       0.47      0.36      0.41        22\n",
      "         213       0.29      0.07      0.12        27\n",
      "         214       0.50      0.16      0.24        32\n",
      "         215       0.32      0.33      0.33        33\n",
      "         216       0.19      0.36      0.24        28\n",
      "         217       0.22      0.07      0.11        28\n",
      "         218       0.37      0.64      0.47        25\n",
      "         219       0.17      0.04      0.06        28\n",
      "         220       0.45      0.42      0.43        31\n",
      "         221       0.57      0.59      0.58        29\n",
      "         222       0.17      0.03      0.06        30\n",
      "         224       0.38      0.31      0.34        32\n",
      "         225       0.17      0.23      0.20        26\n",
      "         226       0.50      0.59      0.54        32\n",
      "         227       0.54      0.23      0.33        30\n",
      "         228       0.56      0.89      0.68        28\n",
      "         231       0.33      0.68      0.45        25\n",
      "         232       0.60      0.18      0.28        33\n",
      "         233       0.55      0.37      0.44        30\n",
      "         234       0.43      0.38      0.41        26\n",
      "         235       0.89      0.57      0.70        14\n",
      "         236       0.82      0.69      0.75        26\n",
      "         237       0.70      0.79      0.75        24\n",
      "         238       0.61      0.58      0.60        24\n",
      "         239       0.77      0.94      0.85        32\n",
      "         240       0.46      0.82      0.59        22\n",
      "         241       0.44      0.15      0.23        26\n",
      "         242       0.00      0.00      0.00        17\n",
      "         243       0.78      0.54      0.64        26\n",
      "         245       0.88      0.26      0.40        27\n",
      "         247       0.46      0.75      0.57        32\n",
      "         248       0.43      0.11      0.18        27\n",
      "         249       0.41      0.41      0.41        27\n",
      "         250       1.00      0.16      0.27        19\n",
      "         253       0.55      0.42      0.48        26\n",
      "         254       0.23      0.54      0.33        28\n",
      "         255       0.64      0.31      0.42        29\n",
      "         256       0.11      0.11      0.11        18\n",
      "         257       0.31      0.40      0.35        25\n",
      "         258       0.68      0.72      0.70        32\n",
      "         259       0.00      0.00      0.00        26\n",
      "         260       0.45      0.74      0.56        23\n",
      "         261       0.35      0.50      0.41        16\n",
      "         262       0.40      0.60      0.48        30\n",
      "         263       0.79      0.96      0.87        27\n",
      "         264       0.54      0.73      0.62        30\n",
      "         265       1.00      0.03      0.06        34\n",
      "         267       0.64      0.78      0.71        23\n",
      "         268       0.65      0.53      0.59        32\n",
      "         270       1.00      0.15      0.26        27\n",
      "         271       0.57      0.58      0.58        36\n",
      "         272       0.41      0.88      0.56        32\n",
      "         273       0.29      0.40      0.33        25\n",
      "         274       0.20      0.04      0.06        27\n",
      "         275       0.36      0.15      0.22        26\n",
      "         276       0.33      0.04      0.08        23\n",
      "         277       0.35      0.57      0.44        21\n",
      "         279       1.00      0.04      0.08        25\n",
      "         280       0.29      0.08      0.12        25\n",
      "         281       0.30      0.29      0.29        21\n",
      "         282       0.00      0.00      0.00        21\n",
      "         283       0.72      0.52      0.60        25\n",
      "         284       0.61      0.33      0.43        33\n",
      "         285       0.16      0.28      0.20        25\n",
      "         286       0.37      0.44      0.40        25\n",
      "         287       0.50      0.17      0.25        24\n",
      "         288       0.33      0.10      0.15        10\n",
      "         290       0.37      0.24      0.29        29\n",
      "         291       0.49      0.50      0.49        34\n",
      "         292       0.42      0.19      0.26        27\n",
      "         296       0.42      0.56      0.48        27\n",
      "         297       0.68      0.72      0.70        29\n",
      "         298       0.19      0.25      0.21        20\n",
      "         299       0.63      0.55      0.59        22\n",
      "         300       0.44      0.24      0.31        34\n",
      "         301       0.52      0.82      0.64        28\n",
      "         302       0.35      0.48      0.41        23\n",
      "         303       0.15      0.18      0.17        22\n",
      "         304       0.64      0.70      0.67        23\n",
      "         305       0.67      0.62      0.64        29\n",
      "         306       0.00      0.00      0.00        17\n",
      "         307       0.60      0.38      0.46        24\n",
      "         308       0.28      0.68      0.40        25\n",
      "         309       0.46      0.39      0.42        28\n",
      "         310       0.32      0.59      0.42        27\n",
      "         311       0.80      0.41      0.55        29\n",
      "         312       0.23      0.11      0.15        27\n",
      "         313       0.65      0.74      0.69        27\n",
      "         314       0.64      0.82      0.72        22\n",
      "         315       0.69      0.44      0.54        25\n",
      "         316       0.72      0.67      0.69        27\n",
      "         317       0.43      0.09      0.15        34\n",
      "         318       0.68      0.85      0.76        33\n",
      "         320       0.40      0.76      0.52        25\n",
      "         321       0.50      0.32      0.39        22\n",
      "         322       0.17      0.35      0.23        20\n",
      "         323       0.25      0.06      0.09        18\n",
      "         324       0.38      0.10      0.16        30\n",
      "         325       0.28      0.21      0.24        24\n",
      "         326       0.41      0.21      0.27        34\n",
      "         327       0.26      0.30      0.28        27\n",
      "         328       0.17      0.24      0.20        21\n",
      "         329       0.46      0.63      0.53        27\n",
      "         330       0.19      0.18      0.19        22\n",
      "         331       0.38      0.16      0.23        31\n",
      "         332       0.64      0.86      0.73        21\n",
      "         335       0.21      0.35      0.26        20\n",
      "         336       0.14      0.38      0.21        24\n",
      "         337       0.00      0.00      0.00        27\n",
      "         338       0.16      0.52      0.25        21\n",
      "         339       0.41      0.58      0.48        31\n",
      "         340       0.67      0.09      0.16        22\n",
      "         341       0.52      0.41      0.46        29\n",
      "         343       0.29      0.16      0.21        25\n",
      "         344       0.32      0.35      0.33        26\n",
      "         345       0.11      0.15      0.13        27\n",
      "         346       0.14      0.04      0.06        27\n",
      "         347       0.05      0.05      0.05        19\n",
      "         349       0.10      0.12      0.11        24\n",
      "         350       0.00      0.00      0.00        30\n",
      "         351       0.00      0.00      0.00        30\n",
      "         352       0.36      0.16      0.22        31\n",
      "         353       0.70      0.18      0.29        38\n",
      "         354       0.13      0.08      0.10        26\n",
      "         355       0.16      0.36      0.22        22\n",
      "         356       0.53      0.27      0.36        30\n",
      "         357       0.69      0.28      0.40        32\n",
      "         358       0.41      0.95      0.58        20\n",
      "         359       1.00      0.11      0.20        18\n",
      "         361       0.71      0.29      0.42        34\n",
      "         364       0.65      0.43      0.52        30\n",
      "         365       0.84      0.72      0.78        29\n",
      "         368       0.50      0.54      0.52        26\n",
      "         369       0.75      0.39      0.51        31\n",
      "         371       0.56      0.29      0.38        17\n",
      "         372       0.52      0.63      0.57        27\n",
      "         373       0.67      0.38      0.48        21\n",
      "         374       0.67      0.30      0.41        27\n",
      "         375       0.31      0.22      0.26        23\n",
      "         376       0.62      0.33      0.43        30\n",
      "         377       0.50      0.03      0.05        36\n",
      "         378       0.87      0.65      0.74        31\n",
      "         379       0.45      0.26      0.33        35\n",
      "         380       0.20      0.26      0.23        27\n",
      "         381       0.50      0.45      0.47        31\n",
      "         382       0.81      0.89      0.85        19\n",
      "         383       0.50      0.17      0.25        24\n",
      "         385       0.57      0.43      0.49        28\n",
      "         386       0.31      0.35      0.33        23\n",
      "         387       0.00      0.00      0.00        26\n",
      "         388       0.36      0.19      0.25        26\n",
      "         389       0.28      0.50      0.36        26\n",
      "         392       0.45      0.20      0.28        25\n",
      "         394       0.26      0.41      0.32        22\n",
      "         395       0.62      0.48      0.54        33\n",
      "         396       0.62      0.36      0.46        22\n",
      "         397       0.58      0.44      0.50        34\n",
      "         398       0.83      0.45      0.59        33\n",
      "         399       0.56      0.14      0.23        35\n",
      "         400       0.43      0.40      0.41        15\n",
      "         401       0.40      0.30      0.34        20\n",
      "         402       0.50      0.26      0.34        27\n",
      "         403       0.23      0.12      0.15        26\n",
      "         404       0.57      0.53      0.55        30\n",
      "         405       0.50      0.15      0.23        27\n",
      "         406       0.20      0.39      0.26        23\n",
      "         407       0.36      0.63      0.46        19\n",
      "         408       0.19      0.33      0.25        21\n",
      "         411       0.21      0.12      0.16        24\n",
      "         412       0.50      0.39      0.44        33\n",
      "         413       0.00      0.00      0.00        13\n",
      "         414       0.35      0.77      0.48        26\n",
      "         415       0.31      0.15      0.21        26\n",
      "         416       0.50      0.04      0.08        23\n",
      "         417       0.19      0.17      0.18        29\n",
      "         418       0.47      0.21      0.29        33\n",
      "         419       0.25      0.35      0.29        20\n",
      "         420       0.57      0.57      0.57        28\n",
      "         421       0.46      0.43      0.44        14\n",
      "         422       0.32      0.63      0.42        19\n",
      "         424       0.29      0.48      0.36        21\n",
      "         425       0.57      0.31      0.40        26\n",
      "         426       0.27      0.36      0.31        22\n",
      "         427       0.70      0.50      0.58        14\n",
      "         428       0.50      0.34      0.41        32\n",
      "         429       0.63      0.61      0.62        28\n",
      "         430       0.32      0.24      0.27        25\n",
      "         431       0.71      0.26      0.38        19\n",
      "         432       0.40      0.07      0.12        27\n",
      "         433       0.15      0.12      0.13        26\n",
      "         434       0.67      0.27      0.38        30\n",
      "         435       0.40      0.40      0.40        20\n",
      "         436       0.38      0.38      0.38        32\n",
      "         437       0.94      0.57      0.71        28\n",
      "         439       0.44      0.44      0.44        18\n",
      "         440       0.47      0.67      0.55        21\n",
      "         441       0.55      0.96      0.70        24\n",
      "         443       0.40      0.31      0.35        26\n",
      "         444       0.20      0.35      0.26        26\n",
      "         445       0.50      0.56      0.53        27\n",
      "         446       0.15      0.33      0.20        18\n",
      "         447       0.14      0.03      0.05        31\n",
      "         448       0.46      0.41      0.43        27\n",
      "         449       0.09      0.12      0.11        24\n",
      "         450       0.23      0.26      0.24        27\n",
      "         451       0.50      0.21      0.30        28\n",
      "         452       0.85      0.57      0.68        30\n",
      "         453       0.20      0.67      0.31        21\n",
      "         454       0.47      0.70      0.57        27\n",
      "         455       0.65      0.53      0.59        32\n",
      "         456       0.24      0.31      0.27        29\n",
      "         457       0.28      0.24      0.26        29\n",
      "         458       0.24      0.46      0.32        28\n",
      "         459       0.65      0.48      0.55        27\n",
      "         460       0.68      0.38      0.49        34\n",
      "         461       0.38      0.31      0.34        36\n",
      "         462       0.57      0.77      0.65        22\n",
      "         463       0.24      0.45      0.31        22\n",
      "         465       0.56      0.18      0.27        28\n",
      "         466       0.00      0.00      0.00        21\n",
      "         467       0.20      0.23      0.21        31\n",
      "         468       0.00      0.00      0.00        28\n",
      "         469       0.31      0.41      0.35        22\n",
      "         470       0.31      0.62      0.41        26\n",
      "         471       0.32      0.32      0.32        22\n",
      "         472       0.23      0.32      0.26        22\n",
      "         473       0.33      0.10      0.15        30\n",
      "         474       0.27      0.61      0.37        18\n",
      "         475       0.35      0.21      0.27        28\n",
      "         476       0.00      0.00      0.00        33\n",
      "         477       0.58      0.28      0.38        25\n",
      "         478       0.31      0.21      0.25        19\n",
      "         479       0.47      0.29      0.36        31\n",
      "         480       0.13      0.27      0.18        26\n",
      "         481       0.47      0.74      0.58        23\n",
      "         482       0.19      0.44      0.26        27\n",
      "         483       0.27      0.17      0.21        24\n",
      "         484       0.56      0.17      0.26        29\n",
      "         485       0.78      0.21      0.33        34\n",
      "         486       0.13      0.67      0.22        15\n",
      "         487       0.44      0.17      0.24        24\n",
      "         488       0.09      0.10      0.09        21\n",
      "         489       0.40      0.14      0.21        28\n",
      "         490       0.42      0.45      0.43        33\n",
      "         491       0.24      0.48      0.32        25\n",
      "         492       0.38      0.29      0.33        31\n",
      "         493       0.62      0.18      0.28        28\n",
      "         494       0.41      0.50      0.45        28\n",
      "         495       0.96      0.85      0.90        27\n",
      "         496       0.22      0.07      0.10        30\n",
      "         497       0.45      0.20      0.28        25\n",
      "         498       0.45      0.18      0.26        28\n",
      "         499       0.32      0.27      0.29        22\n",
      "         500       0.00      0.00      0.00        28\n",
      "         501       0.09      0.04      0.06        24\n",
      "         502       0.36      0.36      0.36        28\n",
      "         503       0.18      0.08      0.11        26\n",
      "         504       0.10      0.08      0.09        24\n",
      "         505       0.30      0.64      0.41        28\n",
      "         506       0.34      0.40      0.37        25\n",
      "         507       0.08      0.08      0.08        24\n",
      "         508       0.12      0.42      0.19        19\n",
      "         509       0.22      0.22      0.22        23\n",
      "         510       0.45      0.80      0.58        25\n",
      "         511       0.00      0.00      0.00        30\n",
      "         512       0.28      0.36      0.31        22\n",
      "         513       0.41      0.35      0.38        31\n",
      "         514       0.19      0.16      0.17        25\n",
      "         515       0.00      0.00      0.00        36\n",
      "         516       0.30      0.37      0.33        30\n",
      "         517       0.31      0.44      0.37        25\n",
      "         519       0.24      0.36      0.29        28\n",
      "         520       0.25      0.07      0.11        29\n",
      "         521       0.76      0.67      0.71        24\n",
      "         522       0.34      0.42      0.38        26\n",
      "         523       0.25      0.11      0.15        27\n",
      "         524       0.42      0.73      0.54        26\n",
      "         525       0.27      0.29      0.28        24\n",
      "         526       0.50      0.04      0.07        25\n",
      "         527       0.20      0.07      0.11        28\n",
      "         528       0.67      0.92      0.77        26\n",
      "         529       0.27      0.29      0.28        24\n",
      "         530       0.50      0.33      0.40        21\n",
      "         531       0.41      0.41      0.41        29\n",
      "         532       0.81      0.69      0.75        32\n",
      "         533       0.42      0.54      0.47        26\n",
      "         534       0.31      0.29      0.30        28\n",
      "         535       0.23      0.25      0.24        28\n",
      "         536       0.30      0.69      0.42        26\n",
      "         537       0.31      0.17      0.22        24\n",
      "         538       0.70      0.58      0.64        24\n",
      "         539       0.29      0.59      0.39        17\n",
      "         540       0.21      0.12      0.16        24\n",
      "         541       0.39      0.43      0.41        28\n",
      "         542       0.36      0.50      0.42        18\n",
      "         543       0.25      0.24      0.25        29\n",
      "         544       0.50      0.15      0.23        27\n",
      "         545       0.25      0.36      0.30        25\n",
      "         546       0.65      0.37      0.47        30\n",
      "         547       0.50      0.53      0.52        30\n",
      "         548       0.28      0.42      0.34        26\n",
      "         549       0.15      0.06      0.09        32\n",
      "         550       0.17      0.17      0.17        30\n",
      "         551       0.46      0.60      0.52        20\n",
      "         552       0.22      0.15      0.18        26\n",
      "         553       0.00      0.00      0.00        34\n",
      "         554       0.20      0.40      0.26        25\n",
      "         555       0.52      0.45      0.48        29\n",
      "         556       0.54      0.48      0.51        29\n",
      "         557       0.38      0.10      0.16        30\n",
      "         558       0.37      0.27      0.31        26\n",
      "         559       0.14      0.08      0.10        25\n",
      "         560       0.18      0.09      0.12        32\n",
      "         561       0.39      0.64      0.49        28\n",
      "         562       0.00      0.00      0.00        26\n",
      "         603       0.27      0.11      0.15        28\n",
      "         604       0.57      0.41      0.48        29\n",
      "         609       0.00      0.00      0.00        32\n",
      "         769       0.45      0.82      0.58        28\n",
      "         779       0.00      0.00      0.00        27\n",
      "         780       0.54      0.39      0.46        33\n",
      "         781       0.42      0.59      0.49        22\n",
      "         782       0.35      0.54      0.42        26\n",
      "         783       0.35      0.29      0.32        21\n",
      "         784       0.84      0.81      0.82        26\n",
      "         785       0.63      0.50      0.56        24\n",
      "         786       0.26      0.46      0.33        26\n",
      "         825       0.38      0.33      0.36        24\n",
      "         826       0.58      0.37      0.45        19\n",
      "         827       0.29      0.22      0.25        27\n",
      "         829       0.44      0.13      0.20        31\n",
      "         830       0.85      0.53      0.65        32\n",
      "         831       0.41      0.54      0.46        28\n",
      "         833       1.00      0.22      0.36        18\n",
      "         834       0.77      0.74      0.75        27\n",
      "         836       0.80      0.46      0.59        26\n",
      "         837       0.54      0.50      0.52        28\n",
      "         838       0.77      0.74      0.75        27\n",
      "         839       0.50      0.11      0.18        27\n",
      "         840       0.53      0.70      0.60        30\n",
      "         843       0.83      0.21      0.33        24\n",
      "         845       0.18      0.27      0.22        26\n",
      "         846       0.68      0.86      0.76        22\n",
      "         847       0.50      0.28      0.36        25\n",
      "         848       0.81      0.68      0.74        25\n",
      "         849       0.75      0.40      0.52        30\n",
      "         850       1.00      0.13      0.23        23\n",
      "         851       0.38      0.12      0.18        25\n",
      "         852       0.44      0.57      0.50        21\n",
      "         853       0.71      0.77      0.74        26\n",
      "         854       0.81      0.66      0.72        32\n",
      "         855       0.89      0.70      0.78        23\n",
      "         857       0.33      0.33      0.33        12\n",
      "         858       0.49      0.74      0.59        27\n",
      "         862       0.50      0.68      0.58        28\n",
      "         863       0.50      0.44      0.47        25\n",
      "         864       0.44      0.38      0.41        29\n",
      "         865       0.55      0.79      0.65        28\n",
      "         866       0.54      0.60      0.57        25\n",
      "         867       0.90      0.86      0.88        21\n",
      "         869       1.00      0.48      0.65        27\n",
      "         871       0.62      0.45      0.53        33\n",
      "         872       0.45      0.69      0.55        29\n",
      "         873       0.43      0.64      0.52        25\n",
      "         874       0.79      0.73      0.76        30\n",
      "         875       0.33      0.05      0.08        22\n",
      "         878       0.50      0.70      0.58        30\n",
      "         881       0.70      0.53      0.60        30\n",
      "         882       0.50      0.43      0.46        28\n",
      "         883       1.00      0.42      0.59        12\n",
      "         884       0.17      0.09      0.12        11\n",
      "         885       0.68      0.59      0.63        32\n",
      "         887       0.47      0.24      0.32        33\n",
      "         888       0.45      0.19      0.26        27\n",
      "         889       0.32      0.45      0.37        31\n",
      "         890       0.62      0.19      0.29        26\n",
      "         891       0.00      0.00      0.00        24\n",
      "         892       0.80      0.40      0.53        20\n",
      "         893       0.67      0.61      0.64        23\n",
      "         894       0.08      0.04      0.06        24\n",
      "         897       0.70      0.32      0.44        22\n",
      "         899       0.39      0.30      0.34        23\n",
      "         900       0.62      0.17      0.27        29\n",
      "         901       0.73      0.76      0.75        25\n",
      "         902       0.60      0.10      0.17        31\n",
      "         903       0.80      0.17      0.28        24\n",
      "         904       0.24      0.58      0.34        24\n",
      "         905       0.44      0.83      0.58        23\n",
      "         906       0.53      0.25      0.34        32\n",
      "         907       0.50      0.57      0.53        28\n",
      "         908       0.85      0.73      0.79        30\n",
      "         909       0.78      0.21      0.33        33\n",
      "         910       0.56      0.60      0.58        25\n",
      "         911       0.58      0.23      0.33        30\n",
      "         912       0.14      0.22      0.17        23\n",
      "         913       0.58      0.44      0.50        34\n",
      "         914       0.51      0.80      0.62        30\n",
      "         915       0.48      0.33      0.39        30\n",
      "         916       0.20      0.26      0.23        23\n",
      "         917       0.63      0.63      0.63        38\n",
      "         918       0.62      0.65      0.63        31\n",
      "         919       1.00      0.35      0.52        23\n",
      "         920       0.45      0.36      0.40        28\n",
      "         922       1.00      0.21      0.35        14\n",
      "         923       1.00      0.93      0.97        15\n",
      "         924       0.50      0.06      0.10        36\n",
      "         925       0.53      0.41      0.46        39\n",
      "         926       0.40      0.20      0.27        30\n",
      "         927       0.65      0.65      0.65        26\n",
      "         929       0.26      0.82      0.39        22\n",
      "         930       0.93      0.48      0.64        29\n",
      "         931       0.80      0.12      0.21        34\n",
      "         933       0.75      0.15      0.25        20\n",
      "         934       0.67      0.44      0.53        32\n",
      "         935       0.09      0.23      0.13        22\n",
      "         936       0.17      0.36      0.23        22\n",
      "         937       0.86      0.22      0.35        27\n",
      "         938       0.44      0.15      0.23        26\n",
      "         939       0.43      0.23      0.30        13\n",
      "         940       0.03      0.04      0.03        28\n",
      "         942       0.00      0.00      0.00        10\n",
      "         943       0.21      0.58      0.31        26\n",
      "         944       0.32      0.30      0.31        27\n",
      "         945       0.26      0.28      0.27        29\n",
      "         946       0.83      0.29      0.43        35\n",
      "         947       0.43      0.73      0.54        22\n",
      "         948       0.48      0.88      0.62        34\n",
      "         949       0.71      0.29      0.42        17\n",
      "         950       0.60      0.19      0.29        16\n",
      "         951       0.15      0.06      0.09        33\n",
      "         952       0.25      0.09      0.13        35\n",
      "         954       0.67      0.33      0.44        36\n",
      "         955       0.36      0.62      0.46        26\n",
      "         956       0.30      0.10      0.15        31\n",
      "         957       0.44      0.28      0.34        25\n",
      "         958       0.28      0.21      0.24        24\n",
      "         959       0.28      0.25      0.26        28\n",
      "         961       0.65      0.41      0.50        32\n",
      "         962       0.50      0.43      0.46        30\n",
      "         963       0.89      0.33      0.48        24\n",
      "         965       0.00      0.00      0.00        36\n",
      "         967       0.50      0.55      0.52        22\n",
      "         968       0.26      0.24      0.25        21\n",
      "         969       0.44      0.32      0.37        22\n",
      "         970       0.44      0.30      0.36        27\n",
      "         971       0.25      0.15      0.19        20\n",
      "         972       0.35      0.26      0.30        23\n",
      "         973       0.42      0.18      0.25        28\n",
      "         974       0.21      0.67      0.31        21\n",
      "         975       0.06      0.33      0.11        18\n",
      "         976       0.38      0.27      0.32        33\n",
      "         977       0.41      0.38      0.39        37\n",
      "         978       0.14      0.23      0.18        22\n",
      "         979       0.50      0.04      0.08        24\n",
      "         980       0.26      0.26      0.26        34\n",
      "         981       0.79      0.76      0.77        29\n",
      "         982       0.61      0.59      0.60        29\n",
      "         983       0.63      0.59      0.61        32\n",
      "         985       0.50      0.21      0.29        29\n",
      "         986       0.39      0.62      0.48        32\n",
      "         987       0.27      0.52      0.36        25\n",
      "         988       0.79      0.77      0.78        30\n",
      "         989       0.00      0.00      0.00        29\n",
      "         990       0.62      0.33      0.43        24\n",
      "         991       0.67      0.05      0.10        37\n",
      "         992       0.11      0.16      0.13        19\n",
      "         993       0.16      0.15      0.15        27\n",
      "         994       0.00      0.00      0.00        27\n",
      "         996       0.36      0.48      0.41        27\n",
      "         997       0.26      0.64      0.37        22\n",
      "         998       0.31      0.61      0.42        18\n",
      "         999       0.25      0.10      0.14        30\n",
      "        1000       0.28      0.41      0.33        27\n",
      "        1001       0.40      0.66      0.50        35\n",
      "        1002       0.00      0.00      0.00        29\n",
      "        1003       0.33      0.09      0.15        32\n",
      "        1004       0.00      0.00      0.00        27\n",
      "        1005       0.37      0.50      0.43        26\n",
      "        1006       0.60      0.72      0.66        29\n",
      "        1007       0.72      0.67      0.69        27\n",
      "        1008       0.29      0.24      0.26        29\n",
      "        1009       0.29      0.63      0.40        19\n",
      "        1010       0.48      0.48      0.48        27\n",
      "        1011       0.45      0.39      0.42        33\n",
      "        1012       0.17      0.22      0.20        18\n",
      "        1014       0.42      0.87      0.56        23\n",
      "        1016       0.27      0.15      0.19        27\n",
      "        1017       0.38      0.39      0.39        33\n",
      "        1018       0.00      0.00      0.00        23\n",
      "        1019       0.38      0.43      0.40        28\n",
      "        1020       0.17      0.14      0.15        29\n",
      "        1021       0.58      0.91      0.71        33\n",
      "        1022       0.49      0.65      0.56        26\n",
      "        1023       0.00      0.00      0.00        27\n",
      "        1024       0.50      0.30      0.37        30\n",
      "        1025       1.00      0.06      0.11        34\n",
      "        1026       0.10      0.04      0.05        28\n",
      "        1027       0.00      0.00      0.00        30\n",
      "        1028       0.40      0.20      0.27        30\n",
      "        1029       0.00      0.00      0.00        28\n",
      "        1030       0.42      0.33      0.37        24\n",
      "        1031       0.50      0.08      0.14        25\n",
      "        1033       0.00      0.00      0.00        35\n",
      "        1034       0.15      0.20      0.17        25\n",
      "        1035       0.00      0.00      0.00        25\n",
      "        1036       0.00      0.00      0.00        24\n",
      "        1037       0.27      0.28      0.27        25\n",
      "        1038       0.60      0.65      0.63        23\n",
      "        1039       0.50      0.10      0.17        30\n",
      "        1040       0.12      0.22      0.16        23\n",
      "        1042       0.55      0.21      0.31        28\n",
      "        1043       0.00      0.00      0.00        20\n",
      "        1044       0.14      0.24      0.18        21\n",
      "        1045       0.16      0.35      0.21        26\n",
      "        1046       0.61      0.85      0.71        27\n",
      "        1047       0.33      0.03      0.05        37\n",
      "        1048       0.23      0.15      0.18        33\n",
      "        1049       0.07      0.03      0.04        31\n",
      "        1050       0.25      0.17      0.20        30\n",
      "        1051       0.00      0.00      0.00        26\n",
      "        1052       0.00      0.00      0.00        28\n",
      "        1053       0.00      0.00      0.00        20\n",
      "        1054       0.00      0.00      0.00        26\n",
      "        1055       0.21      0.46      0.29        28\n",
      "        1056       0.30      0.58      0.39        19\n",
      "        1057       0.38      0.50      0.43        32\n",
      "        1058       0.52      0.62      0.56        26\n",
      "        1059       0.32      0.30      0.31        20\n",
      "        1060       0.12      0.11      0.11        19\n",
      "        1061       0.53      0.36      0.43        25\n",
      "        1062       0.31      0.79      0.45        24\n",
      "        1063       0.33      0.24      0.28        29\n",
      "        1064       0.40      0.07      0.12        29\n",
      "        1065       0.13      0.29      0.18        31\n",
      "        1066       0.22      0.43      0.29        23\n",
      "        1067       0.00      0.00      0.00        28\n",
      "        1068       0.27      0.17      0.21        23\n",
      "        1069       0.19      0.32      0.24        25\n",
      "        1070       0.48      0.64      0.55        33\n",
      "        1071       0.48      0.38      0.43        26\n",
      "        1072       0.42      0.65      0.51        20\n",
      "        1073       1.00      0.03      0.06        31\n",
      "        1074       0.00      0.00      0.00        25\n",
      "        1075       0.00      0.00      0.00        31\n",
      "        1076       0.00      0.00      0.00        28\n",
      "        1077       0.07      0.04      0.05        28\n",
      "        1078       0.23      0.28      0.25        25\n",
      "        1079       1.00      0.03      0.05        36\n",
      "        1080       0.40      0.96      0.57        24\n",
      "        1081       0.33      0.10      0.15        21\n",
      "        1082       0.39      0.46      0.42        26\n",
      "        1083       0.55      0.53      0.54        34\n",
      "        1085       0.26      0.19      0.22        26\n",
      "        1086       0.33      0.05      0.09        20\n",
      "        1088       0.12      0.03      0.05        32\n",
      "        1089       0.28      0.21      0.24        24\n",
      "        1090       0.61      0.77      0.68        22\n",
      "        1091       0.38      0.11      0.17        28\n",
      "        1092       0.61      0.93      0.74        27\n",
      "        1093       0.43      0.59      0.50        27\n",
      "        1094       0.32      0.39      0.35        28\n",
      "        1095       0.68      0.90      0.77        30\n",
      "        1096       0.50      0.24      0.32        21\n",
      "        1097       0.00      0.00      0.00        35\n",
      "        1098       0.48      0.65      0.56        23\n",
      "        1099       0.39      0.76      0.51        25\n",
      "        1100       0.65      0.43      0.52        30\n",
      "        1101       0.17      0.07      0.10        30\n",
      "        1102       1.00      0.03      0.06        32\n",
      "        1103       0.00      0.00      0.00        28\n",
      "        1104       0.21      0.67      0.32        27\n",
      "        1105       0.17      0.05      0.07        21\n",
      "        1106       0.86      0.55      0.67        22\n",
      "        1107       0.50      0.24      0.32        25\n",
      "        1108       0.75      0.18      0.29        33\n",
      "        1109       0.56      0.36      0.44        25\n",
      "        1110       0.13      0.10      0.11        30\n",
      "        1112       0.70      0.26      0.38        27\n",
      "        1113       0.75      0.09      0.16        33\n",
      "        1114       0.77      0.33      0.47        30\n",
      "        1115       0.88      0.37      0.52        19\n",
      "        1116       0.50      0.17      0.26        29\n",
      "        1117       0.67      0.32      0.43        31\n",
      "        1118       0.21      0.23      0.22        31\n",
      "        1119       0.26      0.22      0.24        32\n",
      "        1120       0.32      0.33      0.33        24\n",
      "        1121       0.50      0.74      0.60        27\n",
      "        1122       0.33      0.62      0.43        29\n",
      "        1123       0.67      0.80      0.73        30\n",
      "        1124       0.24      0.30      0.26        27\n",
      "        1125       0.44      0.31      0.36        26\n",
      "        1126       0.35      0.57      0.43        28\n",
      "        1129       0.29      0.50      0.37        24\n",
      "        1130       0.56      0.54      0.55        28\n",
      "        1132       0.67      0.90      0.77        20\n",
      "        1133       0.42      0.68      0.52        19\n",
      "        1135       0.00      0.00      0.00        25\n",
      "        1136       0.00      0.00      0.00        33\n",
      "        1137       0.36      0.35      0.35        26\n",
      "        1138       0.00      0.00      0.00        32\n",
      "        1139       0.00      0.00      0.00        24\n",
      "        1140       0.07      0.04      0.05        25\n",
      "        1141       0.83      0.83      0.83        36\n",
      "        1142       0.09      0.04      0.05        27\n",
      "        1143       0.43      0.36      0.39        25\n",
      "        1144       0.33      0.19      0.24        26\n",
      "        1145       0.55      0.44      0.49        25\n",
      "        1146       0.64      0.70      0.67        30\n",
      "        1147       0.42      0.31      0.36        32\n",
      "        1148       0.26      0.57      0.36        28\n",
      "        1149       0.54      0.56      0.55        25\n",
      "        1150       0.71      0.42      0.53        24\n",
      "        1151       0.00      0.00      0.00        24\n",
      "        1152       0.27      0.65      0.39        26\n",
      "        1153       0.68      0.39      0.50        38\n",
      "        1154       0.86      0.78      0.82        32\n",
      "        1155       0.05      0.09      0.06        23\n",
      "        1156       0.32      0.52      0.39        29\n",
      "        1157       0.22      0.07      0.11        27\n",
      "        1158       0.11      0.28      0.16        25\n",
      "        1159       0.36      0.12      0.18        34\n",
      "        1160       0.32      0.39      0.35        28\n",
      "        1161       0.00      0.00      0.00        10\n",
      "        1163       0.18      0.12      0.14        25\n",
      "        1165       0.00      0.00      0.00        24\n",
      "        1166       0.20      0.09      0.13        32\n",
      "        1167       0.08      0.10      0.09        29\n",
      "        1168       0.50      0.04      0.07        27\n",
      "        1169       0.67      0.22      0.33        27\n",
      "        1170       0.46      0.48      0.47        25\n",
      "        1171       0.33      0.39      0.36        28\n",
      "        1172       0.34      0.50      0.41        24\n",
      "        1173       0.88      0.23      0.36        31\n",
      "        1174       0.71      0.52      0.60        29\n",
      "        1175       0.30      0.31      0.30        26\n",
      "        1176       0.74      0.63      0.68        27\n",
      "        1177       0.50      0.17      0.25        24\n",
      "        1178       0.76      0.96      0.85        23\n",
      "        1179       0.50      0.07      0.12        29\n",
      "        1180       0.46      0.48      0.47        23\n",
      "        1181       0.00      0.00      0.00        33\n",
      "        1182       0.29      0.14      0.19        28\n",
      "        1183       0.46      0.50      0.48        24\n",
      "        1184       0.84      0.67      0.74        24\n",
      "        1185       0.63      0.80      0.71        30\n",
      "        1186       0.43      0.10      0.16        30\n",
      "        1187       0.47      0.50      0.48        28\n",
      "        1188       0.23      0.44      0.31        25\n",
      "        1189       0.27      0.18      0.21        34\n",
      "        1190       0.71      0.44      0.55        27\n",
      "        1191       0.46      0.64      0.53        25\n",
      "        1192       0.49      0.59      0.53        34\n",
      "        1193       0.00      0.00      0.00        33\n",
      "        1194       0.10      0.04      0.06        26\n",
      "        1195       0.21      0.28      0.24        29\n",
      "        1196       0.31      0.17      0.22        30\n",
      "        1197       0.41      0.30      0.35        30\n",
      "        1198       0.10      0.29      0.14        17\n",
      "        1199       0.36      0.74      0.49        23\n",
      "        1200       0.30      0.21      0.24        29\n",
      "        1201       0.33      0.04      0.07        26\n",
      "        1202       0.46      0.54      0.50        24\n",
      "        1203       0.09      0.12      0.10        17\n",
      "        1204       0.24      0.38      0.30        26\n",
      "        1205       0.48      0.60      0.53        20\n",
      "        1206       0.20      0.06      0.09        33\n",
      "        1207       0.38      0.48      0.42        25\n",
      "        1208       0.11      0.04      0.06        26\n",
      "        1210       0.46      0.53      0.49        32\n",
      "        1211       0.52      0.54      0.53        28\n",
      "        1212       0.31      0.18      0.23        28\n",
      "        1213       0.60      0.54      0.57        28\n",
      "        1214       0.06      0.04      0.05        25\n",
      "        1215       0.39      0.60      0.47        20\n",
      "        1216       0.17      0.07      0.10        27\n",
      "        1217       0.00      0.00      0.00        29\n",
      "        1218       0.24      0.17      0.20        35\n",
      "        1219       0.14      0.30      0.19        27\n",
      "        1220       0.36      0.29      0.32        31\n",
      "        1221       0.25      0.21      0.23        29\n",
      "        1222       0.12      0.09      0.10        22\n",
      "        1223       0.18      0.13      0.15        23\n",
      "        1224       0.40      0.39      0.39        31\n",
      "        1225       0.19      0.20      0.20        25\n",
      "        1226       0.27      0.32      0.30        28\n",
      "        1227       0.35      0.65      0.46        26\n",
      "        1228       0.25      0.03      0.05        33\n",
      "        1229       0.19      0.21      0.20        28\n",
      "        1230       0.30      0.37      0.33        30\n",
      "        1240       0.62      0.23      0.33        22\n",
      "        1248       0.95      0.64      0.77        28\n",
      "        1249       0.37      0.43      0.40        23\n",
      "        1250       1.00      0.04      0.08        25\n",
      "        1251       0.00      0.00      0.00        28\n",
      "        1254       0.50      0.48      0.49        23\n",
      "        1257       0.07      0.10      0.09        29\n",
      "        1258       0.42      0.29      0.34        28\n",
      "        1259       0.43      0.65      0.52        31\n",
      "        1260       0.54      0.83      0.65        18\n",
      "        1261       0.17      0.03      0.05        36\n",
      "        1262       0.42      0.68      0.52        31\n",
      "        1263       0.57      0.48      0.52        25\n",
      "        1264       0.45      0.87      0.60        23\n",
      "        1265       0.15      0.26      0.19        27\n",
      "        1266       0.00      0.00      0.00        30\n",
      "        1267       0.17      0.12      0.14        24\n",
      "        1268       0.50      0.08      0.13        26\n",
      "        1269       0.56      0.74      0.64        31\n",
      "        1270       0.71      0.55      0.62        31\n",
      "        1271       0.67      0.21      0.32        29\n",
      "        1272       0.29      0.25      0.27        28\n",
      "        1273       0.53      0.47      0.50        38\n",
      "        1274       0.34      0.82      0.48        28\n",
      "        1275       0.73      0.37      0.49        30\n",
      "        1276       0.58      0.54      0.56        26\n",
      "        1277       0.33      0.21      0.26        24\n",
      "        1278       0.35      0.38      0.36        24\n",
      "        1279       0.21      0.61      0.31        23\n",
      "        1280       0.17      0.08      0.11        25\n",
      "        1281       0.35      0.45      0.39        29\n",
      "        1282       0.27      0.62      0.38        24\n",
      "        1283       0.52      0.89      0.66        28\n",
      "        1284       0.16      0.47      0.24        19\n",
      "        1285       0.64      0.20      0.30        35\n",
      "        1286       0.58      0.50      0.54        30\n",
      "        1287       0.18      0.10      0.13        20\n",
      "        1288       0.40      0.26      0.32        23\n",
      "        1289       0.14      0.13      0.14        23\n",
      "        1290       0.44      0.41      0.42        27\n",
      "        1291       0.55      0.22      0.32        27\n",
      "        1292       0.20      0.44      0.28        25\n",
      "        1293       0.38      0.58      0.46        26\n",
      "        1294       0.10      0.17      0.13        23\n",
      "        1295       0.52      0.58      0.55        26\n",
      "        1296       0.34      0.38      0.36        26\n",
      "        1299       0.47      0.90      0.61        30\n",
      "        1303       0.00      0.00      0.00        33\n",
      "        1304       0.71      0.57      0.63        35\n",
      "        1305       0.00      0.00      0.00        15\n",
      "        1308       0.70      0.42      0.53        33\n",
      "        1309       0.33      0.65      0.44        20\n",
      "        1310       0.21      0.55      0.30        20\n",
      "        1311       0.50      0.44      0.47        32\n",
      "        1312       0.00      0.00      0.00        37\n",
      "        1313       0.24      0.33      0.28        21\n",
      "        1314       0.33      0.23      0.27        31\n",
      "        1315       1.00      0.03      0.06        32\n",
      "        1316       0.40      0.71      0.51        28\n",
      "        1317       0.09      0.07      0.08        30\n",
      "        1318       0.53      0.69      0.60        29\n",
      "        1319       0.19      0.11      0.14        27\n",
      "        1320       0.62      0.14      0.23        36\n",
      "        1322       0.08      0.16      0.11        25\n",
      "        1326       0.12      0.15      0.13        33\n",
      "        1327       0.14      0.11      0.12        27\n",
      "        1328       0.79      0.68      0.73        34\n",
      "        1330       0.00      0.00      0.00        20\n",
      "        1331       0.18      0.07      0.10        28\n",
      "        1332       0.30      0.33      0.31        24\n",
      "        1333       0.57      0.59      0.58        27\n",
      "        1334       0.34      0.46      0.39        26\n",
      "        1336       0.00      0.00      0.00        27\n",
      "        1337       0.44      0.16      0.24        25\n",
      "        1339       0.30      0.14      0.19        22\n",
      "        1340       0.79      0.70      0.75        27\n",
      "        1341       0.58      0.68      0.62        28\n",
      "        1343       0.33      0.38      0.36        21\n",
      "        1344       0.83      0.18      0.29        28\n",
      "        1345       0.48      0.40      0.43        25\n",
      "        1346       0.33      0.12      0.18        25\n",
      "        1347       0.36      0.14      0.20        29\n",
      "        1348       0.40      0.15      0.22        27\n",
      "        1349       0.12      0.05      0.07        20\n",
      "        1350       0.30      0.55      0.39        33\n",
      "        1351       0.73      0.27      0.39        30\n",
      "        1352       1.00      0.06      0.11        35\n",
      "        1353       0.33      0.67      0.44        24\n",
      "        1354       0.26      0.69      0.38        26\n",
      "        1355       0.70      0.41      0.52        34\n",
      "        1356       0.62      0.57      0.59        28\n",
      "        1357       0.43      0.11      0.18        27\n",
      "        1358       0.61      0.58      0.60        24\n",
      "        1360       0.75      0.18      0.29        34\n",
      "        1361       1.00      0.56      0.72        32\n",
      "        1363       0.58      0.41      0.48        27\n",
      "        1364       0.78      0.78      0.78        32\n",
      "        1365       0.50      0.31      0.38        32\n",
      "        1366       0.61      0.77      0.68        26\n",
      "        1367       0.72      0.85      0.78        27\n",
      "        1368       0.76      0.58      0.66        33\n",
      "        1369       0.17      0.04      0.06        25\n",
      "        1370       0.69      0.71      0.70        28\n",
      "        1371       0.83      0.61      0.70        31\n",
      "        1373       0.67      0.39      0.49        31\n",
      "        1374       0.43      0.10      0.17        29\n",
      "        1376       0.81      0.61      0.69        28\n",
      "        1377       0.53      0.81      0.64        21\n",
      "        1378       0.69      0.72      0.71        25\n",
      "        1379       0.69      0.95      0.80        19\n",
      "        1380       0.55      0.62      0.58        29\n",
      "        1382       0.49      0.62      0.55        29\n",
      "        1383       0.47      0.66      0.55        29\n",
      "        1384       0.52      0.47      0.49        30\n",
      "        1385       0.39      0.67      0.49        24\n",
      "        1386       0.66      0.93      0.77        27\n",
      "        1387       0.52      0.45      0.48        33\n",
      "        1388       0.50      0.06      0.11        17\n",
      "        1389       0.53      0.67      0.59        15\n",
      "        1390       0.80      0.71      0.75        28\n",
      "        1391       1.00      0.17      0.29        24\n",
      "        1393       0.72      0.85      0.78        34\n",
      "        1394       0.92      0.44      0.59        25\n",
      "        1396       0.33      0.17      0.23        29\n",
      "        1397       0.42      0.56      0.48        25\n",
      "        1399       0.38      0.38      0.38        24\n",
      "        1400       0.32      0.69      0.44        29\n",
      "        1401       0.57      0.84      0.68        19\n",
      "        1402       0.31      0.18      0.23        22\n",
      "        1405       1.00      0.15      0.27        26\n",
      "        1408       0.68      0.58      0.62        26\n",
      "        1410       0.00      0.00      0.00        17\n",
      "        1412       0.54      1.00      0.70        28\n",
      "        1413       0.70      0.54      0.61        13\n",
      "        1415       0.86      0.20      0.32        30\n",
      "        1416       1.00      0.44      0.61        16\n",
      "        1417       0.44      0.43      0.44        28\n",
      "        1418       0.51      0.77      0.62        26\n",
      "        1419       0.45      0.85      0.59        20\n",
      "        1420       0.71      0.71      0.71        31\n",
      "        1421       0.40      0.13      0.20        31\n",
      "        1423       1.00      0.97      0.99        34\n",
      "        1424       0.30      0.67      0.42        24\n",
      "        1425       0.43      0.46      0.44        26\n",
      "        1426       0.70      0.75      0.72        28\n",
      "        1427       0.48      0.46      0.47        28\n",
      "        1428       0.29      0.63      0.40        19\n",
      "        1429       0.00      0.00      0.00        20\n",
      "        1431       0.29      0.41      0.34        32\n",
      "        1438       0.65      0.71      0.68        31\n",
      "        1439       0.62      0.31      0.41        26\n",
      "        1440       0.38      0.23      0.29        13\n",
      "        1441       0.26      0.16      0.20        31\n",
      "        1442       0.87      0.67      0.75        30\n",
      "        1444       1.00      0.23      0.38        26\n",
      "        1447       0.40      0.21      0.28        38\n",
      "        1448       0.50      0.40      0.44        25\n",
      "        1449       0.31      0.15      0.20        27\n",
      "        1450       0.53      0.38      0.44        24\n",
      "        1451       0.65      0.46      0.54        28\n",
      "        1452       0.35      0.58      0.44        24\n",
      "        1453       0.40      0.44      0.42        18\n",
      "        1455       0.55      0.76      0.64        21\n",
      "        1456       0.74      0.71      0.73        28\n",
      "        1457       0.58      0.78      0.67        23\n",
      "        1458       0.67      0.37      0.48        27\n",
      "        1459       0.30      0.42      0.35        26\n",
      "        1460       0.52      0.73      0.60        22\n",
      "        1461       0.88      0.20      0.33        35\n",
      "        1462       0.70      0.44      0.54        32\n",
      "        1463       1.00      0.13      0.24        15\n",
      "        1465       1.00      0.06      0.11        17\n",
      "        1467       0.92      0.52      0.67        21\n",
      "        1468       0.57      0.65      0.60        20\n",
      "        1469       0.60      0.30      0.40        30\n",
      "        1470       0.32      0.59      0.42        17\n",
      "        1471       0.62      0.80      0.70        20\n",
      "        1473       0.37      0.50      0.43        26\n",
      "        1474       0.70      0.55      0.62        29\n",
      "        1476       0.59      0.52      0.55        25\n",
      "        1477       0.28      0.68      0.39        19\n",
      "        1480       0.46      0.65      0.54        20\n",
      "        1483       0.75      0.75      0.75        20\n",
      "        1484       0.57      0.26      0.36        31\n",
      "        1485       0.30      0.30      0.30        23\n",
      "        1486       0.35      0.52      0.42        27\n",
      "        1488       0.34      0.46      0.39        26\n",
      "        1489       0.86      0.38      0.52        16\n",
      "        1490       0.67      0.10      0.17        21\n",
      "        1491       0.72      0.55      0.62        33\n",
      "        1492       0.68      0.71      0.70        21\n",
      "        1494       0.50      0.59      0.54        27\n",
      "        1495       0.32      0.35      0.33        23\n",
      "        1496       0.00      0.00      0.00        35\n",
      "        1499       0.46      0.48      0.47        27\n",
      "        1500       0.62      0.47      0.53        17\n",
      "        1502       0.39      0.41      0.40        29\n",
      "        1503       0.16      0.31      0.21        26\n",
      "        1504       0.31      0.82      0.45        22\n",
      "        1505       0.09      0.07      0.08        28\n",
      "        1506       0.83      0.42      0.56        36\n",
      "        1509       0.57      0.59      0.58        27\n",
      "        1510       0.32      0.39      0.35        18\n",
      "        1511       0.60      0.29      0.39        31\n",
      "        1512       0.50      0.36      0.42        22\n",
      "        1513       0.00      0.00      0.00        31\n",
      "        1514       0.14      0.04      0.06        25\n",
      "        1516       0.30      0.21      0.25        33\n",
      "        1518       0.18      0.78      0.30        23\n",
      "        1519       0.46      0.53      0.49        36\n",
      "        1520       1.00      0.10      0.18        30\n",
      "        1521       0.31      0.77      0.44        26\n",
      "        1522       0.62      0.58      0.60        26\n",
      "        1523       0.47      0.32      0.38        28\n",
      "        1524       0.41      0.29      0.34        31\n",
      "        1525       0.43      0.45      0.44        29\n",
      "        1526       0.11      0.32      0.17        22\n",
      "        1527       0.00      0.00      0.00        31\n",
      "        1528       0.74      0.54      0.62        26\n",
      "        1529       0.62      0.17      0.26        30\n",
      "        1531       0.55      0.21      0.30        29\n",
      "        1532       0.29      0.50      0.36        24\n",
      "        1533       0.51      0.79      0.62        28\n",
      "        1534       0.16      0.11      0.13        28\n",
      "        1535       0.40      0.57      0.47        21\n",
      "        1536       0.43      0.09      0.15        32\n",
      "        1537       0.20      0.03      0.06        31\n",
      "        1538       0.16      0.17      0.17        29\n",
      "        1539       0.25      0.03      0.05        33\n",
      "        1540       0.47      0.29      0.36        31\n",
      "        1541       0.29      0.06      0.10        32\n",
      "        1542       0.30      0.33      0.31        24\n",
      "        1545       0.82      0.86      0.84        21\n",
      "        1547       0.52      0.74      0.61        19\n",
      "        1548       0.32      0.58      0.41        26\n",
      "        1550       0.63      0.77      0.70        31\n",
      "        1551       0.27      0.10      0.14        31\n",
      "        1552       1.00      0.13      0.23        31\n",
      "        1553       0.36      0.12      0.18        34\n",
      "        1554       0.33      0.06      0.10        35\n",
      "        1555       0.29      0.13      0.18        30\n",
      "        1556       0.80      0.15      0.25        27\n",
      "        1557       0.13      0.15      0.14        20\n",
      "        1558       0.61      0.76      0.68        33\n",
      "        1559       0.36      0.21      0.26        24\n",
      "        1560       0.55      0.25      0.34        24\n",
      "        1561       0.26      0.35      0.30        31\n",
      "        1563       0.33      0.64      0.44        28\n",
      "        1564       0.40      0.29      0.33        21\n",
      "        1565       0.92      0.41      0.56        27\n",
      "        1566       0.00      0.00      0.00        34\n",
      "        1567       1.00      0.03      0.06        30\n",
      "        1568       0.00      0.00      0.00        24\n",
      "        1569       0.58      0.42      0.49        33\n",
      "        1570       0.50      0.03      0.06        32\n",
      "        1571       1.00      0.23      0.38        30\n",
      "        1572       0.30      0.50      0.37        24\n",
      "        1573       0.63      0.63      0.63        27\n",
      "        1575       0.79      0.62      0.70        24\n",
      "        1576       0.80      0.17      0.28        24\n",
      "        1577       0.85      0.55      0.67        31\n",
      "        1579       0.00      0.00      0.00        24\n",
      "        1580       1.00      0.04      0.07        28\n",
      "        1581       1.00      0.07      0.13        28\n",
      "        1582       0.43      0.69      0.53        29\n",
      "        1583       0.14      0.30      0.19        27\n",
      "        1584       0.20      0.08      0.12        24\n",
      "        1585       0.08      0.06      0.07        32\n",
      "        1586       0.15      0.24      0.18        25\n",
      "        1587       0.50      0.11      0.18        28\n",
      "        1588       0.52      0.52      0.52        23\n",
      "        1589       0.53      0.64      0.58        28\n",
      "        1590       0.76      0.76      0.76        25\n",
      "        1591       0.55      0.41      0.47        27\n",
      "        1592       0.33      0.07      0.12        27\n",
      "        1593       0.64      0.56      0.60        25\n",
      "        1594       0.44      0.62      0.52        26\n",
      "        1595       0.68      0.60      0.64        25\n",
      "        1596       1.00      0.43      0.60        28\n",
      "        1597       0.45      0.62      0.53        24\n",
      "        1598       0.87      0.71      0.78        28\n",
      "        1599       0.78      0.78      0.78        32\n",
      "        1600       0.16      0.33      0.22        18\n",
      "        1601       0.87      0.54      0.67        24\n",
      "        1602       0.78      0.83      0.81        30\n",
      "        1603       0.45      0.65      0.54        23\n",
      "        1604       0.43      0.10      0.16        30\n",
      "        1605       1.00      0.03      0.06        33\n",
      "        1606       0.18      0.08      0.11        25\n",
      "        1607       0.08      0.30      0.12        10\n",
      "        1608       0.40      0.29      0.33        28\n",
      "        1611       0.36      0.15      0.21        33\n",
      "        1612       0.25      0.04      0.07        23\n",
      "        1613       0.77      0.61      0.68        28\n",
      "        1614       0.20      0.16      0.18        25\n",
      "        1615       0.36      0.24      0.29        21\n",
      "        1616       0.45      0.54      0.49        26\n",
      "        1617       0.16      0.43      0.23        23\n",
      "        1618       0.82      0.39      0.53        36\n",
      "        1619       0.59      0.76      0.67        25\n",
      "        1620       0.19      0.32      0.24        25\n",
      "        1621       0.19      0.12      0.14        26\n",
      "        1622       0.32      0.32      0.32        28\n",
      "        1623       0.76      0.52      0.62        31\n",
      "        1624       0.53      0.40      0.45        25\n",
      "        1625       0.31      0.38      0.34        21\n",
      "        1627       0.43      0.22      0.29        27\n",
      "        1628       0.50      0.21      0.30        28\n",
      "        1629       1.00      0.03      0.06        33\n",
      "        1630       0.23      0.12      0.15        26\n",
      "        1631       0.25      0.59      0.35        27\n",
      "        1632       0.54      0.54      0.54        13\n",
      "        1633       0.00      0.00      0.00        31\n",
      "        1634       0.46      0.24      0.32        25\n",
      "        1635       0.20      0.09      0.12        23\n",
      "        1636       0.47      0.31      0.38        29\n",
      "        1638       0.41      0.21      0.28        33\n",
      "        1639       0.29      0.35      0.31        23\n",
      "        1640       0.37      0.53      0.44        32\n",
      "        1641       0.23      0.10      0.14        29\n",
      "        1642       0.31      0.36      0.33        25\n",
      "        1645       0.62      0.14      0.22        37\n",
      "        1646       0.39      0.39      0.39        23\n",
      "        1647       1.00      0.03      0.06        30\n",
      "        1648       0.42      0.65      0.51        34\n",
      "        1649       0.25      0.35      0.29        26\n",
      "        1650       0.76      0.42      0.54        31\n",
      "        1651       0.65      0.56      0.60        27\n",
      "        1652       0.50      0.67      0.57        24\n",
      "        1653       0.71      0.43      0.53        28\n",
      "        1654       0.67      0.18      0.29        22\n",
      "        1656       0.46      0.65      0.54        26\n",
      "        1657       0.00      0.00      0.00        34\n",
      "        1658       0.48      0.43      0.45        35\n",
      "        1659       0.52      0.41      0.46        34\n",
      "        1660       0.46      0.76      0.58        25\n",
      "        1661       0.20      0.26      0.23        23\n",
      "        1662       0.50      0.03      0.06        34\n",
      "        1663       0.57      0.14      0.23        28\n",
      "        1664       0.38      0.24      0.29        34\n",
      "        1665       0.21      0.17      0.19        18\n",
      "        1666       0.15      0.08      0.11        25\n",
      "        1667       0.33      0.07      0.12        27\n",
      "        1668       0.19      0.15      0.17        33\n",
      "        1669       0.57      0.72      0.64        32\n",
      "        1670       0.65      0.81      0.72        27\n",
      "        1671       0.44      0.15      0.22        27\n",
      "        1672       0.38      0.56      0.45        25\n",
      "        1673       0.36      0.32      0.34        28\n",
      "        1674       1.00      0.07      0.14        27\n",
      "        1675       0.48      0.50      0.49        32\n",
      "        1676       0.38      0.24      0.30        33\n",
      "        1677       0.85      0.35      0.50        31\n",
      "        1678       0.09      0.18      0.12        22\n",
      "        1679       0.47      0.62      0.54        24\n",
      "        1680       0.62      0.38      0.48        26\n",
      "        1681       0.17      0.21      0.18        29\n",
      "        1682       0.21      0.25      0.23        28\n",
      "        1683       0.65      0.55      0.60        31\n",
      "        1684       0.12      0.25      0.16        20\n",
      "        1685       0.45      0.40      0.43        25\n",
      "        1686       0.15      0.19      0.17        21\n",
      "        1687       0.41      0.38      0.39        24\n",
      "        1697       0.61      1.00      0.76        33\n",
      "        1698       0.91      0.87      0.89        23\n",
      "        1699       0.69      0.86      0.77        29\n",
      "        1727       0.44      0.32      0.37        22\n",
      "        1728       1.00      0.04      0.07        27\n",
      "        1746       0.57      0.14      0.23        28\n",
      "        1754       0.56      0.40      0.47        25\n",
      "        1755       0.38      0.37      0.38        27\n",
      "        1756       0.25      0.17      0.20        29\n",
      "        1757       0.43      0.36      0.39        28\n",
      "        1758       0.00      0.00      0.00        30\n",
      "        1760       0.56      0.50      0.53        28\n",
      "        1761       0.58      0.52      0.55        29\n",
      "        1762       0.95      0.91      0.93        23\n",
      "        1763       0.50      0.32      0.39        19\n",
      "        1764       0.38      0.09      0.15        32\n",
      "        1765       0.57      0.40      0.47        30\n",
      "        1768       0.29      0.73      0.41        26\n",
      "        1769       0.22      0.06      0.10        31\n",
      "        1771       0.40      0.36      0.38        28\n",
      "        1774       0.48      0.48      0.48        27\n",
      "        1775       0.22      0.19      0.20        27\n",
      "        1777       0.88      0.66      0.75        32\n",
      "        1778       0.94      0.68      0.79        22\n",
      "        1779       0.60      0.67      0.63        27\n",
      "        1780       0.40      0.50      0.44        28\n",
      "        1781       0.17      0.35      0.23        26\n",
      "        1782       0.54      0.44      0.48        32\n",
      "        1783       0.17      0.43      0.24        21\n",
      "        1784       0.20      0.17      0.19        29\n",
      "        1785       0.81      0.68      0.74        25\n",
      "        1786       0.16      0.15      0.15        34\n",
      "        1787       0.67      0.58      0.62        24\n",
      "        1788       0.33      0.59      0.42        22\n",
      "        1789       0.62      0.45      0.53        11\n",
      "        1790       0.48      0.74      0.58        27\n",
      "        1791       0.92      0.73      0.81        15\n",
      "        1792       0.88      0.23      0.36        31\n",
      "        1793       0.62      0.32      0.43        31\n",
      "        1794       0.51      0.64      0.57        28\n",
      "        1795       0.45      0.40      0.43        25\n",
      "        1796       0.50      0.22      0.30        23\n",
      "        1797       0.69      0.69      0.69        32\n",
      "        1798       0.50      0.04      0.07        27\n",
      "        1799       0.00      0.00      0.00        31\n",
      "        1800       0.43      0.75      0.55        28\n",
      "        1801       0.76      0.81      0.78        36\n",
      "        1802       0.39      0.28      0.33        32\n",
      "        1803       0.39      0.48      0.43        31\n",
      "        1804       0.28      0.80      0.41        15\n",
      "        1806       1.00      0.08      0.15        12\n",
      "        1808       0.80      0.21      0.33        19\n",
      "        1809       0.60      0.88      0.71        24\n",
      "        1810       0.44      0.50      0.47        24\n",
      "        1811       0.00      0.00      0.00        25\n",
      "        1812       0.46      0.59      0.52        22\n",
      "        1813       0.31      0.48      0.38        23\n",
      "        1815       0.19      0.33      0.24        18\n",
      "        1816       0.71      0.53      0.61        32\n",
      "        1821       0.29      0.48      0.36        21\n",
      "        1822       0.88      0.33      0.48        21\n",
      "        1824       0.57      0.13      0.21        31\n",
      "        1825       0.64      0.26      0.37        35\n",
      "        1826       0.43      0.80      0.56        25\n",
      "        1827       0.57      0.41      0.48        29\n",
      "        1828       0.29      0.14      0.19        28\n",
      "        1829       0.26      0.55      0.35        20\n",
      "        1830       0.38      0.21      0.27        29\n",
      "        1831       0.41      0.36      0.38        25\n",
      "        1832       0.25      0.08      0.12        26\n",
      "        1833       0.59      0.52      0.55        25\n",
      "        1834       0.57      0.81      0.67        26\n",
      "        1835       0.09      0.13      0.11        23\n",
      "        1836       0.32      0.21      0.25        29\n",
      "        1837       0.19      0.28      0.23        25\n",
      "        1838       0.32      0.32      0.32        25\n",
      "        1839       0.13      0.09      0.11        22\n",
      "        1840       0.27      0.77      0.40        22\n",
      "        1843       0.42      0.48      0.45        27\n",
      "        1844       0.42      0.91      0.58        23\n",
      "        1845       0.33      0.45      0.38        29\n",
      "        1846       0.60      0.09      0.15        35\n",
      "        1847       0.60      0.10      0.17        30\n",
      "        1848       0.25      0.48      0.33        27\n",
      "        1849       1.00      0.20      0.33        30\n",
      "        1851       0.29      0.25      0.27        16\n",
      "        1852       0.48      0.40      0.43        25\n",
      "        1853       0.29      0.33      0.31        24\n",
      "        1854       0.14      0.04      0.06        28\n",
      "        1855       0.45      0.19      0.27        26\n",
      "        1857       0.08      0.03      0.05        29\n",
      "        1858       0.12      0.80      0.21        20\n",
      "        1859       0.26      0.67      0.37        18\n",
      "        1860       0.38      0.11      0.17        27\n",
      "        1861       0.18      0.24      0.20        21\n",
      "        1862       0.33      0.05      0.08        21\n",
      "        1863       0.00      0.00      0.00        35\n",
      "        1864       0.45      0.70      0.55        20\n",
      "        1865       0.33      0.19      0.24        26\n",
      "        1866       0.00      0.00      0.00        27\n",
      "        1867       0.00      0.00      0.00        22\n",
      "        1868       0.30      0.12      0.18        24\n",
      "        1869       1.00      0.03      0.06        32\n",
      "        1870       0.49      0.66      0.56        29\n",
      "        1871       0.76      0.73      0.74        22\n",
      "        1872       0.42      0.43      0.43        23\n",
      "        1873       0.40      0.32      0.36        25\n",
      "        1874       0.00      0.00      0.00        25\n",
      "        1875       0.33      0.20      0.25        25\n",
      "        1876       0.54      0.91      0.68        23\n",
      "        1877       0.42      0.55      0.48        20\n",
      "        1878       0.52      0.59      0.55        22\n",
      "        1879       0.49      0.76      0.59        29\n",
      "        1881       0.54      0.83      0.66        23\n",
      "        1883       0.43      0.67      0.52        27\n",
      "        1884       0.31      0.64      0.42        28\n",
      "        1886       0.24      0.52      0.33        33\n",
      "        1888       0.34      0.59      0.43        22\n",
      "        1889       0.52      0.53      0.52        30\n",
      "        1890       0.58      0.71      0.64        35\n",
      "        1891       0.63      0.55      0.59        31\n",
      "        1893       0.05      0.04      0.05        25\n",
      "        1894       0.69      0.72      0.71        25\n",
      "        1895       0.25      0.11      0.15        27\n",
      "        1896       0.48      0.57      0.52        28\n",
      "        1898       0.66      0.84      0.74        25\n",
      "        1899       0.55      0.71      0.62        24\n",
      "        1900       0.47      0.85      0.60        26\n",
      "        1901       0.16      0.54      0.25        26\n",
      "        1902       0.93      0.54      0.68        26\n",
      "        1903       0.83      0.30      0.44        33\n",
      "        1904       0.77      0.31      0.44        32\n",
      "        1905       0.61      0.61      0.61        28\n",
      "        1909       0.39      0.35      0.37        26\n",
      "        1910       0.55      0.63      0.59        27\n",
      "        1911       0.30      0.35      0.32        26\n",
      "        1912       0.75      0.12      0.20        26\n",
      "        1913       0.40      0.77      0.53        26\n",
      "        1915       0.77      0.68      0.72        25\n",
      "        1916       0.76      0.79      0.77        28\n",
      "        1917       0.44      0.16      0.24        25\n",
      "        1918       0.58      0.88      0.70        24\n",
      "        1919       0.95      0.59      0.73        32\n",
      "        1920       0.52      0.88      0.66        25\n",
      "        1921       0.41      0.68      0.52        25\n",
      "        1922       0.51      1.00      0.68        21\n",
      "        1923       0.62      0.77      0.69        30\n",
      "        1924       0.63      0.50      0.56        24\n",
      "        1925       0.42      0.12      0.19        40\n",
      "        1926       0.70      0.72      0.71        29\n",
      "        1929       0.73      0.32      0.45        34\n",
      "        1930       0.40      0.50      0.44        20\n",
      "        1931       0.57      0.59      0.58        27\n",
      "        1932       0.30      0.10      0.15        30\n",
      "        1933       0.48      0.52      0.50        23\n",
      "        1934       0.27      0.21      0.24        19\n",
      "        1935       0.25      0.17      0.20        24\n",
      "        1936       0.58      0.76      0.66        33\n",
      "        1937       0.21      0.24      0.22        17\n",
      "        1938       0.00      0.00      0.00        23\n",
      "        1939       0.31      0.44      0.36        18\n",
      "        1940       1.00      0.08      0.14        13\n",
      "        1941       0.27      0.80      0.40        20\n",
      "        1942       0.25      0.31      0.28        26\n",
      "        1943       0.31      0.27      0.29        33\n",
      "        1944       0.00      0.00      0.00        25\n",
      "        1945       0.32      0.81      0.46        26\n",
      "        1946       0.11      0.19      0.14        27\n",
      "        1947       0.50      0.08      0.13        26\n",
      "        1948       0.25      0.04      0.07        25\n",
      "        1949       0.31      0.15      0.21        26\n",
      "        1950       0.63      0.61      0.62        31\n",
      "        1951       0.50      0.62      0.56        24\n",
      "        1952       0.90      0.27      0.42        33\n",
      "        1953       0.46      0.59      0.52        27\n",
      "        1954       0.41      0.39      0.40        28\n",
      "        1955       0.40      0.21      0.27        29\n",
      "        1956       0.46      0.24      0.32        25\n",
      "        1957       0.26      0.67      0.37        27\n",
      "        1958       0.26      0.40      0.32        25\n",
      "        1959       0.30      0.33      0.32        27\n",
      "        1960       0.20      0.04      0.07        25\n",
      "        1961       0.36      0.57      0.44        21\n",
      "        1962       0.56      0.26      0.36        34\n",
      "        1963       0.60      0.81      0.69        32\n",
      "        1964       0.38      0.34      0.36        29\n",
      "        1965       0.58      0.24      0.34        29\n",
      "        1966       0.37      0.26      0.30        27\n",
      "        1967       0.48      0.38      0.43        26\n",
      "        1970       0.32      0.62      0.42        29\n",
      "        1972       0.67      0.24      0.35        25\n",
      "        1973       0.22      0.68      0.34        19\n",
      "        1974       0.47      0.28      0.35        25\n",
      "        1975       0.43      0.31      0.36        29\n",
      "        1976       0.70      0.67      0.68        21\n",
      "        1977       0.72      0.62      0.67        29\n",
      "        1978       0.62      0.18      0.28        28\n",
      "        1979       0.00      0.00      0.00        31\n",
      "        1980       0.30      0.65      0.41        23\n",
      "        1981       0.56      0.52      0.54        27\n",
      "        1982       0.63      0.44      0.52        27\n",
      "        1983       0.34      0.64      0.44        25\n",
      "        1984       0.53      0.32      0.40        25\n",
      "        1985       0.78      0.60      0.68        30\n",
      "        1986       0.42      0.42      0.42        26\n",
      "        1987       0.45      0.32      0.38        28\n",
      "        1988       0.29      0.35      0.32        26\n",
      "        1992       0.47      0.76      0.58        21\n",
      "        1994       0.69      0.92      0.79        26\n",
      "        1995       0.70      0.82      0.75        28\n",
      "        1996       1.00      0.12      0.22        16\n",
      "        1999       0.54      0.52      0.53        25\n",
      "        2001       0.58      0.69      0.63        26\n",
      "        2003       0.56      0.56      0.56        27\n",
      "        2006       0.52      0.96      0.67        28\n",
      "        2007       0.80      0.14      0.24        28\n",
      "        2008       0.27      0.19      0.23        31\n",
      "        2009       0.04      0.04      0.04        23\n",
      "        2010       0.32      0.41      0.36        29\n",
      "        2011       0.00      0.00      0.00        30\n",
      "        2012       0.12      0.04      0.06        27\n",
      "        2013       0.26      0.48      0.34        23\n",
      "        2015       0.90      0.31      0.46        29\n",
      "        2016       1.00      0.65      0.79        23\n",
      "        2017       0.29      0.48      0.36        21\n",
      "        2018       0.64      0.42      0.51        33\n",
      "        2021       0.75      0.13      0.22        23\n",
      "        2024       0.54      0.84      0.66        25\n",
      "        2026       0.60      0.19      0.29        31\n",
      "        2035       0.45      0.88      0.59        34\n",
      "        2038       0.38      0.21      0.27        28\n",
      "        2042       0.27      0.20      0.23        20\n",
      "        2043       0.09      0.29      0.14        28\n",
      "        2044       1.00      0.57      0.73        21\n",
      "        2046       0.54      0.32      0.40        22\n",
      "        2051       0.80      0.20      0.31        41\n",
      "        2052       0.13      0.27      0.18        22\n",
      "        2054       0.36      0.33      0.35        27\n",
      "        2055       0.59      0.80      0.68        20\n",
      "        2056       0.52      0.35      0.42        34\n",
      "        2057       0.67      0.13      0.22        31\n",
      "        2058       0.20      0.38      0.26        24\n",
      "        2059       0.35      0.68      0.46        28\n",
      "        2060       0.21      0.15      0.18        26\n",
      "        2061       0.42      0.73      0.54        30\n",
      "        2062       0.57      0.67      0.62        24\n",
      "        2063       0.53      0.80      0.64        20\n",
      "        2064       0.12      0.71      0.21        24\n",
      "        2067       0.75      0.38      0.50        32\n",
      "        2070       0.36      0.40      0.38        25\n",
      "        2071       0.62      0.81      0.70        31\n",
      "        2072       0.12      0.12      0.12        32\n",
      "        2078       0.29      0.48      0.36        33\n",
      "        2079       0.45      0.33      0.38        27\n",
      "        2080       0.57      0.71      0.63        28\n",
      "        2081       0.50      0.55      0.52        22\n",
      "        2084       0.29      0.56      0.38        27\n",
      "        2085       0.48      0.50      0.49        26\n",
      "        2086       0.62      0.23      0.33        22\n",
      "        2087       0.36      0.39      0.37        23\n",
      "        2088       0.32      0.75      0.45        24\n",
      "        2089       0.23      0.22      0.22        23\n",
      "        2091       0.31      0.35      0.33        23\n",
      "        2092       0.19      0.22      0.20        23\n",
      "        2097       0.20      0.03      0.05        38\n",
      "        2098       0.27      0.57      0.36        28\n",
      "        2099       0.14      0.17      0.15        30\n",
      "        2101       1.00      0.38      0.56        13\n",
      "        2102       0.47      0.62      0.53        26\n",
      "        2103       0.65      0.65      0.65        26\n",
      "        2107       0.34      0.66      0.45        29\n",
      "        2108       0.14      0.12      0.13        24\n",
      "        2113       0.29      0.40      0.34        30\n",
      "        2114       0.24      0.45      0.31        31\n",
      "        2115       0.17      0.07      0.10        28\n",
      "        2116       0.52      0.85      0.65        27\n",
      "        2117       0.41      0.93      0.57        30\n",
      "        2118       0.27      0.35      0.30        23\n",
      "        2119       0.59      0.59      0.59        29\n",
      "        2122       0.22      0.10      0.13        21\n",
      "        2123       0.70      0.58      0.64        24\n",
      "        2124       0.54      0.25      0.34        28\n",
      "        2125       0.21      0.23      0.22        31\n",
      "        2126       0.61      0.57      0.59        30\n",
      "        2127       0.73      0.50      0.59        16\n",
      "        2128       0.62      0.67      0.64        24\n",
      "        2129       0.50      0.88      0.64        17\n",
      "        2130       0.80      0.52      0.63        23\n",
      "        2132       0.34      0.50      0.41        28\n",
      "        2134       0.42      0.63      0.51        27\n",
      "        2136       0.18      0.17      0.18        23\n",
      "        2137       0.16      0.29      0.21        24\n",
      "        2140       0.45      0.42      0.43        31\n",
      "        2141       0.50      0.17      0.26        29\n",
      "        2142       0.38      0.09      0.15        32\n",
      "        2146       0.65      0.65      0.65        26\n",
      "        2147       0.32      0.50      0.39        24\n",
      "        2149       0.57      0.28      0.37        29\n",
      "        2151       0.44      0.32      0.37        25\n",
      "        2153       0.65      0.79      0.71        19\n",
      "        2154       0.78      0.88      0.83        33\n",
      "        2159       0.59      0.71      0.65        31\n",
      "        2160       0.32      0.79      0.46        29\n",
      "        2168       0.64      0.23      0.34        30\n",
      "        2169       0.68      0.43      0.53        35\n",
      "        2170       0.75      0.15      0.25        20\n",
      "        2171       0.48      0.44      0.46        34\n",
      "        2172       0.49      0.71      0.58        34\n",
      "        2173       0.36      0.83      0.50        30\n",
      "        2174       0.54      0.70      0.61        27\n",
      "        2175       0.25      0.33      0.29        27\n",
      "        2176       0.16      0.53      0.24        19\n",
      "        2177       0.36      0.64      0.46        25\n",
      "        2178       0.24      0.45      0.32        22\n",
      "        2179       0.50      0.65      0.57        23\n",
      "        2180       0.36      0.55      0.44        22\n",
      "        2182       0.30      0.74      0.43        23\n",
      "        2183       1.00      0.06      0.11        35\n",
      "        2184       0.35      0.44      0.39        25\n",
      "        2185       0.78      0.54      0.64        26\n",
      "        2186       0.40      0.34      0.37        29\n",
      "        2187       0.48      0.34      0.40        29\n",
      "        2188       0.35      0.44      0.39        27\n",
      "        2189       0.67      0.34      0.45        29\n",
      "        2190       0.38      0.31      0.34        26\n",
      "        2192       0.41      0.38      0.39        24\n",
      "        2193       0.45      0.37      0.41        35\n",
      "        2195       0.24      0.15      0.19        33\n",
      "        2196       0.35      0.39      0.37        28\n",
      "        2198       0.26      0.32      0.29        19\n",
      "        2200       0.18      0.10      0.12        21\n",
      "        2201       0.31      0.57      0.41        28\n",
      "        2202       0.33      0.42      0.37        26\n",
      "        2203       0.56      0.17      0.26        29\n",
      "        2205       0.28      0.89      0.43        18\n",
      "        2206       0.16      0.53      0.25        15\n",
      "        2207       1.00      0.09      0.16        23\n",
      "        2211       0.60      0.56      0.58        27\n",
      "        2212       0.18      0.07      0.11        27\n",
      "        2213       0.33      0.12      0.17        34\n",
      "        2214       0.15      0.14      0.15        28\n",
      "        2216       0.50      0.10      0.16        31\n",
      "        2224       0.53      0.70      0.60        27\n",
      "        2225       0.50      0.58      0.54        26\n",
      "        2230       0.62      0.37      0.47        27\n",
      "        2231       0.25      0.28      0.26        18\n",
      "        2243       0.42      0.42      0.42        24\n",
      "        2279       0.28      0.59      0.38        34\n",
      "        2280       0.67      0.07      0.13        28\n",
      "        2286       0.56      0.36      0.44        39\n",
      "        2287       0.38      0.36      0.37        28\n",
      "        2288       0.08      0.10      0.09        21\n",
      "        2289       0.37      0.53      0.43        19\n",
      "        2290       0.50      0.26      0.35        34\n",
      "        2291       0.00      0.00      0.00        21\n",
      "        2292       0.65      0.67      0.66        30\n",
      "        2295       0.48      0.53      0.50        19\n",
      "        2296       0.22      0.90      0.36        21\n",
      "        2297       0.35      0.80      0.48        20\n",
      "        2298       0.18      0.45      0.26        31\n",
      "        2301       0.00      0.00      0.00        22\n",
      "        2306       0.45      0.17      0.25        29\n",
      "        2308       0.18      0.32      0.23        22\n",
      "        2309       0.07      0.35      0.12        20\n",
      "        2310       0.55      0.34      0.42        32\n",
      "        2311       0.44      0.80      0.57        20\n",
      "        2312       0.37      0.59      0.45        17\n",
      "        2313       0.39      0.48      0.43        29\n",
      "        2314       0.58      0.26      0.36        27\n",
      "        2315       0.44      0.27      0.33        30\n",
      "        2316       0.80      0.71      0.75        28\n",
      "        2321       0.24      0.35      0.28        26\n",
      "        2324       0.56      0.24      0.33        21\n",
      "        2325       0.05      0.04      0.04        27\n",
      "        2326       0.31      0.17      0.22        30\n",
      "        2333       1.00      0.14      0.24        36\n",
      "        2334       0.22      0.61      0.33        23\n",
      "        2335       0.50      0.61      0.55        23\n",
      "        2336       0.44      0.57      0.50        28\n",
      "        2337       0.64      0.75      0.69        24\n",
      "        2338       0.55      0.66      0.60        32\n",
      "        2339       0.35      0.39      0.37        23\n",
      "        2340       0.44      0.81      0.57        31\n",
      "        2343       0.83      0.54      0.65        28\n",
      "        2346       0.53      0.90      0.67        10\n",
      "        2347       0.91      0.36      0.51        28\n",
      "        2348       0.34      0.30      0.32        33\n",
      "        2349       0.72      0.78      0.75        27\n",
      "        2350       0.23      0.68      0.35        25\n",
      "        2351       0.83      0.38      0.53        26\n",
      "        2352       0.40      0.40      0.40        20\n",
      "        2353       0.36      0.25      0.30        32\n",
      "        2354       0.40      0.06      0.11        31\n",
      "        2355       0.18      0.47      0.26        17\n",
      "        2356       0.27      0.13      0.18        23\n",
      "        2357       0.71      0.20      0.31        25\n",
      "        2358       1.00      0.24      0.38        17\n",
      "        2360       0.10      0.19      0.13        16\n",
      "        2363       1.00      0.67      0.80        21\n",
      "        2364       0.78      0.25      0.38        28\n",
      "        2365       1.00      0.12      0.21        34\n",
      "        2366       0.80      0.26      0.39        31\n",
      "        2367       1.00      0.09      0.17        33\n",
      "        2368       0.88      0.28      0.42        25\n",
      "        2369       0.58      0.73      0.65        30\n",
      "        2370       1.00      0.03      0.06        30\n",
      "        2371       0.38      0.68      0.49        22\n",
      "        2372       0.81      0.89      0.85        28\n",
      "        2373       0.82      0.54      0.65        26\n",
      "        2377       1.00      0.36      0.53        33\n",
      "        2379       0.88      0.81      0.85        27\n",
      "        2381       0.55      0.52      0.54        21\n",
      "        2383       0.39      0.46      0.42        24\n",
      "        2385       0.83      0.59      0.69        32\n",
      "        2386       0.21      0.75      0.33        28\n",
      "        2387       0.90      0.36      0.51        25\n",
      "        2388       0.54      0.67      0.60        21\n",
      "        2389       0.34      0.67      0.45        24\n",
      "        2390       0.69      0.65      0.67        34\n",
      "        2392       0.72      0.64      0.68        33\n",
      "        2393       0.46      0.48      0.47        27\n",
      "        2394       0.50      0.15      0.23        27\n",
      "        2395       0.40      0.26      0.32        23\n",
      "        2396       0.21      0.45      0.29        22\n",
      "        2397       0.33      0.05      0.08        21\n",
      "        2398       0.45      0.31      0.37        29\n",
      "        2399       0.27      0.41      0.33        39\n",
      "        2400       0.12      0.03      0.05        31\n",
      "        2401       0.32      0.44      0.38        27\n",
      "        2402       0.44      0.48      0.46        25\n",
      "        2403       0.88      0.29      0.44        24\n",
      "        2404       0.39      0.47      0.42        30\n",
      "        2405       0.50      0.21      0.30        28\n",
      "        2531       0.33      0.25      0.29        24\n",
      "        2532       0.39      0.32      0.35        28\n",
      "        2533       0.21      0.17      0.19        29\n",
      "        2534       0.29      0.37      0.33        27\n",
      "        2535       0.71      0.29      0.42        34\n",
      "        2537       0.00      0.00      0.00        19\n",
      "        2538       0.00      0.00      0.00        26\n",
      "        2539       0.00      0.00      0.00        20\n",
      "        2540       0.54      0.32      0.40        22\n",
      "        2638       0.52      0.42      0.46        31\n",
      "        2639       0.16      0.22      0.18        27\n",
      "        2640       0.19      0.10      0.13        30\n",
      "        2641       0.30      0.81      0.44        21\n",
      "        2642       0.10      0.17      0.12        18\n",
      "        2643       0.33      0.37      0.35        30\n",
      "        2644       0.32      0.38      0.34        32\n",
      "        2645       0.54      0.32      0.40        22\n",
      "        2652       0.62      0.64      0.63        28\n",
      "        2653       0.23      0.35      0.28        17\n",
      "        2654       0.47      0.39      0.43        23\n",
      "        2664       0.25      0.25      0.25        28\n",
      "        2665       0.43      0.12      0.19        24\n",
      "        2666       0.14      0.41      0.21        17\n",
      "        2667       0.08      0.12      0.10        25\n",
      "        2781       0.00      0.00      0.00        27\n",
      "        2782       0.15      0.32      0.20        19\n",
      "        2783       0.33      0.11      0.16        28\n",
      "        2784       0.25      0.23      0.24        30\n",
      "        2785       0.27      0.12      0.17        25\n",
      "        2786       0.23      0.12      0.15        26\n",
      "        2787       0.38      0.31      0.34        26\n",
      "        2788       0.53      0.86      0.65        21\n",
      "        2789       0.20      0.04      0.07        25\n",
      "        2790       0.15      0.26      0.19        19\n",
      "        2791       0.00      0.00      0.00        25\n",
      "        2792       0.72      0.54      0.62        24\n",
      "        2793       0.50      0.12      0.19        25\n",
      "        2804       0.00      0.00      0.00        13\n",
      "        2808       0.43      0.29      0.35        31\n",
      "        2809       0.11      0.10      0.10        21\n",
      "        2810       0.53      0.66      0.59        35\n",
      "        2811       0.37      0.54      0.43        28\n",
      "        2813       0.61      0.69      0.65        32\n",
      "        2814       0.25      0.48      0.33        25\n",
      "        2815       0.24      0.19      0.21        32\n",
      "        2818       0.49      0.62      0.55        29\n",
      "        2819       0.80      0.15      0.26        26\n",
      "        2820       0.44      1.00      0.61        19\n",
      "        2821       0.68      0.81      0.74        26\n",
      "        2826       0.40      0.66      0.49        29\n",
      "        2828       0.51      0.93      0.66        29\n",
      "        2830       0.62      0.72      0.67        29\n",
      "        2831       0.38      0.33      0.35        33\n",
      "        2833       0.62      0.36      0.46        22\n",
      "        2835       0.21      0.12      0.15        26\n",
      "        2836       0.26      0.30      0.28        27\n",
      "        2837       0.35      0.44      0.39        18\n",
      "        2838       0.36      0.50      0.42        26\n",
      "        2839       0.61      0.42      0.50        26\n",
      "        2842       0.20      0.03      0.06        29\n",
      "        2843       0.17      0.81      0.29        16\n",
      "        2844       0.17      0.44      0.24        25\n",
      "        2845       0.54      0.70      0.61        20\n",
      "        2847       0.29      0.59      0.39        27\n",
      "        2848       0.60      0.20      0.30        30\n",
      "        2849       0.15      0.73      0.25        15\n",
      "        2850       0.17      0.54      0.26        24\n",
      "        2851       0.33      0.78      0.47        18\n",
      "        2852       0.59      0.93      0.72        29\n",
      "        2853       0.28      0.43      0.34        23\n",
      "        2854       0.21      0.28      0.24        29\n",
      "        2855       0.08      0.05      0.06        20\n",
      "        2856       0.25      0.18      0.21        28\n",
      "        2858       1.00      0.04      0.07        26\n",
      "        2861       1.00      0.15      0.26        27\n",
      "        2862       0.61      0.38      0.47        29\n",
      "        2867       0.58      0.56      0.57        27\n",
      "        2868       0.45      0.79      0.57        28\n",
      "        2869       0.12      0.04      0.06        26\n",
      "        2885       0.50      0.06      0.11        34\n",
      "        2887       0.41      0.47      0.44        30\n",
      "        2889       0.22      0.52      0.31        27\n",
      "        2895       0.34      0.46      0.39        26\n",
      "        2896       0.47      0.21      0.29        33\n",
      "        2897       0.24      0.29      0.26        24\n",
      "        2898       0.19      0.22      0.21        18\n",
      "        2899       0.32      0.68      0.43        22\n",
      "        2900       0.69      0.33      0.45        27\n",
      "        2901       0.70      0.25      0.37        28\n",
      "        2903       0.71      0.41      0.52        29\n",
      "        2904       0.05      0.04      0.04        24\n",
      "        2905       0.48      0.30      0.37        37\n",
      "        2906       0.52      0.47      0.49        32\n",
      "        2907       0.61      0.50      0.55        28\n",
      "        2909       0.60      0.38      0.46        24\n",
      "        2910       0.45      0.62      0.53        32\n",
      "        2911       0.21      0.23      0.22        26\n",
      "        2912       0.96      0.96      0.96        25\n",
      "        2913       0.39      0.32      0.35        28\n",
      "        2914       0.25      0.08      0.12        26\n",
      "        2915       0.67      0.14      0.23        29\n",
      "        2917       0.89      0.63      0.74        27\n",
      "        2918       0.95      0.91      0.93        22\n",
      "        2919       0.19      0.11      0.14        27\n",
      "        2920       0.71      0.22      0.33        23\n",
      "        2921       0.82      0.48      0.61        29\n",
      "        2922       0.31      0.48      0.38        29\n",
      "        2923       0.71      0.52      0.60        29\n",
      "        2924       0.38      0.48      0.43        27\n",
      "        2925       0.46      0.53      0.49        32\n",
      "        2926       0.69      0.67      0.68        27\n",
      "        2927       0.36      0.63      0.46        27\n",
      "        2928       0.68      0.87      0.76        31\n",
      "        2929       0.26      0.35      0.30        26\n",
      "        2930       0.48      0.50      0.49        24\n",
      "        2931       0.18      0.67      0.28        21\n",
      "        6053       0.17      0.59      0.27        22\n",
      "        6054       0.33      0.17      0.23        29\n",
      "        6055       0.56      0.93      0.69        27\n",
      "        6056       0.50      0.47      0.48        32\n",
      "        6057       0.23      0.31      0.26        29\n",
      "        6058       0.62      0.69      0.66        29\n",
      "        6059       0.23      0.65      0.34        31\n",
      "        6060       0.55      0.17      0.26        35\n",
      "        6061       0.36      0.14      0.20        29\n",
      "        6064       0.46      0.82      0.59        22\n",
      "        6065       0.44      0.14      0.21        29\n",
      "        6067       0.41      0.43      0.42        30\n",
      "        6068       0.50      0.18      0.26        34\n",
      "        6069       0.45      0.17      0.25        29\n",
      "        6070       0.39      0.50      0.44        26\n",
      "        6072       0.43      0.57      0.49        23\n",
      "        6074       0.55      0.58      0.56        31\n",
      "        6075       0.47      0.48      0.47        29\n",
      "        6076       0.59      0.53      0.56        30\n",
      "        6077       0.55      0.67      0.60        33\n",
      "        6078       1.00      0.07      0.13        28\n",
      "        6079       0.06      0.04      0.05        24\n",
      "        6080       0.17      0.11      0.13        27\n",
      "        6081       0.27      0.27      0.27        26\n",
      "        6082       0.17      0.35      0.23        20\n",
      "        6083       0.28      0.31      0.29        26\n",
      "        6084       0.17      0.03      0.06        29\n",
      "        6085       0.35      0.62      0.45        24\n",
      "        6086       1.00      0.21      0.34        29\n",
      "        6087       0.27      0.15      0.19        27\n",
      "        6088       0.43      0.52      0.47        25\n",
      "        6089       0.86      0.70      0.78        27\n",
      "        6090       0.79      0.79      0.79        29\n",
      "        6091       0.54      0.80      0.65        25\n",
      "        6093       0.67      0.56      0.61        32\n",
      "        6094       1.00      0.63      0.78        30\n",
      "        6095       0.91      0.50      0.65        40\n",
      "        6096       0.10      0.14      0.12        22\n",
      "        6098       0.55      0.46      0.50        24\n",
      "        6099       0.36      0.36      0.36        28\n",
      "        6100       0.49      0.70      0.58        27\n",
      "        6102       0.28      0.50      0.36        28\n",
      "        6103       0.52      0.46      0.49        26\n",
      "        6104       0.37      0.73      0.49        26\n",
      "        6108       0.26      0.82      0.40        22\n",
      "        6109       0.18      0.22      0.20        23\n",
      "        6110       0.28      0.36      0.31        28\n",
      "        6112       0.53      0.78      0.63        32\n",
      "        6114       0.47      0.32      0.38        28\n",
      "        6115       0.33      0.64      0.44        25\n",
      "        6116       0.77      0.95      0.85        21\n",
      "        6121       0.39      0.57      0.46        30\n",
      "        6122       0.44      0.63      0.52        19\n",
      "        6123       0.57      0.62      0.59        34\n",
      "        6217       0.97      0.76      0.85        37\n",
      "        6218       0.75      0.15      0.25        20\n",
      "        6219       0.35      0.32      0.33        28\n",
      "        6220       0.32      0.27      0.29        26\n",
      "        6221       0.00      0.00      0.00        33\n",
      "        6223       0.87      0.89      0.88        38\n",
      "        6224       0.52      0.58      0.55        26\n",
      "        6225       0.00      0.00      0.00        23\n",
      "        6227       0.48      0.45      0.47        22\n",
      "        6229       0.33      0.18      0.24        22\n",
      "        6231       0.79      0.79      0.79        33\n",
      "        6232       0.00      0.00      0.00        27\n",
      "        6233       0.75      0.24      0.36        25\n",
      "        6234       0.50      0.26      0.34        31\n",
      "        6235       0.00      0.00      0.00        31\n",
      "        6236       0.50      0.50      0.50        26\n",
      "        6237       0.87      0.39      0.54        33\n",
      "        6238       0.32      0.73      0.45        26\n",
      "        6239       0.45      0.33      0.38        27\n",
      "        6240       0.29      0.38      0.33        21\n",
      "        6241       1.00      0.12      0.22        24\n",
      "        6242       0.80      0.62      0.70        26\n",
      "        6243       0.41      0.92      0.56        26\n",
      "        6245       0.44      0.50      0.47        28\n",
      "        6246       0.94      0.44      0.60        34\n",
      "        6248       0.41      0.60      0.49        30\n",
      "        6252       0.57      1.00      0.72        26\n",
      "        6253       0.86      0.86      0.86        29\n",
      "        6255       0.59      0.40      0.48        25\n",
      "        6256       0.75      0.17      0.27        18\n",
      "        6257       0.43      0.27      0.33        33\n",
      "        6258       0.35      0.62      0.44        26\n",
      "        6259       0.40      0.72      0.51        32\n",
      "        6262       0.41      0.48      0.44        25\n",
      "        6264       0.95      0.80      0.87        25\n",
      "        6265       0.74      0.89      0.81        19\n",
      "        6267       0.50      0.24      0.33        29\n",
      "        6268       0.79      0.52      0.62        29\n",
      "        6269       0.67      0.34      0.45        29\n",
      "        6270       0.35      0.73      0.47        30\n",
      "        6271       0.62      0.91      0.73        32\n",
      "        6272       0.30      0.43      0.36        23\n",
      "        6273       0.48      0.62      0.54        26\n",
      "        6274       0.56      0.23      0.32        22\n",
      "        6275       0.59      0.50      0.54        20\n",
      "        6276       0.62      0.58      0.60        31\n",
      "        6277       0.89      0.36      0.52        22\n",
      "        6279       0.53      0.48      0.50        21\n",
      "        6280       0.30      0.68      0.41        19\n",
      "        6281       0.12      0.12      0.12        24\n",
      "        6282       0.28      0.19      0.22        27\n",
      "        6283       0.93      0.46      0.62        28\n",
      "        6284       0.52      0.39      0.45        28\n",
      "        6285       0.41      0.32      0.36        22\n",
      "        6286       0.59      0.89      0.71        27\n",
      "        6287       0.51      0.67      0.58        30\n",
      "        6288       0.62      0.74      0.68        27\n",
      "        6289       0.68      0.48      0.57        27\n",
      "        6290       0.55      0.60      0.57        30\n",
      "        6291       0.29      0.20      0.24        25\n",
      "        6292       0.65      0.39      0.49        28\n",
      "        6293       0.60      0.56      0.58        32\n",
      "        6294       0.33      0.64      0.44        28\n",
      "        6295       0.48      0.85      0.61        26\n",
      "        6296       0.81      0.55      0.65        31\n",
      "        6297       0.57      0.62      0.59        21\n",
      "        6298       0.92      0.85      0.88        26\n",
      "        6299       0.28      0.74      0.40        23\n",
      "        6303       0.00      0.00      0.00        25\n",
      "        6305       0.77      0.34      0.48        29\n",
      "        6306       0.61      0.31      0.41        36\n",
      "        6307       0.33      0.07      0.12        28\n",
      "        6308       0.20      0.07      0.11        28\n",
      "        6312       0.40      0.19      0.26        21\n",
      "        6313       0.65      0.33      0.44        33\n",
      "        6315       0.79      0.82      0.81        28\n",
      "        6316       0.83      0.79      0.81        19\n",
      "        6317       0.55      0.60      0.57        20\n",
      "        6319       0.64      0.30      0.41        30\n",
      "        6320       0.67      0.69      0.68        29\n",
      "        6321       0.29      0.65      0.40        23\n",
      "        6333       0.53      0.53      0.53        32\n",
      "        6335       0.29      0.27      0.28        22\n",
      "        6336       0.75      0.62      0.68        29\n",
      "        6338       0.28      0.19      0.22        27\n",
      "        6339       0.40      0.88      0.55        24\n",
      "        6343       0.36      0.67      0.46        24\n",
      "        6345       0.44      0.35      0.39        20\n",
      "        6346       0.17      0.54      0.26        24\n",
      "        6348       0.70      0.26      0.38        27\n",
      "        6350       0.27      0.62      0.38        29\n",
      "        6352       0.30      0.56      0.39        34\n",
      "        6353       0.25      0.80      0.38        30\n",
      "        6355       0.27      0.18      0.22        22\n",
      "        6356       0.67      0.79      0.72        33\n",
      "        6357       0.69      0.77      0.73        31\n",
      "        6358       0.24      0.78      0.37        27\n",
      "        6359       0.39      0.48      0.43        25\n",
      "        6360       0.77      0.61      0.68        33\n",
      "        6361       0.19      0.71      0.30        24\n",
      "        6362       0.91      0.88      0.89        24\n",
      "        6365       0.29      0.32      0.31        28\n",
      "        6367       0.00      0.00      0.00        20\n",
      "        6368       1.00      0.87      0.93        23\n",
      "        6370       0.60      0.25      0.35        24\n",
      "        6371       0.40      0.15      0.22        13\n",
      "        6372       0.38      0.50      0.43        28\n",
      "        6373       0.47      0.61      0.53        28\n",
      "        6374       0.67      0.24      0.35        17\n",
      "        6375       0.43      0.18      0.26        33\n",
      "        6377       0.57      0.41      0.48        29\n",
      "        6380       0.85      0.88      0.86        25\n",
      "        6381       0.15      0.09      0.11        22\n",
      "        6382       0.75      0.12      0.21        24\n",
      "        6386       0.60      0.68      0.64        31\n",
      "        6387       0.40      0.42      0.41        24\n",
      "        6388       0.39      0.35      0.37        20\n",
      "        6389       0.25      0.12      0.16        33\n",
      "        6391       0.34      0.85      0.48        26\n",
      "        6392       0.33      0.72      0.45        25\n",
      "        6393       0.89      0.67      0.76        24\n",
      "        6394       0.65      0.96      0.78        27\n",
      "        6396       0.00      0.00      0.00        26\n",
      "        6397       0.36      0.15      0.22        26\n",
      "        6398       0.32      0.24      0.27        25\n",
      "        6399       0.95      0.70      0.81        27\n",
      "        6402       0.53      0.30      0.38        27\n",
      "        6404       0.00      0.00      0.00        28\n",
      "        6407       0.67      0.20      0.31        20\n",
      "        6408       0.45      0.39      0.42        23\n",
      "        6410       0.36      0.57      0.44        28\n",
      "        6411       0.18      0.43      0.26        21\n",
      "        6412       1.00      0.04      0.07        27\n",
      "        6415       0.34      0.31      0.33        32\n",
      "        6416       0.55      0.21      0.31        28\n",
      "        6420       0.60      0.62      0.61        29\n",
      "        6422       0.96      0.92      0.94        25\n",
      "        6423       0.32      0.41      0.36        22\n",
      "        6424       0.46      0.75      0.57        28\n",
      "        6426       0.26      0.25      0.26        24\n",
      "        6427       0.19      0.46      0.27        26\n",
      "        6428       0.27      0.75      0.39        20\n",
      "        6429       0.10      0.04      0.06        23\n",
      "        6430       0.53      0.52      0.52        31\n",
      "        6431       0.69      0.49      0.57        37\n",
      "        6432       0.62      0.52      0.56        31\n",
      "        6434       0.82      0.48      0.61        29\n",
      "        6435       0.50      0.80      0.62        25\n",
      "        6436       0.36      0.35      0.36        23\n",
      "        6437       0.82      0.67      0.73        27\n",
      "        6438       0.17      0.34      0.23        32\n",
      "        6439       0.57      0.40      0.47        30\n",
      "        6440       0.21      0.63      0.32        19\n",
      "        6442       0.45      0.50      0.47        26\n",
      "        6443       0.37      0.34      0.35        32\n",
      "        6444       0.09      0.06      0.07        32\n",
      "        6445       0.12      0.20      0.15        25\n",
      "        6450       0.08      0.08      0.08        24\n",
      "        6451       0.30      0.59      0.40        34\n",
      "        6452       0.22      0.59      0.32        17\n",
      "        6453       0.32      0.62      0.42        29\n",
      "        6454       0.74      0.62      0.68        32\n",
      "        6455       0.00      0.00      0.00        26\n",
      "        6464       0.41      0.66      0.51        29\n",
      "        6466       0.60      0.47      0.53        19\n",
      "        6467       0.77      1.00      0.87        20\n",
      "        6468       0.70      0.72      0.71        29\n",
      "        6469       0.43      0.78      0.55        23\n",
      "        6470       0.43      0.70      0.53        30\n",
      "        6472       0.69      0.55      0.61        33\n",
      "        6473       0.70      0.47      0.56        30\n",
      "        6476       0.87      0.79      0.83        34\n",
      "        6477       0.86      0.43      0.57        28\n",
      "        6493       0.00      0.00      0.00        34\n",
      "        6494       0.20      0.48      0.28        25\n",
      "        6495       0.31      0.37      0.34        27\n",
      "        6497       0.21      0.84      0.34        25\n",
      "        6498       0.60      0.57      0.59        21\n",
      "        6499       0.49      0.85      0.62        27\n",
      "        6500       0.13      0.26      0.17        27\n",
      "        6502       0.15      0.21      0.17        19\n",
      "        6503       0.18      0.08      0.11        25\n",
      "        6504       0.29      0.57      0.38        23\n",
      "        6505       0.10      0.39      0.16        18\n",
      "        6506       0.16      0.21      0.18        28\n",
      "        6509       0.76      0.67      0.71        39\n",
      "        6512       0.71      0.30      0.43        33\n",
      "        6531       0.28      0.64      0.39        28\n",
      "        6534       0.68      0.85      0.75        27\n",
      "        6536       0.59      0.68      0.63        28\n",
      "        6540       0.50      0.47      0.48        30\n",
      "        6548       0.81      0.46      0.59        28\n",
      "        6550       0.23      0.43      0.30        23\n",
      "        6551       0.44      0.48      0.46        25\n",
      "        6553       0.32      0.28      0.30        29\n",
      "        6567       0.56      0.53      0.54        36\n",
      "        6576       0.27      0.19      0.22        21\n",
      "        6577       0.57      0.70      0.63        23\n",
      "        6578       0.90      0.70      0.79        27\n",
      "        6579       0.31      1.00      0.47        25\n",
      "        6581       0.68      0.79      0.73        33\n",
      "        6582       0.48      0.62      0.54        26\n",
      "        6584       0.73      0.96      0.83        25\n",
      "        6585       0.00      0.00      0.00        24\n",
      "        6586       0.50      0.09      0.16        32\n",
      "        6589       0.41      0.91      0.57        23\n",
      "        6590       1.00      0.33      0.50        24\n",
      "        6591       0.29      0.68      0.41        22\n",
      "        6592       0.24      0.64      0.35        28\n",
      "        6593       0.47      0.35      0.40        26\n",
      "        6594       0.22      0.21      0.22        28\n",
      "        6595       0.82      0.27      0.41        33\n",
      "        6597       0.67      0.40      0.50        25\n",
      "        6598       0.29      0.24      0.26        29\n",
      "        6599       0.14      0.42      0.21        19\n",
      "        6600       0.64      0.89      0.75        28\n",
      "        6602       0.70      0.73      0.71        22\n",
      "        6604       0.50      0.55      0.52        22\n",
      "        6605       0.59      0.88      0.71        26\n",
      "        6607       0.56      0.56      0.56        32\n",
      "        6611       0.83      0.77      0.80        31\n",
      "        6617       0.56      0.48      0.52        29\n",
      "        6618       0.83      0.52      0.64        29\n",
      "        6619       0.54      0.54      0.54        26\n",
      "        6622       0.28      0.65      0.39        20\n",
      "        6623       0.19      0.95      0.32        22\n",
      "        6625       0.53      0.40      0.45        25\n",
      "        6627       0.14      0.04      0.06        24\n",
      "        6632       0.17      0.73      0.28        22\n",
      "        6636       0.44      0.48      0.46        31\n",
      "        6645       1.00      0.43      0.61        23\n",
      "        6647       0.13      0.45      0.20        22\n",
      "        6648       0.36      0.53      0.43        32\n",
      "        6649       0.23      0.16      0.19        32\n",
      "        6650       0.67      0.36      0.47        39\n",
      "        6651       0.15      0.53      0.23        15\n",
      "        6653       0.35      0.47      0.40        19\n",
      "        6654       0.70      0.87      0.78        38\n",
      "        6655       0.32      0.21      0.25        33\n",
      "        6657       0.50      0.05      0.10        19\n",
      "        6658       0.53      0.53      0.53        17\n",
      "        6659       0.45      0.62      0.52        29\n",
      "        6660       0.19      0.58      0.29        19\n",
      "        6664       0.73      0.59      0.66        32\n",
      "        6665       0.62      0.88      0.73        32\n",
      "        6666       0.76      0.70      0.73        23\n",
      "        6667       0.56      0.48      0.52        29\n",
      "        6668       0.75      0.32      0.44        38\n",
      "        6671       0.39      0.23      0.29        31\n",
      "        6673       0.57      0.93      0.70        27\n",
      "        6674       0.61      0.50      0.55        28\n",
      "        6675       0.21      0.70      0.32        20\n",
      "        6676       0.70      0.68      0.69        31\n",
      "        6677       0.83      0.38      0.53        13\n",
      "        6681       0.37      0.81      0.51        27\n",
      "        6684       0.35      0.30      0.32        30\n",
      "        6685       0.33      0.24      0.28        17\n",
      "        6687       0.33      0.25      0.29        20\n",
      "        6688       0.22      0.50      0.30        24\n",
      "        6690       0.50      0.56      0.53        27\n",
      "        6691       0.43      0.50      0.46        24\n",
      "        6696       0.74      0.65      0.69        26\n",
      "        6704       1.00      0.08      0.14        13\n",
      "        6710       0.00      0.00      0.00        13\n",
      "        6711       0.60      0.18      0.27        17\n",
      "        6712       0.56      0.62      0.59        24\n",
      "        6714       0.38      0.19      0.26        31\n",
      "        6715       0.69      0.32      0.44        28\n",
      "        6716       0.56      0.71      0.63        31\n",
      "        6718       1.00      0.21      0.35        14\n",
      "        6720       0.69      0.87      0.77        31\n",
      "        6723       0.88      0.56      0.68        25\n",
      "        6729       0.00      0.00      0.00        19\n",
      "        6730       0.00      0.00      0.00        18\n",
      "        6751       0.38      0.63      0.47        27\n",
      "        6752       0.50      0.09      0.15        23\n",
      "        6756       0.30      0.14      0.19        22\n",
      "        6758       0.90      0.79      0.84        34\n",
      "        6760       0.39      0.96      0.55        25\n",
      "        6763       0.62      0.31      0.41        26\n",
      "        6764       0.46      0.57      0.51        28\n",
      "        6765       0.46      0.50      0.48        26\n",
      "        6766       0.33      0.65      0.43        23\n",
      "        6767       0.46      0.48      0.47        25\n",
      "        6769       0.25      0.23      0.24        22\n",
      "        6772       0.35      0.68      0.46        22\n",
      "        6782       0.75      0.13      0.22        23\n",
      "        6786       0.83      0.22      0.34        23\n",
      "        6788       1.00      0.22      0.36        18\n",
      "        6789       0.64      0.47      0.54        30\n",
      "        6792       0.65      0.52      0.58        29\n",
      "        6793       0.12      0.04      0.06        25\n",
      "        6794       0.66      0.73      0.69        26\n",
      "        6796       0.00      0.00      0.00        12\n",
      "        6797       0.76      0.63      0.69        30\n",
      "        6798       0.50      0.24      0.33        29\n",
      "        6799       0.38      0.57      0.46        28\n",
      "        6800       0.47      0.68      0.56        22\n",
      "        6801       0.46      0.25      0.32        24\n",
      "        6802       0.53      0.93      0.67        29\n",
      "        6803       0.56      0.82      0.67        28\n",
      "        6804       0.45      0.68      0.54        28\n",
      "        6807       0.86      0.79      0.83        24\n",
      "        6808       0.77      0.74      0.75        27\n",
      "        6809       0.59      0.77      0.67        30\n",
      "        6810       0.60      0.30      0.40        30\n",
      "        6813       0.95      0.68      0.79        31\n",
      "        6814       0.88      0.28      0.42        25\n",
      "        6819       0.65      0.58      0.61        26\n",
      "        6820       0.92      0.85      0.88        13\n",
      "        6823       0.37      0.53      0.44        32\n",
      "        6835       0.51      0.88      0.65        24\n",
      "        6836       0.67      0.50      0.57        32\n",
      "        6837       0.74      0.50      0.60        34\n",
      "        6838       0.44      0.42      0.43        19\n",
      "        6839       0.25      0.61      0.35        23\n",
      "        6840       0.87      0.52      0.65        25\n",
      "        6841       0.46      0.57      0.51        21\n",
      "        6842       0.80      0.26      0.39        31\n",
      "        6843       0.53      0.32      0.40        28\n",
      "        6844       0.06      0.14      0.09        21\n",
      "        6847       0.75      0.72      0.73        25\n",
      "        6851       0.32      0.59      0.42        27\n",
      "        6852       0.29      0.36      0.32        28\n",
      "        6853       0.55      0.78      0.65        27\n",
      "        6854       0.52      0.54      0.53        24\n",
      "        6855       0.19      0.35      0.25        26\n",
      "        6856       0.63      0.71      0.67        24\n",
      "        6858       0.55      0.43      0.48        28\n",
      "        6859       0.47      0.28      0.35        29\n",
      "        6861       0.28      0.41      0.33        27\n",
      "        6862       0.38      0.38      0.38        21\n",
      "        6863       0.42      0.35      0.39        31\n",
      "        6864       0.64      0.56      0.60        25\n",
      "        6865       0.00      0.00      0.00        13\n",
      "        6868       0.25      0.39      0.30        18\n",
      "        6871       0.31      0.28      0.29        29\n",
      "        6874       0.51      0.72      0.60        25\n",
      "        6876       0.39      0.85      0.53        26\n",
      "        6878       0.25      0.11      0.15        28\n",
      "        6882       0.34      0.42      0.38        24\n",
      "        6883       0.31      0.77      0.44        31\n",
      "        6888       0.26      0.35      0.30        26\n",
      "        6889       0.81      0.79      0.80        33\n",
      "        6890       0.31      0.68      0.43        22\n",
      "        6891       0.42      0.29      0.34        28\n",
      "        6894       0.42      0.50      0.45        30\n",
      "        6899       0.50      0.89      0.64        28\n",
      "        6903       0.25      0.43      0.32        28\n",
      "        6905       0.90      0.87      0.88        30\n",
      "        6906       0.29      0.20      0.24        10\n",
      "        6907       0.40      0.58      0.47        31\n",
      "        6911       0.86      0.35      0.50        17\n",
      "        6915       0.32      0.38      0.35        26\n",
      "        6917       0.76      0.90      0.83        29\n",
      "        6918       0.71      0.88      0.78        33\n",
      "        6920       0.50      0.34      0.41        32\n",
      "        6921       0.24      0.36      0.29        22\n",
      "        6923       0.77      0.75      0.76        32\n",
      "        6925       0.88      0.54      0.67        13\n",
      "        6931       0.41      0.77      0.54        22\n",
      "        6932       0.44      0.37      0.40        30\n",
      "        6936       0.60      0.46      0.52        13\n",
      "        6940       0.67      0.57      0.62        14\n",
      "        6943       0.30      0.45      0.36        22\n",
      "        6954       1.00      0.92      0.96        13\n",
      "        6958       0.71      0.60      0.65        25\n",
      "        6961       0.65      0.96      0.77        23\n",
      "        6963       0.48      0.63      0.55        19\n",
      "        6970       0.40      0.11      0.17        19\n",
      "        6971       0.90      0.87      0.88        30\n",
      "        6974       0.44      0.60      0.51        25\n",
      "        6976       0.79      0.94      0.86        32\n",
      "        6982       1.00      0.69      0.81        32\n",
      "        6987       0.80      0.88      0.84        32\n",
      "        6988       0.78      0.44      0.56        32\n",
      "        6989       0.62      0.61      0.62        33\n",
      "        6990       0.86      0.82      0.84        22\n",
      "        6994       1.00      1.00      1.00        17\n",
      "        7020       0.55      0.85      0.67        27\n",
      "        7021       1.00      0.84      0.91        19\n",
      "        7022       0.89      0.81      0.85        31\n",
      "        7023       1.00      0.50      0.67        22\n",
      "        7024       0.45      0.54      0.49        26\n",
      "        7026       0.73      0.79      0.76        14\n",
      "        7027       0.32      0.58      0.42        19\n",
      "        7029       0.50      0.59      0.54        29\n",
      "        7030       0.66      0.88      0.75        24\n",
      "        7032       1.00      0.57      0.73        35\n",
      "        7033       0.53      0.30      0.38        33\n",
      "        7034       0.35      0.50      0.42        22\n",
      "        7035       0.49      0.81      0.61        26\n",
      "        7037       0.59      0.94      0.72        32\n",
      "        7038       0.46      0.75      0.57        24\n",
      "        7041       0.50      0.59      0.54        29\n",
      "        7042       0.59      0.43      0.50        23\n",
      "        7043       0.88      0.85      0.87        34\n",
      "        7045       0.20      0.36      0.26        25\n",
      "        7046       0.54      0.91      0.68        22\n",
      "        7047       0.59      0.43      0.50        23\n",
      "        7050       0.64      0.40      0.49        35\n",
      "        7051       0.28      0.50      0.36        28\n",
      "        7059       0.58      0.70      0.63        27\n",
      "        7061       0.48      0.59      0.53        22\n",
      "        7066       0.69      0.92      0.79        26\n",
      "        7067       0.68      0.78      0.72        27\n",
      "        7069       0.84      0.79      0.82        34\n",
      "        9117       0.47      0.36      0.41        22\n",
      "        9119       0.08      0.22      0.11        23\n",
      "        9121       0.60      0.16      0.26        37\n",
      "        9122       0.26      0.48      0.34        23\n",
      "        9123       0.24      0.22      0.23        23\n",
      "        9124       0.31      0.50      0.38        18\n",
      "        9127       0.78      0.21      0.33        34\n",
      "        9129       1.00      0.73      0.85        15\n",
      "        9132       0.69      0.77      0.73        26\n",
      "        9182       1.00      0.75      0.86        16\n",
      "        9183       0.54      0.59      0.56        34\n",
      "        9185       0.89      0.62      0.73        26\n",
      "        9186       0.20      0.09      0.13        11\n",
      "        9187       0.55      0.88      0.67        32\n",
      "        9188       0.67      0.29      0.40        28\n",
      "        9190       0.81      0.87      0.84        30\n",
      "        9199       1.00      0.44      0.61        16\n",
      "        9202       0.43      0.41      0.42        22\n",
      "        9203       0.34      0.36      0.35        28\n",
      "        9204       0.90      0.62      0.73        29\n",
      "        9205       0.74      0.44      0.55        32\n",
      "        9322       0.83      0.20      0.32        25\n",
      "        9323       0.61      0.58      0.59        33\n",
      "        9326       0.63      0.63      0.63        30\n",
      "        9327       0.59      0.59      0.59        22\n",
      "        9329       0.00      0.00      0.00        38\n",
      "        9331       0.50      0.43      0.46        28\n",
      "        9337       0.77      0.96      0.86        25\n",
      "        9338       1.00      0.03      0.05        37\n",
      "        9339       0.46      0.71      0.56        17\n",
      "       10784       0.39      0.21      0.27        34\n",
      "       10785       0.22      0.46      0.29        24\n",
      "       10797       0.44      0.57      0.49        30\n",
      "       10799       0.62      0.18      0.28        28\n",
      "       10801       0.78      0.44      0.56        16\n",
      "       10802       0.33      0.38      0.36        34\n",
      "       10803       0.79      0.77      0.78        30\n",
      "       10806       0.57      0.70      0.63        23\n",
      "       10809       0.50      0.72      0.59        36\n",
      "       10811       0.40      0.40      0.40        30\n",
      "       10812       0.25      0.42      0.31        26\n",
      "       10813       1.00      0.60      0.75        15\n",
      "       10814       1.00      1.00      1.00        15\n",
      "       10840       0.40      0.15      0.22        26\n",
      "       10841       0.24      0.25      0.25        28\n",
      "       10842       0.62      0.73      0.67        33\n",
      "       10847       0.70      0.63      0.67        30\n",
      "       11110       0.11      0.09      0.10        23\n",
      "       11112       0.18      0.15      0.17        26\n",
      "       11114       0.36      0.56      0.44        25\n",
      "       11115       0.36      0.12      0.18        34\n",
      "       11116       0.73      0.31      0.43        26\n",
      "       11118       0.38      0.21      0.27        24\n",
      "       11119       0.67      0.35      0.46        34\n",
      "       11120       0.27      0.57      0.37        23\n",
      "       11121       0.36      0.71      0.48        28\n",
      "       11122       0.52      0.93      0.67        28\n",
      "       11123       0.42      0.42      0.42        12\n",
      "       11124       0.23      0.64      0.34        25\n",
      "       11131       0.16      0.22      0.19        23\n",
      "       11132       0.52      0.65      0.58        26\n",
      "       11133       0.76      0.67      0.71        24\n",
      "       11134       0.31      0.58      0.41        24\n",
      "       11136       0.28      0.36      0.31        28\n",
      "       11137       0.21      0.21      0.21        33\n",
      "       11138       0.65      0.48      0.55        27\n",
      "       11140       0.27      0.11      0.15        28\n",
      "       11142       0.20      0.15      0.17        13\n",
      "       11143       0.31      0.76      0.44        25\n",
      "       11144       0.28      0.42      0.33        24\n",
      "       11145       0.44      0.32      0.37        25\n",
      "       11146       0.68      0.42      0.52        31\n",
      "       11147       0.33      0.40      0.36        25\n",
      "       11150       0.24      0.58      0.34        19\n",
      "       11151       0.22      0.15      0.18        26\n",
      "       11152       0.49      0.62      0.55        29\n",
      "       11155       0.76      0.76      0.76        25\n",
      "       11161       0.38      0.83      0.52        24\n",
      "       11162       0.73      0.31      0.43        36\n",
      "       11163       0.46      0.23      0.31        26\n",
      "       11164       0.05      0.67      0.10        21\n",
      "       11165       0.11      0.16      0.13        25\n",
      "       11166       0.38      0.08      0.13        37\n",
      "       11169       0.67      0.12      0.21        16\n",
      "       11170       0.50      0.34      0.41        29\n",
      "       11171       0.00      0.00      0.00        33\n",
      "       11173       0.61      0.91      0.73        22\n",
      "       11175       1.00      0.11      0.19        19\n",
      "       11176       0.77      0.56      0.65        18\n",
      "       11178       0.79      0.41      0.54        27\n",
      "       11179       0.61      0.45      0.52        31\n",
      "       11181       0.62      0.56      0.59        18\n",
      "       11182       0.00      0.00      0.00        19\n",
      "       11184       0.28      0.21      0.24        34\n",
      "       11190       0.29      0.59      0.38        17\n",
      "       11195       0.71      0.69      0.70        29\n",
      "       11196       0.46      0.68      0.55        28\n",
      "       11198       0.86      0.71      0.77        34\n",
      "       11199       0.83      0.47      0.60        32\n",
      "       11200       0.37      0.38      0.37        29\n",
      "       11203       0.46      0.57      0.51        21\n",
      "       11204       0.36      0.13      0.19        31\n",
      "       11205       0.50      0.14      0.22        36\n",
      "       11207       0.87      0.37      0.52        35\n",
      "       11208       0.13      0.14      0.14        29\n",
      "       11211       0.47      0.58      0.52        24\n",
      "       11214       0.23      0.32      0.26        22\n",
      "       11216       1.00      0.35      0.52        23\n",
      "       11217       0.50      0.17      0.25        30\n",
      "       11218       0.42      0.20      0.27        25\n",
      "       11219       0.96      0.79      0.86        28\n",
      "       11220       0.00      0.00      0.00        14\n",
      "       11222       0.29      0.46      0.36        26\n",
      "       11223       0.30      0.43      0.36        23\n",
      "       11224       0.49      0.84      0.62        25\n",
      "       11226       0.59      0.88      0.71        33\n",
      "       11228       0.87      0.39      0.54        33\n",
      "       11239       0.28      0.48      0.35        25\n",
      "       11240       0.79      0.52      0.62        29\n",
      "       11241       0.21      0.26      0.23        27\n",
      "       11242       0.40      0.08      0.14        24\n",
      "       11243       0.70      0.58      0.64        24\n",
      "       11244       0.25      0.54      0.34        28\n",
      "       11245       0.19      0.46      0.27        26\n",
      "       11252       0.46      0.61      0.52        28\n",
      "       11253       0.23      0.42      0.29        24\n",
      "       11254       0.00      0.00      0.00        21\n",
      "       11255       0.17      0.04      0.06        25\n",
      "       11256       0.00      0.00      0.00        28\n",
      "       11257       0.55      0.25      0.34        24\n",
      "       11258       0.42      0.76      0.54        33\n",
      "       11259       0.66      0.78      0.72        37\n",
      "       11260       0.33      0.07      0.11        29\n",
      "       11261       0.43      0.12      0.18        26\n",
      "       11262       0.14      0.04      0.06        25\n",
      "       11263       0.12      0.14      0.13        14\n",
      "       11264       0.71      0.19      0.30        26\n",
      "       11265       1.00      0.23      0.37        22\n",
      "       11266       0.00      0.00      0.00        35\n",
      "       11267       0.62      0.16      0.25        32\n",
      "       11268       0.58      0.58      0.58        24\n",
      "       11269       0.46      0.41      0.44        29\n",
      "       11271       0.37      0.29      0.33        34\n",
      "       11272       0.00      0.00      0.00        20\n",
      "       11273       0.81      0.52      0.63        25\n",
      "       11274       0.23      0.55      0.32        20\n",
      "       11275       0.63      0.56      0.59        34\n",
      "       11276       0.48      0.34      0.40        29\n",
      "       11286       0.29      0.25      0.27        20\n",
      "       11296       0.67      0.76      0.71        21\n",
      "       11297       0.53      0.33      0.41        30\n",
      "       11299       0.20      0.14      0.17        28\n",
      "       11315       0.51      0.85      0.64        26\n",
      "       11316       0.67      0.80      0.73        30\n",
      "       11327       0.52      0.43      0.47        30\n",
      "       11334       0.24      0.39      0.30        28\n",
      "       11335       0.92      1.00      0.96        22\n",
      "       11346       0.82      0.93      0.87        29\n",
      "       11347       0.77      0.75      0.76        32\n",
      "       11348       0.84      0.95      0.89        22\n",
      "       11351       0.56      0.76      0.64        25\n",
      "       11352       0.62      0.58      0.60        26\n",
      "       11353       0.46      0.82      0.59        22\n",
      "       11355       0.15      0.13      0.14        23\n",
      "       11356       0.25      0.56      0.34        27\n",
      "       11358       0.79      0.63      0.70        30\n",
      "       11368       0.50      0.48      0.49        25\n",
      "       11486       0.52      0.40      0.45        35\n",
      "       11488       0.53      0.53      0.53        17\n",
      "       11502       0.28      0.58      0.38        31\n",
      "       11556       0.86      0.88      0.87        34\n",
      "       11647       0.86      0.72      0.78        25\n",
      "       11650       0.61      0.67      0.64        33\n",
      "       11837       0.39      0.82      0.53        22\n",
      "       12069       0.53      0.74      0.62        23\n",
      "       12106       0.51      0.69      0.59        29\n",
      "       12108       0.44      0.12      0.20        32\n",
      "       12109       0.32      0.16      0.21        37\n",
      "       12110       0.21      0.24      0.22        21\n",
      "       12112       0.53      0.96      0.69        24\n",
      "       12139       0.94      0.89      0.91        18\n",
      "       12140       0.89      0.86      0.88        29\n",
      "       12149       0.90      0.73      0.81        26\n",
      "       12151       0.58      0.71      0.64        31\n",
      "       12155       0.26      0.33      0.29        27\n",
      "       12162       0.48      0.57      0.52        28\n",
      "       12165       0.72      0.85      0.78        27\n",
      "       12166       0.65      0.72      0.68        39\n",
      "       12167       0.38      0.44      0.41        25\n",
      "       12168       1.00      0.07      0.12        15\n",
      "       12169       0.25      0.62      0.36        26\n",
      "       12170       0.35      0.41      0.38        27\n",
      "       12171       0.63      0.61      0.62        31\n",
      "       12172       0.63      0.71      0.67        24\n",
      "       12173       0.50      0.78      0.61        18\n",
      "       12175       0.38      0.46      0.42        24\n",
      "       12176       0.76      0.79      0.78        24\n",
      "       12178       0.41      0.82      0.55        17\n",
      "       12179       0.43      0.48      0.45        25\n",
      "       12180       0.50      0.88      0.64        24\n",
      "       12181       0.21      0.36      0.26        25\n",
      "       12182       0.36      0.43      0.39        28\n",
      "       12183       0.49      0.73      0.58        26\n",
      "       12184       0.48      0.48      0.48        29\n",
      "       12185       0.59      0.52      0.55        31\n",
      "       12186       0.17      0.29      0.22        28\n",
      "       12189       0.80      0.13      0.23        30\n",
      "       12190       0.67      0.19      0.30        21\n",
      "       12191       0.23      0.60      0.33        25\n",
      "       12192       0.24      0.41      0.31        27\n",
      "       12193       0.50      0.62      0.55        26\n",
      "       12195       0.97      0.97      0.97        38\n",
      "       12196       0.92      0.48      0.63        25\n",
      "       12197       0.59      0.43      0.50        30\n",
      "       12198       0.42      0.86      0.57        22\n",
      "       12200       0.84      0.75      0.79        28\n",
      "       12201       0.72      0.85      0.78        27\n",
      "       12202       0.59      0.42      0.49        24\n",
      "       12204       0.36      0.88      0.51        33\n",
      "       12205       0.27      0.62      0.37        21\n",
      "       12206       0.83      0.16      0.26        32\n",
      "       12207       0.46      0.52      0.49        25\n",
      "       12208       0.10      0.79      0.18        28\n",
      "       12209       0.75      0.96      0.84        25\n",
      "       12210       0.40      0.19      0.26        21\n",
      "       12212       0.33      0.84      0.47        25\n",
      "       12213       0.32      0.60      0.42        20\n",
      "       12215       0.68      0.95      0.79        22\n",
      "       12216       0.53      0.71      0.61        28\n",
      "       12217       0.58      0.84      0.69        25\n",
      "       12218       0.71      0.73      0.72        30\n",
      "       12219       0.35      0.65      0.46        26\n",
      "       12223       0.80      0.89      0.84         9\n",
      "       12224       0.77      0.83      0.80        24\n",
      "       12225       0.49      0.75      0.59        32\n",
      "       12226       0.77      0.66      0.71        35\n",
      "       12227       0.50      0.67      0.57        30\n",
      "       12228       0.50      0.20      0.29        35\n",
      "       12229       0.52      0.59      0.55        29\n",
      "       12230       0.81      0.70      0.75        30\n",
      "       12232       0.64      0.83      0.72        30\n",
      "       12234       0.39      0.30      0.34        23\n",
      "       12235       0.55      0.85      0.67        27\n",
      "       12237       0.61      0.59      0.60        29\n",
      "       12239       0.27      0.33      0.30        24\n",
      "       12240       0.63      0.76      0.69        29\n",
      "       12241       0.65      0.80      0.72        30\n",
      "       12242       0.54      0.66      0.59        29\n",
      "       12243       0.68      0.43      0.53        35\n",
      "       12245       0.81      0.63      0.71        27\n",
      "       12246       0.91      0.88      0.89        24\n",
      "       12313       0.24      0.40      0.30        15\n",
      "       12316       0.55      0.86      0.67        28\n",
      "       12332       0.14      0.67      0.23        18\n",
      "       12348       0.65      0.43      0.52        30\n",
      "       12349       0.40      0.38      0.39        16\n",
      "       12350       0.56      0.58      0.57        31\n",
      "       12351       0.47      0.25      0.33        28\n",
      "       12352       0.48      0.56      0.52        27\n",
      "       12354       0.70      0.58      0.64        24\n",
      "       12356       0.00      0.00      0.00        12\n",
      "       12357       0.42      0.93      0.58        30\n",
      "       12358       0.89      0.74      0.81        23\n",
      "       12360       0.64      0.75      0.69        12\n",
      "       12362       0.50      0.94      0.65        18\n",
      "       12369       0.33      0.08      0.13        38\n",
      "       12370       0.40      0.59      0.47        29\n",
      "       12371       0.29      0.64      0.40        25\n",
      "       12372       0.24      0.36      0.29        25\n",
      "       12376       0.71      0.88      0.79        17\n",
      "       12380       0.48      0.76      0.59        21\n",
      "       12382       0.58      0.91      0.71        33\n",
      "       12387       0.61      0.70      0.66        27\n",
      "       12390       0.88      0.96      0.92        24\n",
      "       12392       0.78      1.00      0.88        21\n",
      "       12394       0.18      0.50      0.26        32\n",
      "       12396       0.32      0.44      0.37        16\n",
      "       12397       0.74      0.94      0.83        31\n",
      "       12403       0.71      0.21      0.32        24\n",
      "       12405       0.33      0.75      0.46        12\n",
      "       12406       0.25      0.73      0.38        22\n",
      "       12408       1.00      0.30      0.46        20\n",
      "       12410       0.54      0.67      0.60        21\n",
      "       12417       0.54      0.75      0.63        40\n",
      "       12419       0.65      0.69      0.67        29\n",
      "       12420       0.74      0.74      0.74        27\n",
      "       12421       0.54      0.96      0.69        23\n",
      "       12422       0.75      1.00      0.86        18\n",
      "       12423       0.77      0.96      0.86        25\n",
      "       12424       0.58      0.96      0.72        27\n",
      "       12425       0.70      0.70      0.70        30\n",
      "       12426       0.69      0.46      0.55        24\n",
      "       12427       0.49      0.64      0.55        33\n",
      "       12428       0.53      0.37      0.43        27\n",
      "       12430       0.54      0.87      0.67        23\n",
      "       12434       0.66      0.81      0.72        26\n",
      "       12437       0.20      0.67      0.30        27\n",
      "       12438       0.60      0.91      0.72        33\n",
      "       12439       0.73      0.82      0.77        33\n",
      "       12440       0.21      0.63      0.32        19\n",
      "       12441       0.28      0.41      0.33        29\n",
      "       12442       0.71      0.85      0.77        26\n",
      "       12443       0.59      0.41      0.48        32\n",
      "       12444       0.68      0.93      0.79        28\n",
      "       12445       0.24      0.61      0.35        23\n",
      "       12446       0.40      0.79      0.54        24\n",
      "       12448       0.23      0.45      0.30        20\n",
      "       12449       0.24      0.86      0.37        29\n",
      "       12450       0.39      0.32      0.35        22\n",
      "       12455       0.57      0.74      0.65        27\n",
      "       12456       0.55      0.29      0.37        21\n",
      "       12457       0.67      0.58      0.62        31\n",
      "       12458       0.63      0.44      0.52        27\n",
      "       12459       0.76      0.83      0.79        23\n",
      "       12461       0.31      0.36      0.33        28\n",
      "       12462       0.35      0.28      0.31        29\n",
      "       12463       0.68      1.00      0.81        25\n",
      "       12464       0.54      0.63      0.58        35\n",
      "       12465       0.36      0.62      0.45        26\n",
      "       12466       0.74      0.70      0.72        20\n",
      "       12468       0.67      0.32      0.44        37\n",
      "       12469       0.17      0.35      0.23        26\n",
      "       12470       0.43      0.52      0.47        31\n",
      "       12471       0.32      0.23      0.26        31\n",
      "       12472       0.24      0.26      0.25        31\n",
      "       12474       0.39      0.54      0.45        28\n",
      "       12475       0.20      0.34      0.25        29\n",
      "       12476       0.13      0.12      0.12        26\n",
      "       12478       0.49      0.60      0.54        30\n",
      "       12479       0.62      0.78      0.69        23\n",
      "       12480       0.56      0.58      0.57        24\n",
      "       12481       0.25      0.20      0.22        35\n",
      "       12482       0.59      0.96      0.73        27\n",
      "       12483       0.38      0.79      0.51        33\n",
      "       12484       0.14      0.14      0.14        22\n",
      "       12485       0.44      0.76      0.56        25\n",
      "       12486       0.57      0.68      0.62        31\n",
      "       12487       0.33      0.77      0.47        22\n",
      "       12490       0.00      0.00      0.00        31\n",
      "       12491       0.15      0.36      0.21        22\n",
      "       12492       0.38      0.52      0.44        29\n",
      "       12493       0.21      0.32      0.25        19\n",
      "\n",
      "    accuracy                           0.42     68888\n",
      "   macro avg       0.45      0.42      0.40     68888\n",
      "weighted avg       0.46      0.42      0.40     68888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns=['product_id','title', 'description', 'tags','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=read_data(test_dir, test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['combined_text'] = df_test['title'].fillna('') + ' ' + df_test['description'].fillna('') + ' ' + df_test['tags'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text_combined = df_test['combined_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X does not contain any features, but ColumnTransformer is expecting 2 features",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:366\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 366\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m \u001b[43m_num_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:301\u001b[0m, in \u001b[0;36m_num_features\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m    300\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 301\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(message)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: Unable to find the number of features from X of type numpy.ndarray with shape (25514,)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m test_pred\u001b[38;5;241m=\u001b[39m\u001b[43mbest_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text_combined\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\pipeline.py:480\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    478\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:798\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    800\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(\n\u001b[0;32m    801\u001b[0m     X,\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    805\u001b[0m     column_as_strings\u001b[38;5;241m=\u001b[39mfit_dataframe_and_transform_dataframe,\n\u001b[0;32m    806\u001b[0m )\n\u001b[0;32m    807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n",
      "File \u001b[1;32mc:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:369\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m reset \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features_in_\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 369\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX does not contain any features, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is expecting \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    374\u001b[0m     \u001b[38;5;66;03m# If the number of features is not defined and reset=True,\u001b[39;00m\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;66;03m# then we skip this check\u001b[39;00m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: X does not contain any features, but ColumnTransformer is expecting 2 features"
     ]
    }
   ],
   "source": [
    "test_pred=best_model.predict(test_text_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train['combined_text'] = df_train['title'] + \" \" + df_train['description'] + \" \" + df_train['tags']\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  \n",
    "X_text = tfidf_vectorizer.fit_transform(df_train['combined_text'])\n",
    "\n",
    "type_encoder = LabelEncoder()\n",
    "X_type = type_encoder.fit_transform(df_train['type'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hstack([X_text, X_type[:, None]])\n",
    "\n",
    "y = df_train['bottom_category_id']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('nb', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1, 2)],\n",
    "    'tfidf__max_features': [5000],\n",
    "    'nb__alpha': [ 0.1,1,0.01]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training, df_validation = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.3,\n",
    "    stratify=df_train['bottom_category_id'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine text columns for feature extraction\n",
    "df_training['combined_text'] = df_training['title'].fillna('') + ' ' + df_training['description'].fillna('') + ' ' + df_training['tags'].fillna('')\n",
    "df_validation['combined_text'] = df_validation['title'].fillna('') + ' ' + df_validation['description'].fillna('') + ' ' + df_validation['tags'].fillna('')\n",
    "\n",
    "train_text_combined = df_training['combined_text'].values\n",
    "val_text_combined = df_validation['combined_text'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_label=df_validation['bottom_category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(nb_pipeline, param_grid, cv=5, scoring='f1_weighted', verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "             param_grid={&#x27;nb__alpha&#x27;: [0.1, 1, 0.01],\n",
       "                         &#x27;tfidf__max_features&#x27;: [5000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 2)]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;tfidf&#x27;,\n",
       "                                        TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                                       (&#x27;nb&#x27;, MultinomialNB())]),\n",
       "             param_grid={&#x27;nb__alpha&#x27;: [0.1, 1, 0.01],\n",
       "                         &#x27;tfidf__max_features&#x27;: [5000],\n",
       "                         &#x27;tfidf__ngram_range&#x27;: [(1, 2)]},\n",
       "             scoring=&#x27;f1_weighted&#x27;, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer(stop_words=&#x27;english&#x27;)),\n",
       "                (&#x27;nb&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('tfidf',\n",
       "                                        TfidfVectorizer(stop_words='english')),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'nb__alpha': [0.1, 1, 0.01],\n",
       "                         'tfidf__max_features': [5000],\n",
       "                         'tfidf__ngram_range': [(1, 2)]},\n",
       "             scoring='f1_weighted', verbose=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(train_text_combined, df_training['bottom_category_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = grid_search\n",
    "val_pred_bottom = nb_model.predict(val_text_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation F1 score with Naive Bayes: 0.5645\n",
      "Best Parameters: {'nb__alpha': 0.01, 'tfidf__max_features': 5000, 'tfidf__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "val_f1_score = f1_score(val_label, val_pred_bottom, average='weighted')\n",
    "print(f\"Validation F1 score with Naive Bayes: {val_f1_score:.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.12      0.19        26\n",
      "           2       0.91      0.34      0.50        29\n",
      "           3       0.47      0.65      0.55        26\n",
      "           4       0.55      0.44      0.49        27\n",
      "           5       0.58      0.62      0.60        29\n",
      "           6       0.42      0.31      0.36        26\n",
      "           7       0.55      0.62      0.58        26\n",
      "           8       0.74      0.82      0.78        28\n",
      "           9       0.24      0.26      0.25        27\n",
      "          10       0.48      0.56      0.52        27\n",
      "          11       0.96      0.85      0.90        27\n",
      "          12       0.59      0.48      0.53        27\n",
      "          13       0.79      0.88      0.84        26\n",
      "          14       0.84      0.96      0.90        28\n",
      "          15       0.72      0.82      0.77        28\n",
      "          16       0.50      0.44      0.47        27\n",
      "          17       0.43      0.50      0.46        26\n",
      "          18       0.85      0.41      0.55        27\n",
      "          19       0.67      0.54      0.60        26\n",
      "          20       0.49      0.69      0.57        26\n",
      "          22       0.60      0.43      0.50        28\n",
      "          23       0.77      0.61      0.68        28\n",
      "          24       0.54      0.52      0.53        27\n",
      "          25       0.36      0.30      0.33        27\n",
      "          26       0.60      0.67      0.63        27\n",
      "          27       0.44      0.39      0.42        28\n",
      "          28       0.74      0.50      0.60        28\n",
      "          29       0.73      0.88      0.80        25\n",
      "          30       0.52      0.46      0.49        28\n",
      "          31       0.50      0.34      0.41        29\n",
      "          32       0.20      0.30      0.24        27\n",
      "          33       0.61      0.42      0.50        26\n",
      "          34       0.63      0.48      0.55        25\n",
      "          35       0.59      0.37      0.45        27\n",
      "          36       0.30      0.30      0.30        27\n",
      "          37       0.28      0.28      0.28        25\n",
      "          38       0.58      0.54      0.56        26\n",
      "          39       0.90      0.73      0.81        26\n",
      "          40       0.50      0.74      0.60        27\n",
      "          41       0.48      0.36      0.41        28\n",
      "          42       0.64      0.35      0.45        26\n",
      "          43       0.62      0.74      0.68        27\n",
      "          44       0.81      0.50      0.62        26\n",
      "          45       0.39      0.28      0.33        25\n",
      "          46       0.06      0.59      0.11        29\n",
      "          47       0.31      0.41      0.35        27\n",
      "          48       1.00      0.50      0.67        28\n",
      "          49       0.72      0.67      0.69        27\n",
      "          50       0.76      0.96      0.85        26\n",
      "          51       0.59      0.70      0.64        27\n",
      "          52       0.39      0.48      0.43        27\n",
      "          53       0.80      0.83      0.82        24\n",
      "          54       0.43      0.44      0.44        27\n",
      "          55       0.87      0.71      0.78        28\n",
      "          56       0.72      0.67      0.69        27\n",
      "          57       0.53      0.37      0.43        27\n",
      "          58       0.88      0.56      0.68        27\n",
      "          59       0.62      0.62      0.62        26\n",
      "          60       0.65      0.50      0.57        26\n",
      "          61       0.73      0.88      0.80        25\n",
      "          62       0.76      0.85      0.80        26\n",
      "          63       0.85      0.85      0.85        26\n",
      "          64       0.52      0.62      0.56        26\n",
      "          65       1.00      0.78      0.88        27\n",
      "          66       0.12      0.04      0.06        27\n",
      "          67       0.09      0.04      0.05        28\n",
      "          68       0.86      0.67      0.75        27\n",
      "          69       0.24      0.19      0.21        27\n",
      "          70       0.21      0.11      0.15        27\n",
      "          71       0.46      0.22      0.30        27\n",
      "          72       0.09      0.08      0.08        26\n",
      "          73       0.64      0.48      0.55        29\n",
      "          74       0.67      0.44      0.53        27\n",
      "          75       0.31      0.30      0.30        27\n",
      "          76       0.59      0.59      0.59        27\n",
      "          77       0.20      0.04      0.06        26\n",
      "          78       0.28      0.19      0.23        26\n",
      "          79       0.57      0.57      0.57        28\n",
      "          80       0.25      0.22      0.24        27\n",
      "          81       0.33      0.18      0.23        28\n",
      "          82       0.43      0.23      0.30        26\n",
      "          83       0.55      0.59      0.57        27\n",
      "          84       0.76      0.73      0.75        26\n",
      "          85       0.49      0.86      0.62        28\n",
      "          86       0.40      0.22      0.29        27\n",
      "          87       0.52      0.57      0.54        28\n",
      "          88       0.45      0.33      0.38        27\n",
      "          89       0.50      0.70      0.58        27\n",
      "          90       0.50      0.11      0.18        27\n",
      "          91       0.46      0.61      0.52        28\n",
      "          92       0.58      0.56      0.57        27\n",
      "          93       0.56      0.69      0.62        29\n",
      "          94       0.62      0.31      0.41        26\n",
      "          96       0.38      0.37      0.38        27\n",
      "          97       0.78      0.50      0.61        28\n",
      "          98       0.65      0.52      0.58        25\n",
      "          99       0.33      0.22      0.27        27\n",
      "         100       0.42      0.62      0.50        26\n",
      "         101       0.11      0.11      0.11        28\n",
      "         102       0.40      0.29      0.33        28\n",
      "         103       0.38      0.33      0.35        27\n",
      "         104       0.56      0.36      0.43        28\n",
      "         105       0.19      0.19      0.19        26\n",
      "         106       0.23      0.25      0.24        28\n",
      "         107       0.23      0.27      0.25        26\n",
      "         108       0.76      0.59      0.67        27\n",
      "         109       0.17      0.19      0.18        26\n",
      "         110       0.40      0.54      0.46        26\n",
      "         111       0.09      0.11      0.10        27\n",
      "         112       0.49      0.63      0.55        27\n",
      "         113       0.76      0.64      0.70        25\n",
      "         114       0.50      0.54      0.52        28\n",
      "         115       0.42      0.36      0.38        28\n",
      "         116       0.38      0.30      0.33        27\n",
      "         117       0.33      0.36      0.34        28\n",
      "         118       0.45      0.38      0.42        26\n",
      "         119       0.23      0.24      0.24        25\n",
      "         120       0.45      0.54      0.49        26\n",
      "         121       0.10      0.28      0.14        25\n",
      "         122       1.00      0.64      0.78        28\n",
      "         123       0.41      0.43      0.42        28\n",
      "         124       0.64      0.55      0.59        29\n",
      "         125       0.57      0.77      0.66        26\n",
      "         126       0.29      0.22      0.25        27\n",
      "         127       0.58      0.42      0.49        26\n",
      "         128       0.29      0.22      0.25        27\n",
      "         129       0.00      0.00      0.00        25\n",
      "         130       0.17      0.21      0.19        28\n",
      "         131       0.47      0.29      0.36        28\n",
      "         132       0.50      0.23      0.32        26\n",
      "         133       0.28      0.32      0.30        28\n",
      "         134       0.85      0.59      0.69        29\n",
      "         135       0.45      0.46      0.46        28\n",
      "         136       0.65      0.71      0.68        28\n",
      "         137       0.73      0.57      0.64        28\n",
      "         138       0.74      0.88      0.81        26\n",
      "         139       0.46      0.75      0.57        28\n",
      "         140       0.83      0.77      0.80        26\n",
      "         141       0.30      0.36      0.33        28\n",
      "         142       0.79      0.54      0.64        28\n",
      "         143       0.32      0.37      0.34        27\n",
      "         144       0.42      0.31      0.36        26\n",
      "         145       0.23      0.24      0.23        29\n",
      "         147       0.67      0.57      0.62        28\n",
      "         148       0.40      0.37      0.38        27\n",
      "         149       0.59      0.62      0.60        26\n",
      "         150       0.66      0.73      0.69        26\n",
      "         151       0.48      0.37      0.42        27\n",
      "         152       0.71      0.60      0.65        25\n",
      "         153       0.64      0.64      0.64        28\n",
      "         154       0.59      0.59      0.59        27\n",
      "         155       0.75      0.78      0.76        27\n",
      "         156       0.16      0.11      0.13        27\n",
      "         157       0.33      0.41      0.37        27\n",
      "         158       0.30      0.22      0.26        27\n",
      "         159       0.50      0.67      0.57        27\n",
      "         160       0.95      0.64      0.77        28\n",
      "         161       0.17      0.18      0.17        28\n",
      "         162       0.20      0.15      0.17        27\n",
      "         163       0.41      0.54      0.47        26\n",
      "         164       0.71      0.63      0.67        27\n",
      "         165       0.37      0.37      0.37        27\n",
      "         166       0.69      0.85      0.76        26\n",
      "         167       0.68      0.70      0.69        27\n",
      "         168       0.68      0.61      0.64        28\n",
      "         169       0.59      0.61      0.60        28\n",
      "         170       0.77      0.85      0.81        27\n",
      "         171       0.78      0.69      0.73        26\n",
      "         172       0.96      0.79      0.86        28\n",
      "         173       0.77      0.89      0.83        27\n",
      "         174       0.60      0.62      0.61        29\n",
      "         175       0.64      0.64      0.64        28\n",
      "         176       0.90      0.67      0.77        27\n",
      "         177       0.34      0.37      0.36        27\n",
      "         178       0.41      0.83      0.55        29\n",
      "         179       0.81      0.75      0.78        28\n",
      "         180       0.35      0.46      0.40        28\n",
      "         181       0.23      0.24      0.23        29\n",
      "         182       0.28      0.50      0.36        28\n",
      "         183       0.83      0.76      0.79        25\n",
      "         184       0.89      0.86      0.88        29\n",
      "         185       0.76      0.68      0.72        19\n",
      "         186       0.64      0.85      0.73        27\n",
      "         187       0.61      0.65      0.63        26\n",
      "         189       0.83      0.93      0.88        27\n",
      "         190       0.40      0.43      0.41        28\n",
      "         191       0.93      0.50      0.65        28\n",
      "         192       0.64      0.78      0.70        27\n",
      "         193       0.74      0.88      0.81        26\n",
      "         194       0.89      0.63      0.74        27\n",
      "         195       1.00      0.81      0.90        27\n",
      "         196       0.83      0.76      0.79        25\n",
      "         197       0.33      0.50      0.39        28\n",
      "         199       0.88      0.56      0.68        27\n",
      "         200       0.60      0.69      0.64        26\n",
      "         201       0.33      0.28      0.30        25\n",
      "         202       0.70      0.72      0.71        29\n",
      "         203       0.77      0.37      0.50        27\n",
      "         204       0.81      0.45      0.58        29\n",
      "         205       0.82      0.64      0.72        28\n",
      "         206       0.70      0.85      0.77        27\n",
      "         207       0.40      0.57      0.47        28\n",
      "         208       0.48      0.57      0.52        28\n",
      "         210       0.78      0.25      0.38        28\n",
      "         211       0.48      0.41      0.44        27\n",
      "         212       0.79      0.73      0.76        26\n",
      "         213       0.38      0.41      0.39        27\n",
      "         214       0.45      0.37      0.41        27\n",
      "         215       0.27      0.27      0.27        26\n",
      "         216       0.74      0.50      0.60        28\n",
      "         217       0.82      0.35      0.49        26\n",
      "         218       0.41      0.69      0.51        26\n",
      "         219       0.67      0.40      0.50        25\n",
      "         220       0.39      0.39      0.39        28\n",
      "         221       0.71      0.63      0.67        27\n",
      "         222       0.39      0.26      0.31        27\n",
      "         224       0.41      0.43      0.42        28\n",
      "         225       0.29      0.32      0.31        28\n",
      "         226       0.67      0.54      0.60        26\n",
      "         227       0.69      0.42      0.52        26\n",
      "         228       0.96      0.81      0.88        27\n",
      "         231       0.70      0.85      0.77        27\n",
      "         232       0.71      0.44      0.55        27\n",
      "         233       0.49      0.62      0.55        29\n",
      "         234       0.75      0.58      0.65        26\n",
      "         235       0.71      0.36      0.48        14\n",
      "         236       0.86      0.70      0.78        27\n",
      "         237       0.86      0.75      0.80        24\n",
      "         238       0.71      0.85      0.77        26\n",
      "         239       0.73      0.92      0.81        26\n",
      "         240       0.84      0.96      0.90        28\n",
      "         241       0.88      0.56      0.68        27\n",
      "         242       0.88      0.44      0.58        16\n",
      "         243       0.65      0.42      0.51        26\n",
      "         245       0.55      0.78      0.64        23\n",
      "         247       0.73      0.79      0.76        28\n",
      "         248       0.60      0.21      0.32        28\n",
      "         249       0.65      0.61      0.63        28\n",
      "         250       0.73      0.57      0.64        14\n",
      "         253       0.71      0.71      0.71        28\n",
      "         254       0.30      0.27      0.29        26\n",
      "         255       0.83      0.38      0.53        26\n",
      "         256       0.41      0.58      0.48        26\n",
      "         257       0.70      0.62      0.65        26\n",
      "         258       0.86      0.93      0.89        27\n",
      "         259       0.39      0.26      0.31        27\n",
      "         260       0.54      0.56      0.55        27\n",
      "         261       0.56      0.61      0.58        23\n",
      "         262       0.34      0.81      0.48        26\n",
      "         263       0.87      0.96      0.91        27\n",
      "         264       0.79      0.93      0.85        28\n",
      "         265       0.38      0.19      0.25        27\n",
      "         267       0.75      0.84      0.79        25\n",
      "         268       0.47      0.57      0.52        28\n",
      "         270       0.58      0.28      0.38        25\n",
      "         271       0.74      0.77      0.75        26\n",
      "         272       0.81      0.90      0.85        29\n",
      "         273       0.83      0.74      0.78        27\n",
      "         274       0.65      0.48      0.55        27\n",
      "         275       0.79      0.56      0.65        27\n",
      "         276       0.64      0.36      0.46        25\n",
      "         277       0.86      0.79      0.83        24\n",
      "         279       0.52      0.59      0.55        22\n",
      "         280       0.33      0.23      0.27        26\n",
      "         281       0.32      0.29      0.30        28\n",
      "         282       0.47      0.28      0.35        25\n",
      "         283       0.86      0.70      0.78        27\n",
      "         284       0.53      0.59      0.56        27\n",
      "         285       0.59      0.71      0.65        28\n",
      "         286       0.67      0.81      0.73        27\n",
      "         287       0.56      0.56      0.56        27\n",
      "         288       0.67      0.57      0.62        14\n",
      "         290       0.42      0.46      0.44        28\n",
      "         291       0.52      0.52      0.52        27\n",
      "         292       0.64      0.26      0.37        27\n",
      "         296       0.46      0.67      0.55        27\n",
      "         297       0.71      0.63      0.67        27\n",
      "         298       0.18      0.11      0.13        28\n",
      "         299       0.88      0.52      0.65        29\n",
      "         300       0.42      0.18      0.25        28\n",
      "         301       0.57      0.75      0.65        28\n",
      "         302       0.30      0.57      0.39        28\n",
      "         303       0.45      0.35      0.39        26\n",
      "         304       0.83      0.73      0.78        26\n",
      "         305       0.90      1.00      0.95        27\n",
      "         306       0.92      0.80      0.86        15\n",
      "         307       0.63      0.96      0.76        25\n",
      "         308       0.44      0.50      0.47        28\n",
      "         309       0.32      0.50      0.39        26\n",
      "         310       0.60      0.78      0.68        27\n",
      "         311       0.71      0.38      0.50        26\n",
      "         312       0.32      0.31      0.31        26\n",
      "         313       0.51      0.77      0.62        26\n",
      "         314       0.83      0.70      0.76        27\n",
      "         315       0.63      0.63      0.63        27\n",
      "         316       0.96      0.76      0.85        29\n",
      "         317       0.33      0.29      0.31        28\n",
      "         318       0.47      0.93      0.62        27\n",
      "         320       0.64      0.85      0.73        27\n",
      "         321       0.89      0.62      0.73        26\n",
      "         322       0.19      0.26      0.22        27\n",
      "         323       0.67      0.36      0.47        28\n",
      "         324       0.29      0.18      0.22        28\n",
      "         325       0.56      0.56      0.56        25\n",
      "         326       0.38      0.38      0.38        29\n",
      "         327       0.38      0.54      0.44        26\n",
      "         328       0.56      0.33      0.42        27\n",
      "         329       0.55      0.67      0.60        27\n",
      "         330       0.45      0.52      0.48        27\n",
      "         331       0.50      0.74      0.60        27\n",
      "         332       0.91      0.77      0.83        26\n",
      "         335       0.29      0.37      0.32        27\n",
      "         336       0.22      0.29      0.25        28\n",
      "         337       0.24      0.19      0.21        27\n",
      "         338       0.23      0.39      0.29        28\n",
      "         339       0.67      0.88      0.76        25\n",
      "         340       0.47      0.28      0.35        25\n",
      "         341       0.69      0.69      0.69        29\n",
      "         343       0.32      0.31      0.31        26\n",
      "         344       0.50      0.52      0.51        27\n",
      "         345       0.22      0.30      0.25        27\n",
      "         346       0.18      0.16      0.17        25\n",
      "         347       0.11      0.11      0.11        27\n",
      "         349       0.17      0.26      0.21        27\n",
      "         350       0.20      0.11      0.14        28\n",
      "         351       0.33      0.30      0.31        27\n",
      "         352       0.33      0.39      0.36        28\n",
      "         353       0.71      0.38      0.50        26\n",
      "         354       0.24      0.29      0.26        28\n",
      "         355       0.46      0.46      0.46        26\n",
      "         356       0.38      0.54      0.44        28\n",
      "         357       0.78      0.67      0.72        27\n",
      "         358       0.73      0.92      0.81        26\n",
      "         359       0.50      0.15      0.24        26\n",
      "         361       0.53      0.72      0.61        29\n",
      "         364       0.75      0.64      0.69        28\n",
      "         365       1.00      0.81      0.89        26\n",
      "         368       0.74      0.63      0.68        27\n",
      "         369       0.67      0.57      0.62        28\n",
      "         371       0.73      0.44      0.55        18\n",
      "         372       0.82      0.92      0.87        25\n",
      "         373       0.68      0.52      0.59        25\n",
      "         374       0.69      0.33      0.45        27\n",
      "         375       0.38      0.20      0.26        25\n",
      "         376       0.56      0.33      0.42        27\n",
      "         377       0.29      0.31      0.30        26\n",
      "         378       0.85      0.81      0.83        27\n",
      "         379       0.32      0.21      0.25        29\n",
      "         380       0.31      0.50      0.38        26\n",
      "         381       0.56      0.56      0.56        27\n",
      "         382       1.00      0.85      0.92        27\n",
      "         383       0.44      0.27      0.33        26\n",
      "         385       0.36      0.35      0.35        26\n",
      "         386       0.44      0.62      0.52        26\n",
      "         387       0.33      0.23      0.27        26\n",
      "         388       0.33      0.18      0.23        28\n",
      "         389       0.57      0.48      0.52        27\n",
      "         392       0.33      0.41      0.37        27\n",
      "         394       0.24      0.26      0.25        27\n",
      "         395       0.48      0.44      0.46        27\n",
      "         396       0.65      0.63      0.64        27\n",
      "         397       0.40      0.52      0.45        27\n",
      "         398       0.78      0.78      0.78        27\n",
      "         399       0.19      0.31      0.24        26\n",
      "         400       0.69      0.50      0.58        22\n",
      "         401       0.52      0.48      0.50        29\n",
      "         402       0.53      0.62      0.57        26\n",
      "         403       0.40      0.07      0.12        27\n",
      "         404       0.63      0.81      0.71        27\n",
      "         405       0.33      0.33      0.33        27\n",
      "         406       0.39      0.54      0.45        28\n",
      "         407       0.57      0.62      0.59        26\n",
      "         408       0.36      0.44      0.40        27\n",
      "         411       0.40      0.23      0.29        26\n",
      "         412       0.67      0.64      0.65        28\n",
      "         413       0.45      0.38      0.42        13\n",
      "         414       0.29      0.55      0.38        29\n",
      "         415       0.21      0.15      0.17        27\n",
      "         416       0.56      0.20      0.29        25\n",
      "         417       0.35      0.21      0.27        28\n",
      "         418       0.31      0.45      0.37        29\n",
      "         419       0.08      0.04      0.05        27\n",
      "         420       0.58      0.70      0.63        27\n",
      "         421       0.64      0.70      0.67        23\n",
      "         422       0.57      0.29      0.38        28\n",
      "         424       0.47      0.52      0.49        27\n",
      "         425       0.53      0.40      0.45        25\n",
      "         426       0.43      0.33      0.38        27\n",
      "         427       0.75      0.33      0.46        18\n",
      "         428       0.43      0.46      0.45        28\n",
      "         429       0.62      0.75      0.68        28\n",
      "         430       0.30      0.37      0.33        27\n",
      "         431       0.85      0.58      0.69        19\n",
      "         432       0.67      0.15      0.25        26\n",
      "         433       0.12      0.19      0.15        27\n",
      "         434       0.38      0.42      0.40        26\n",
      "         435       0.56      0.56      0.56        25\n",
      "         436       0.28      0.25      0.26        28\n",
      "         437       0.87      0.77      0.82        26\n",
      "         439       0.45      0.52      0.48        25\n",
      "         440       0.70      0.62      0.65        26\n",
      "         441       0.75      0.86      0.80        28\n",
      "         443       0.45      0.36      0.40        28\n",
      "         444       0.30      0.29      0.29        28\n",
      "         445       0.53      0.59      0.56        27\n",
      "         446       0.28      0.44      0.34        25\n",
      "         447       0.48      0.58      0.53        26\n",
      "         448       0.50      0.52      0.51        27\n",
      "         449       0.36      0.29      0.32        28\n",
      "         450       0.32      0.28      0.30        29\n",
      "         451       0.52      0.48      0.50        27\n",
      "         452       0.74      0.56      0.64        25\n",
      "         453       0.55      0.61      0.58        28\n",
      "         454       0.67      0.69      0.68        26\n",
      "         455       0.79      0.70      0.75        27\n",
      "         456       0.28      0.46      0.35        28\n",
      "         457       0.40      0.44      0.42        27\n",
      "         458       0.36      0.48      0.41        27\n",
      "         459       0.62      0.59      0.60        27\n",
      "         460       0.64      0.69      0.67        26\n",
      "         461       0.42      0.38      0.40        29\n",
      "         462       0.77      0.63      0.69        27\n",
      "         463       0.86      0.86      0.86        28\n",
      "         465       0.80      0.48      0.60        25\n",
      "         466       0.38      0.12      0.18        26\n",
      "         467       0.35      0.26      0.30        27\n",
      "         468       0.25      0.07      0.11        27\n",
      "         469       0.29      0.27      0.28        26\n",
      "         470       0.56      0.68      0.61        28\n",
      "         471       0.36      0.18      0.24        28\n",
      "         472       0.45      0.46      0.46        28\n",
      "         473       0.29      0.29      0.29        28\n",
      "         474       0.71      0.58      0.64        26\n",
      "         475       0.46      0.43      0.44        28\n",
      "         476       0.11      0.15      0.12        26\n",
      "         477       0.79      0.56      0.65        27\n",
      "         478       0.33      0.22      0.27        27\n",
      "         479       0.34      0.50      0.41        28\n",
      "         480       0.29      0.46      0.36        28\n",
      "         481       0.55      0.44      0.49        27\n",
      "         482       0.24      0.48      0.32        27\n",
      "         483       0.74      0.85      0.79        27\n",
      "         484       0.56      0.32      0.41        28\n",
      "         485       0.72      0.64      0.68        28\n",
      "         486       0.48      0.44      0.46        27\n",
      "         487       0.37      0.25      0.30        28\n",
      "         488       0.37      0.28      0.32        25\n",
      "         489       0.43      0.38      0.41        26\n",
      "         490       0.36      0.38      0.37        26\n",
      "         491       0.24      0.29      0.26        28\n",
      "         492       0.87      0.74      0.80        27\n",
      "         493       0.38      0.39      0.39        28\n",
      "         494       0.38      0.31      0.34        29\n",
      "         495       1.00      0.85      0.92        27\n",
      "         496       0.26      0.22      0.24        27\n",
      "         497       0.71      0.61      0.65        28\n",
      "         498       0.09      0.07      0.08        27\n",
      "         499       0.58      0.54      0.56        28\n",
      "         500       0.00      0.00      0.00        28\n",
      "         501       0.35      0.26      0.30        27\n",
      "         502       0.47      0.54      0.50        26\n",
      "         503       0.40      0.52      0.45        27\n",
      "         504       0.14      0.14      0.14        28\n",
      "         505       0.38      0.37      0.38        27\n",
      "         506       0.39      0.59      0.47        27\n",
      "         507       0.26      0.28      0.27        25\n",
      "         508       0.31      0.38      0.34        29\n",
      "         509       0.35      0.67      0.46        27\n",
      "         510       0.46      0.79      0.58        28\n",
      "         511       0.10      0.07      0.09        27\n",
      "         512       0.78      0.93      0.85        27\n",
      "         513       0.56      0.93      0.69        27\n",
      "         514       0.32      0.25      0.28        28\n",
      "         515       0.50      0.32      0.39        28\n",
      "         516       0.38      0.57      0.46        28\n",
      "         517       0.51      0.70      0.59        27\n",
      "         519       0.50      0.57      0.53        28\n",
      "         520       0.53      0.64      0.58        25\n",
      "         521       0.87      0.96      0.92        28\n",
      "         522       0.74      0.89      0.81        28\n",
      "         523       0.73      0.62      0.67        26\n",
      "         524       0.41      0.70      0.52        27\n",
      "         525       0.50      0.41      0.45        27\n",
      "         526       0.50      0.60      0.55        25\n",
      "         527       0.33      0.21      0.26        28\n",
      "         528       0.79      0.96      0.87        28\n",
      "         529       0.16      0.19      0.17        27\n",
      "         530       0.42      0.45      0.43        22\n",
      "         531       0.38      0.38      0.38        26\n",
      "         532       0.88      0.78      0.82        27\n",
      "         533       0.50      0.61      0.55        28\n",
      "         534       0.58      0.58      0.58        26\n",
      "         535       0.42      0.52      0.47        27\n",
      "         536       0.74      0.52      0.61        27\n",
      "         537       0.31      0.19      0.24        26\n",
      "         538       0.63      0.65      0.64        26\n",
      "         539       0.60      0.78      0.68        27\n",
      "         540       0.36      0.32      0.34        28\n",
      "         541       0.41      0.50      0.45        26\n",
      "         542       0.50      0.62      0.55        26\n",
      "         543       0.72      0.62      0.67        29\n",
      "         544       0.65      0.58      0.61        26\n",
      "         545       0.80      0.71      0.75        28\n",
      "         546       0.68      0.78      0.72        27\n",
      "         547       0.25      0.62      0.35        29\n",
      "         548       0.23      0.29      0.25        28\n",
      "         549       0.33      0.26      0.29        27\n",
      "         550       0.26      0.29      0.27        28\n",
      "         551       0.41      0.48      0.44        27\n",
      "         552       0.45      0.54      0.49        26\n",
      "         553       0.18      0.14      0.16        28\n",
      "         554       0.31      0.39      0.34        28\n",
      "         555       0.75      0.83      0.79        29\n",
      "         556       0.33      0.26      0.29        27\n",
      "         557       0.27      0.31      0.29        26\n",
      "         558       0.25      0.17      0.20        29\n",
      "         559       0.18      0.08      0.11        26\n",
      "         560       0.42      0.36      0.38        28\n",
      "         561       0.30      0.36      0.33        28\n",
      "         562       0.29      0.08      0.12        26\n",
      "         603       0.64      0.50      0.56        28\n",
      "         604       0.57      0.43      0.49        28\n",
      "         609       0.10      0.08      0.09        26\n",
      "         769       0.55      0.86      0.67        28\n",
      "         779       0.21      0.15      0.18        26\n",
      "         780       0.46      0.59      0.52        27\n",
      "         781       0.68      0.75      0.71        28\n",
      "         782       0.68      0.72      0.70        29\n",
      "         783       0.58      0.67      0.62        27\n",
      "         784       1.00      0.86      0.93        29\n",
      "         785       0.57      0.80      0.67        25\n",
      "         786       1.00      0.70      0.83        27\n",
      "         825       0.86      0.64      0.73        28\n",
      "         826       0.88      0.26      0.40        27\n",
      "         827       0.45      0.69      0.55        26\n",
      "         829       0.69      0.38      0.49        29\n",
      "         830       1.00      0.70      0.83        27\n",
      "         831       0.60      0.54      0.57        28\n",
      "         833       0.77      0.67      0.71        15\n",
      "         834       0.92      0.85      0.88        26\n",
      "         836       0.67      0.85      0.75        26\n",
      "         837       0.80      0.74      0.77        27\n",
      "         838       0.89      0.57      0.70        28\n",
      "         839       0.57      0.57      0.57        28\n",
      "         840       0.48      0.71      0.57        28\n",
      "         843       0.81      0.48      0.60        27\n",
      "         845       0.84      0.84      0.84        25\n",
      "         846       0.96      0.93      0.95        28\n",
      "         847       0.74      0.77      0.75        26\n",
      "         848       0.57      0.89      0.70        27\n",
      "         849       0.87      0.52      0.65        25\n",
      "         850       1.00      0.58      0.73        19\n",
      "         851       0.24      0.14      0.18        28\n",
      "         852       0.88      0.79      0.83        28\n",
      "         853       0.94      0.56      0.70        27\n",
      "         854       1.00      0.61      0.76        28\n",
      "         855       0.88      0.81      0.84        26\n",
      "         857       0.40      0.22      0.29        18\n",
      "         858       0.59      0.85      0.70        26\n",
      "         862       0.58      0.79      0.67        28\n",
      "         863       0.70      0.62      0.65        26\n",
      "         864       0.46      0.52      0.49        25\n",
      "         865       0.88      0.81      0.84        26\n",
      "         866       0.60      0.69      0.64        26\n",
      "         867       0.87      0.87      0.87        23\n",
      "         869       0.92      0.67      0.77        18\n",
      "         871       0.60      0.35      0.44        26\n",
      "         872       0.64      0.89      0.75        28\n",
      "         873       0.77      0.92      0.84        25\n",
      "         874       0.67      0.81      0.73        27\n",
      "         875       0.22      0.15      0.18        26\n",
      "         878       0.84      0.96      0.90        27\n",
      "         881       0.82      0.82      0.82        28\n",
      "         882       0.59      0.48      0.53        27\n",
      "         883       0.77      0.71      0.74        14\n",
      "         884       0.57      0.62      0.59        13\n",
      "         885       0.68      0.61      0.64        28\n",
      "         887       0.58      0.67      0.62        27\n",
      "         888       0.79      0.70      0.75        27\n",
      "         889       0.70      0.78      0.74        27\n",
      "         890       0.64      0.52      0.57        27\n",
      "         891       0.00      0.00      0.00        26\n",
      "         892       0.47      0.30      0.37        23\n",
      "         893       0.95      0.78      0.86        27\n",
      "         894       0.19      0.26      0.22        27\n",
      "         897       0.80      0.43      0.56        28\n",
      "         899       0.94      0.63      0.76        27\n",
      "         900       0.71      0.36      0.48        28\n",
      "         901       0.62      0.69      0.65        26\n",
      "         902       0.53      0.30      0.38        27\n",
      "         903       0.67      0.40      0.50        25\n",
      "         904       0.42      0.52      0.47        27\n",
      "         905       0.74      0.85      0.79        27\n",
      "         906       0.71      0.37      0.49        27\n",
      "         907       0.61      0.66      0.63        29\n",
      "         908       0.87      0.74      0.80        27\n",
      "         909       0.70      0.54      0.61        26\n",
      "         910       0.54      0.48      0.51        27\n",
      "         911       0.83      0.37      0.51        27\n",
      "         912       0.50      0.48      0.49        27\n",
      "         913       0.52      0.56      0.54        27\n",
      "         914       0.64      0.81      0.71        26\n",
      "         915       0.44      0.39      0.42        28\n",
      "         916       0.48      0.62      0.54        26\n",
      "         917       0.62      0.74      0.68        27\n",
      "         918       0.61      0.52      0.56        27\n",
      "         919       1.00      0.54      0.70        26\n",
      "         920       0.73      0.57      0.64        28\n",
      "         922       0.90      0.60      0.72        15\n",
      "         923       0.88      0.79      0.83        19\n",
      "         924       0.65      0.45      0.53        29\n",
      "         925       0.56      0.79      0.66        29\n",
      "         926       0.38      0.11      0.17        28\n",
      "         927       0.92      0.76      0.83        29\n",
      "         929       0.41      0.88      0.56        26\n",
      "         930       0.89      0.62      0.73        26\n",
      "         931       0.25      0.29      0.27        28\n",
      "         933       0.71      0.48      0.57        25\n",
      "         934       0.56      0.52      0.54        27\n",
      "         935       0.63      0.61      0.62        28\n",
      "         936       0.67      0.67      0.67        27\n",
      "         937       0.95      0.71      0.82        28\n",
      "         938       0.40      0.38      0.39        26\n",
      "         939       0.69      0.55      0.61        20\n",
      "         940       0.45      0.36      0.40        28\n",
      "         942       0.45      0.33      0.38        15\n",
      "         943       0.48      0.75      0.58        28\n",
      "         944       0.92      0.85      0.88        26\n",
      "         945       0.62      0.72      0.67        29\n",
      "         946       0.55      0.41      0.47        27\n",
      "         947       0.86      0.93      0.89        27\n",
      "         948       0.87      0.74      0.80        27\n",
      "         949       0.79      0.69      0.73        16\n",
      "         950       0.68      0.81      0.74        16\n",
      "         951       0.20      0.14      0.17        28\n",
      "         952       0.50      0.25      0.33        28\n",
      "         954       0.50      0.52      0.51        27\n",
      "         955       0.49      0.64      0.55        28\n",
      "         956       0.50      0.50      0.50        26\n",
      "         957       0.48      0.41      0.44        27\n",
      "         958       0.25      0.22      0.24        27\n",
      "         959       0.59      0.70      0.64        27\n",
      "         961       0.80      0.46      0.59        26\n",
      "         962       0.71      0.65      0.68        26\n",
      "         963       0.82      0.56      0.67        16\n",
      "         965       0.47      0.31      0.38        29\n",
      "         967       0.82      0.54      0.65        26\n",
      "         968       0.31      0.30      0.30        27\n",
      "         969       0.47      0.35      0.40        26\n",
      "         970       0.64      0.35      0.45        26\n",
      "         971       0.44      0.56      0.49        25\n",
      "         972       0.32      0.33      0.33        27\n",
      "         973       0.27      0.12      0.16        26\n",
      "         974       0.29      0.50      0.36        28\n",
      "         975       0.28      0.59      0.38        27\n",
      "         976       0.67      0.29      0.40        28\n",
      "         977       0.33      0.57      0.42        28\n",
      "         978       0.38      0.38      0.38        26\n",
      "         979       0.18      0.11      0.13        28\n",
      "         980       0.61      0.39      0.48        28\n",
      "         981       0.87      0.71      0.78        28\n",
      "         982       0.75      0.64      0.69        28\n",
      "         983       0.84      0.81      0.82        26\n",
      "         985       0.58      0.60      0.59        25\n",
      "         986       0.79      0.68      0.73        28\n",
      "         987       0.75      0.44      0.56        27\n",
      "         988       0.88      0.78      0.82        27\n",
      "         989       0.06      0.04      0.04        28\n",
      "         990       0.60      0.44      0.51        27\n",
      "         991       0.40      0.37      0.38        27\n",
      "         992       0.26      0.37      0.31        27\n",
      "         993       0.19      0.18      0.19        28\n",
      "         994       0.16      0.12      0.13        26\n",
      "         996       0.57      0.74      0.65        27\n",
      "         997       0.61      0.74      0.67        27\n",
      "         998       0.70      0.70      0.70        27\n",
      "         999       0.35      0.39      0.37        28\n",
      "        1000       0.61      0.52      0.56        27\n",
      "        1001       0.56      0.52      0.54        29\n",
      "        1002       0.71      0.19      0.29        27\n",
      "        1003       0.33      0.23      0.27        26\n",
      "        1004       0.31      0.18      0.23        28\n",
      "        1005       0.30      0.56      0.39        27\n",
      "        1006       0.73      0.81      0.77        27\n",
      "        1007       0.74      0.71      0.73        28\n",
      "        1008       0.57      0.89      0.70        27\n",
      "        1009       0.55      0.46      0.50        26\n",
      "        1010       0.65      0.61      0.63        28\n",
      "        1011       0.36      0.31      0.33        26\n",
      "        1012       0.50      0.46      0.48        26\n",
      "        1014       0.71      0.89      0.79        28\n",
      "        1016       0.59      0.80      0.68        25\n",
      "        1017       0.30      0.44      0.36        27\n",
      "        1018       0.13      0.14      0.14        28\n",
      "        1019       0.36      0.48      0.41        29\n",
      "        1020       0.33      0.32      0.33        28\n",
      "        1021       0.59      0.81      0.69        27\n",
      "        1022       0.48      0.64      0.55        25\n",
      "        1023       0.00      0.00      0.00        28\n",
      "        1024       0.75      0.43      0.55        28\n",
      "        1025       0.38      0.30      0.33        27\n",
      "        1026       0.40      0.54      0.46        26\n",
      "        1027       0.13      0.07      0.09        28\n",
      "        1028       0.38      0.41      0.39        27\n",
      "        1029       0.08      0.04      0.05        25\n",
      "        1030       0.28      0.25      0.26        28\n",
      "        1031       0.88      0.25      0.39        28\n",
      "        1033       0.00      0.00      0.00        28\n",
      "        1034       0.24      0.36      0.29        28\n",
      "        1035       0.23      0.19      0.21        26\n",
      "        1036       0.10      0.04      0.05        28\n",
      "        1037       0.43      0.35      0.38        26\n",
      "        1038       0.47      0.78      0.58        27\n",
      "        1039       0.16      0.19      0.17        26\n",
      "        1040       0.51      0.81      0.63        27\n",
      "        1042       0.29      0.22      0.25        27\n",
      "        1043       0.11      0.08      0.09        26\n",
      "        1044       0.22      0.30      0.25        27\n",
      "        1045       0.65      0.65      0.65        26\n",
      "        1046       0.51      0.62      0.56        29\n",
      "        1047       0.05      0.04      0.04        27\n",
      "        1048       0.38      0.33      0.35        27\n",
      "        1049       0.24      0.22      0.23        27\n",
      "        1050       0.65      0.92      0.76        26\n",
      "        1051       0.05      0.04      0.04        26\n",
      "        1052       0.35      0.30      0.32        27\n",
      "        1053       0.17      0.04      0.06        26\n",
      "        1054       0.18      0.07      0.11        27\n",
      "        1055       0.52      0.59      0.55        27\n",
      "        1056       0.61      0.68      0.64        28\n",
      "        1057       0.67      0.74      0.70        27\n",
      "        1058       0.56      0.76      0.64        25\n",
      "        1059       0.45      0.56      0.50        27\n",
      "        1060       0.45      0.70      0.55        27\n",
      "        1061       0.78      0.81      0.79        26\n",
      "        1062       0.31      0.62      0.42        26\n",
      "        1063       0.70      0.52      0.60        27\n",
      "        1064       0.57      0.29      0.38        28\n",
      "        1065       0.62      0.90      0.73        29\n",
      "        1066       0.23      0.45      0.31        29\n",
      "        1067       0.31      0.20      0.24        25\n",
      "        1068       0.67      0.57      0.62        28\n",
      "        1069       0.22      0.22      0.22        27\n",
      "        1070       0.54      0.68      0.60        28\n",
      "        1071       0.29      0.39      0.33        28\n",
      "        1072       0.81      0.61      0.69        28\n",
      "        1073       0.22      0.07      0.11        27\n",
      "        1074       0.31      0.14      0.20        28\n",
      "        1075       0.49      0.59      0.53        29\n",
      "        1076       0.17      0.08      0.11        25\n",
      "        1077       0.14      0.15      0.15        27\n",
      "        1078       0.61      0.70      0.66        27\n",
      "        1079       0.45      0.65      0.53        26\n",
      "        1080       0.58      0.73      0.64        26\n",
      "        1081       0.40      0.24      0.30        25\n",
      "        1082       0.40      0.86      0.55        28\n",
      "        1083       0.35      0.52      0.42        27\n",
      "        1085       0.33      0.19      0.24        26\n",
      "        1086       0.35      0.23      0.28        26\n",
      "        1088       0.19      0.24      0.21        25\n",
      "        1089       0.08      0.07      0.07        28\n",
      "        1090       0.91      0.77      0.83        26\n",
      "        1091       0.29      0.32      0.31        28\n",
      "        1092       0.87      1.00      0.93        27\n",
      "        1093       0.38      0.58      0.45        26\n",
      "        1094       0.30      0.46      0.36        26\n",
      "        1095       0.89      0.89      0.89        27\n",
      "        1096       0.54      0.26      0.35        27\n",
      "        1097       0.74      0.63      0.68        27\n",
      "        1098       0.70      0.66      0.68        29\n",
      "        1099       0.77      0.86      0.81        28\n",
      "        1100       0.67      0.81      0.73        27\n",
      "        1101       0.35      0.21      0.27        28\n",
      "        1102       0.27      0.14      0.19        28\n",
      "        1103       0.38      0.12      0.18        26\n",
      "        1104       0.81      0.81      0.81        27\n",
      "        1105       0.86      0.44      0.59        27\n",
      "        1106       0.82      0.54      0.65        26\n",
      "        1107       0.36      0.44      0.40        27\n",
      "        1108       0.74      0.61      0.67        28\n",
      "        1109       0.76      0.46      0.58        28\n",
      "        1110       0.29      0.07      0.11        29\n",
      "        1112       0.77      0.37      0.50        27\n",
      "        1113       0.74      0.80      0.77        25\n",
      "        1114       0.89      0.57      0.70        28\n",
      "        1115       1.00      0.35      0.52        23\n",
      "        1116       0.92      0.81      0.86        27\n",
      "        1117       0.59      0.37      0.45        27\n",
      "        1118       0.52      0.39      0.45        28\n",
      "        1119       0.21      0.23      0.22        26\n",
      "        1120       0.25      0.32      0.28        28\n",
      "        1121       0.87      0.71      0.78        28\n",
      "        1122       0.79      0.70      0.75        27\n",
      "        1123       0.94      0.65      0.77        26\n",
      "        1124       0.65      0.52      0.58        25\n",
      "        1125       0.38      0.48      0.43        27\n",
      "        1126       0.75      0.54      0.63        28\n",
      "        1129       0.55      0.65      0.60        26\n",
      "        1130       0.34      0.46      0.39        26\n",
      "        1132       0.82      0.86      0.84        21\n",
      "        1133       0.59      0.48      0.53        27\n",
      "        1135       0.57      0.16      0.25        25\n",
      "        1136       0.25      0.16      0.20        25\n",
      "        1137       0.96      0.85      0.90        26\n",
      "        1138       0.50      0.15      0.23        27\n",
      "        1139       0.13      0.07      0.10        27\n",
      "        1140       0.73      0.42      0.54        26\n",
      "        1141       0.86      0.89      0.88        28\n",
      "        1142       0.27      0.44      0.33        27\n",
      "        1143       0.39      0.44      0.41        27\n",
      "        1144       0.50      0.59      0.54        27\n",
      "        1145       0.71      0.77      0.74        26\n",
      "        1146       0.68      0.68      0.68        25\n",
      "        1147       0.22      0.22      0.22        27\n",
      "        1148       0.47      0.70      0.57        27\n",
      "        1149       0.72      0.64      0.68        28\n",
      "        1150       0.94      0.58      0.71        26\n",
      "        1151       0.28      0.19      0.23        26\n",
      "        1152       0.53      0.63      0.58        27\n",
      "        1153       0.65      0.58      0.61        26\n",
      "        1154       0.77      0.92      0.84        26\n",
      "        1155       0.32      0.32      0.32        28\n",
      "        1156       0.39      0.65      0.49        26\n",
      "        1157       0.70      0.81      0.75        26\n",
      "        1158       0.15      0.26      0.19        27\n",
      "        1159       0.54      0.78      0.64        27\n",
      "        1160       0.67      0.81      0.73        27\n",
      "        1161       0.67      0.43      0.52        14\n",
      "        1163       0.35      0.64      0.45        25\n",
      "        1165       0.62      0.19      0.29        26\n",
      "        1166       0.15      0.24      0.19        29\n",
      "        1167       0.03      0.04      0.03        26\n",
      "        1168       0.15      0.07      0.10        27\n",
      "        1169       0.40      0.31      0.35        26\n",
      "        1170       0.36      0.48      0.41        27\n",
      "        1171       0.53      0.68      0.60        25\n",
      "        1172       0.64      0.57      0.60        28\n",
      "        1173       0.74      0.52      0.61        27\n",
      "        1174       0.75      0.56      0.64        27\n",
      "        1175       0.33      0.38      0.35        29\n",
      "        1176       0.83      0.70      0.76        27\n",
      "        1177       0.41      0.44      0.42        25\n",
      "        1178       0.95      0.74      0.83        27\n",
      "        1179       0.79      0.39      0.52        28\n",
      "        1180       0.54      0.50      0.52        28\n",
      "        1181       0.85      0.39      0.54        28\n",
      "        1182       0.35      0.26      0.30        27\n",
      "        1183       0.65      0.80      0.71        25\n",
      "        1184       0.83      0.74      0.78        27\n",
      "        1185       0.86      0.86      0.86        29\n",
      "        1186       0.55      0.42      0.48        26\n",
      "        1187       0.75      0.78      0.76        27\n",
      "        1188       0.83      0.70      0.76        27\n",
      "        1189       0.54      0.76      0.63        25\n",
      "        1190       0.82      0.67      0.73        27\n",
      "        1191       0.64      0.62      0.63        26\n",
      "        1192       0.85      0.92      0.88        25\n",
      "        1193       0.20      0.19      0.19        27\n",
      "        1194       0.39      0.44      0.42        25\n",
      "        1195       0.23      0.35      0.27        26\n",
      "        1196       0.32      0.27      0.29        26\n",
      "        1197       0.29      0.21      0.24        28\n",
      "        1198       0.46      0.43      0.44        28\n",
      "        1199       0.61      0.74      0.67        27\n",
      "        1200       0.30      0.33      0.32        27\n",
      "        1201       0.24      0.32      0.27        25\n",
      "        1202       0.50      0.59      0.54        27\n",
      "        1203       0.25      0.12      0.16        26\n",
      "        1204       0.46      0.48      0.47        27\n",
      "        1205       0.55      0.65      0.60        26\n",
      "        1206       0.19      0.21      0.20        29\n",
      "        1207       0.50      0.48      0.49        27\n",
      "        1208       0.07      0.08      0.07        26\n",
      "        1210       0.71      0.54      0.61        28\n",
      "        1211       0.67      0.93      0.78        28\n",
      "        1212       0.40      0.37      0.38        27\n",
      "        1213       0.48      0.36      0.41        28\n",
      "        1214       0.40      0.37      0.38        27\n",
      "        1215       0.43      0.56      0.48        27\n",
      "        1216       0.60      0.33      0.43        27\n",
      "        1217       0.09      0.07      0.08        27\n",
      "        1218       0.25      0.30      0.27        27\n",
      "        1219       0.32      0.43      0.36        28\n",
      "        1220       0.44      0.55      0.49        29\n",
      "        1221       0.35      0.27      0.30        26\n",
      "        1222       0.13      0.12      0.12        26\n",
      "        1223       0.40      0.44      0.42        27\n",
      "        1224       0.28      0.46      0.35        28\n",
      "        1225       0.09      0.11      0.10        27\n",
      "        1226       0.41      0.32      0.36        28\n",
      "        1227       0.34      0.81      0.48        26\n",
      "        1228       0.28      0.29      0.28        28\n",
      "        1229       0.38      0.23      0.29        26\n",
      "        1230       0.58      0.68      0.62        28\n",
      "        1240       0.79      0.52      0.63        21\n",
      "        1248       0.95      0.78      0.86        27\n",
      "        1249       0.55      0.44      0.49        27\n",
      "        1250       0.75      0.22      0.34        27\n",
      "        1251       0.67      0.08      0.14        26\n",
      "        1254       0.65      0.48      0.55        27\n",
      "        1257       0.53      0.40      0.45        25\n",
      "        1258       0.84      0.84      0.84        25\n",
      "        1259       0.61      0.89      0.72        28\n",
      "        1260       0.93      0.96      0.94        26\n",
      "        1261       0.13      0.14      0.14        28\n",
      "        1262       0.52      0.52      0.52        27\n",
      "        1263       0.48      0.44      0.46        27\n",
      "        1264       0.43      0.35      0.38        26\n",
      "        1265       0.18      0.23      0.20        26\n",
      "        1266       0.15      0.11      0.13        27\n",
      "        1267       0.33      0.37      0.35        27\n",
      "        1268       0.16      0.22      0.18        27\n",
      "        1269       0.58      0.56      0.57        27\n",
      "        1270       0.65      0.71      0.68        28\n",
      "        1271       0.54      0.50      0.52        28\n",
      "        1272       0.19      0.17      0.18        29\n",
      "        1273       0.32      0.23      0.27        26\n",
      "        1274       0.66      0.85      0.74        27\n",
      "        1275       0.91      0.78      0.84        27\n",
      "        1276       0.76      0.96      0.85        26\n",
      "        1277       0.52      0.54      0.53        26\n",
      "        1278       0.62      0.69      0.65        26\n",
      "        1279       0.34      0.41      0.37        27\n",
      "        1280       0.38      0.50      0.43        26\n",
      "        1281       0.32      0.43      0.37        28\n",
      "        1282       0.38      0.41      0.39        27\n",
      "        1283       0.78      0.75      0.76        28\n",
      "        1284       0.69      0.74      0.71        27\n",
      "        1285       0.63      0.44      0.52        27\n",
      "        1286       0.31      0.19      0.23        27\n",
      "        1287       0.18      0.19      0.19        26\n",
      "        1288       0.54      0.50      0.52        26\n",
      "        1289       0.48      0.41      0.44        27\n",
      "        1290       0.65      0.50      0.57        26\n",
      "        1291       0.82      0.33      0.47        27\n",
      "        1292       0.23      0.39      0.29        28\n",
      "        1293       0.59      0.36      0.44        28\n",
      "        1294       0.09      0.22      0.12        27\n",
      "        1295       0.68      0.56      0.61        27\n",
      "        1296       0.52      0.58      0.55        26\n",
      "        1299       0.74      0.54      0.62        26\n",
      "        1303       0.27      0.11      0.16        27\n",
      "        1304       0.45      0.35      0.39        26\n",
      "        1305       0.82      0.36      0.50        25\n",
      "        1308       0.74      0.61      0.67        28\n",
      "        1309       0.60      0.43      0.50        28\n",
      "        1310       0.41      0.46      0.44        26\n",
      "        1311       0.61      0.71      0.66        28\n",
      "        1312       0.43      0.46      0.45        28\n",
      "        1313       0.51      0.70      0.59        27\n",
      "        1314       0.66      0.72      0.69        29\n",
      "        1315       0.35      0.22      0.27        27\n",
      "        1316       0.74      0.82      0.78        28\n",
      "        1317       0.09      0.04      0.05        28\n",
      "        1318       0.51      0.81      0.63        26\n",
      "        1319       0.23      0.37      0.29        27\n",
      "        1320       0.62      0.38      0.48        26\n",
      "        1322       0.39      0.32      0.35        28\n",
      "        1326       0.19      0.22      0.21        27\n",
      "        1327       0.27      0.42      0.33        26\n",
      "        1328       0.89      0.83      0.86        29\n",
      "        1330       0.50      0.12      0.19        25\n",
      "        1331       0.21      0.11      0.15        27\n",
      "        1332       0.63      0.61      0.62        28\n",
      "        1333       0.86      0.89      0.87        27\n",
      "        1334       0.14      0.15      0.15        27\n",
      "        1336       0.38      0.21      0.27        28\n",
      "        1337       0.82      0.69      0.75        26\n",
      "        1339       0.47      0.68      0.56        28\n",
      "        1340       0.71      0.61      0.65        28\n",
      "        1341       0.68      0.73      0.70        26\n",
      "        1343       0.90      0.73      0.81        26\n",
      "        1344       0.69      0.35      0.46        26\n",
      "        1345       0.86      0.73      0.79        26\n",
      "        1346       0.27      0.22      0.24        27\n",
      "        1347       0.40      0.29      0.33        28\n",
      "        1348       0.43      0.23      0.30        26\n",
      "        1349       0.40      0.21      0.28        28\n",
      "        1350       0.31      0.66      0.42        29\n",
      "        1351       0.77      0.36      0.49        28\n",
      "        1352       0.86      0.66      0.75        29\n",
      "        1353       0.83      0.70      0.76        27\n",
      "        1354       0.79      0.96      0.87        28\n",
      "        1355       0.84      0.62      0.71        26\n",
      "        1356       0.75      0.75      0.75        28\n",
      "        1357       0.53      0.31      0.39        26\n",
      "        1358       0.65      0.92      0.76        26\n",
      "        1360       0.68      0.58      0.62        26\n",
      "        1361       0.57      0.93      0.70        27\n",
      "        1363       0.90      0.64      0.75        28\n",
      "        1364       0.93      1.00      0.96        26\n",
      "        1365       0.43      0.21      0.29        28\n",
      "        1366       0.86      0.89      0.87        27\n",
      "        1367       0.68      0.70      0.69        27\n",
      "        1368       0.76      0.70      0.73        27\n",
      "        1369       0.27      0.11      0.16        27\n",
      "        1370       0.62      0.77      0.69        26\n",
      "        1371       0.79      0.85      0.82        27\n",
      "        1373       0.40      0.62      0.48        26\n",
      "        1374       0.38      0.36      0.37        28\n",
      "        1376       0.61      0.63      0.62        27\n",
      "        1377       1.00      1.00      1.00        25\n",
      "        1378       0.79      0.73      0.76        26\n",
      "        1379       0.76      0.93      0.84        28\n",
      "        1380       0.66      0.68      0.67        28\n",
      "        1382       0.67      0.36      0.47        28\n",
      "        1383       0.94      0.54      0.68        28\n",
      "        1384       0.47      0.63      0.54        27\n",
      "        1385       0.65      0.85      0.73        26\n",
      "        1386       0.84      0.96      0.90        28\n",
      "        1387       0.65      0.74      0.69        27\n",
      "        1388       0.83      0.67      0.74        15\n",
      "        1389       0.78      0.81      0.79        26\n",
      "        1390       0.82      0.67      0.73        27\n",
      "        1391       0.65      0.42      0.51        26\n",
      "        1393       0.69      0.89      0.77        27\n",
      "        1394       1.00      0.68      0.81        19\n",
      "        1396       0.34      0.48      0.40        27\n",
      "        1397       0.74      0.88      0.81        26\n",
      "        1399       0.63      0.70      0.67        27\n",
      "        1400       0.64      0.75      0.69        28\n",
      "        1401       0.86      0.96      0.91        25\n",
      "        1402       0.93      0.56      0.70        25\n",
      "        1405       0.88      0.58      0.70        26\n",
      "        1408       0.67      0.71      0.69        28\n",
      "        1410       0.50      0.61      0.55        18\n",
      "        1412       0.67      0.86      0.75        28\n",
      "        1413       0.92      0.86      0.89        14\n",
      "        1415       0.76      0.73      0.75        26\n",
      "        1416       0.90      0.56      0.69        16\n",
      "        1417       0.81      0.81      0.81        26\n",
      "        1418       0.80      0.89      0.84        27\n",
      "        1419       0.81      0.96      0.88        26\n",
      "        1420       0.73      0.57      0.64        28\n",
      "        1421       0.67      0.50      0.57        28\n",
      "        1423       1.00      0.96      0.98        28\n",
      "        1424       0.92      0.82      0.87        28\n",
      "        1425       0.52      0.50      0.51        24\n",
      "        1426       0.67      0.86      0.75        28\n",
      "        1427       0.57      0.59      0.58        29\n",
      "        1428       0.64      0.54      0.58        26\n",
      "        1429       0.50      0.19      0.28        26\n",
      "        1431       0.43      0.46      0.45        28\n",
      "        1438       0.64      0.67      0.65        27\n",
      "        1439       0.76      0.48      0.59        27\n",
      "        1440       0.46      0.32      0.37        19\n",
      "        1441       0.20      0.41      0.27        27\n",
      "        1442       0.65      0.48      0.55        27\n",
      "        1444       0.78      0.86      0.82        21\n",
      "        1447       0.85      0.41      0.55        27\n",
      "        1448       0.57      0.44      0.50        27\n",
      "        1449       0.60      0.33      0.43        27\n",
      "        1450       0.58      0.76      0.66        25\n",
      "        1451       1.00      0.60      0.75        25\n",
      "        1452       0.75      0.78      0.76        27\n",
      "        1453       0.46      0.50      0.48        26\n",
      "        1455       0.63      0.68      0.66        28\n",
      "        1456       0.84      0.78      0.81        27\n",
      "        1457       0.59      0.77      0.67        26\n",
      "        1458       0.79      0.56      0.65        27\n",
      "        1459       0.42      0.46      0.44        28\n",
      "        1460       0.63      0.73      0.68        26\n",
      "        1461       0.54      0.54      0.54        28\n",
      "        1462       0.47      0.88      0.61        24\n",
      "        1463       0.63      0.71      0.67        17\n",
      "        1465       0.75      0.43      0.55        14\n",
      "        1467       0.80      0.52      0.63        23\n",
      "        1468       0.89      0.86      0.87        28\n",
      "        1469       0.50      0.39      0.44        28\n",
      "        1470       0.36      0.19      0.25        26\n",
      "        1471       0.46      0.65      0.54        26\n",
      "        1473       0.58      0.78      0.67        27\n",
      "        1474       0.62      0.56      0.59        27\n",
      "        1476       0.45      0.56      0.50        25\n",
      "        1477       0.54      0.56      0.55        27\n",
      "        1480       0.47      0.56      0.51        27\n",
      "        1483       0.83      0.65      0.73        23\n",
      "        1484       0.41      0.50      0.45        28\n",
      "        1485       0.80      0.59      0.68        27\n",
      "        1486       0.64      0.62      0.63        29\n",
      "        1488       0.71      0.43      0.53        28\n",
      "        1489       0.83      0.62      0.71        16\n",
      "        1490       0.39      0.41      0.40        22\n",
      "        1491       0.83      0.74      0.78        27\n",
      "        1492       0.92      0.92      0.92        24\n",
      "        1494       0.74      0.77      0.75        26\n",
      "        1495       0.60      0.56      0.58        27\n",
      "        1496       0.36      0.19      0.24        27\n",
      "        1499       0.45      0.56      0.50        27\n",
      "        1500       0.77      0.53      0.62        19\n",
      "        1502       0.43      0.46      0.44        26\n",
      "        1503       0.29      0.43      0.35        28\n",
      "        1504       0.65      0.77      0.70        26\n",
      "        1505       0.16      0.15      0.15        27\n",
      "        1506       0.65      0.54      0.59        28\n",
      "        1509       0.62      0.30      0.40        27\n",
      "        1510       0.47      0.65      0.55        26\n",
      "        1511       0.43      0.33      0.38        27\n",
      "        1512       0.62      0.38      0.48        26\n",
      "        1513       0.37      0.27      0.31        26\n",
      "        1514       0.33      0.30      0.31        27\n",
      "        1516       0.38      0.46      0.42        28\n",
      "        1518       0.35      0.73      0.47        26\n",
      "        1519       0.53      0.63      0.58        27\n",
      "        1520       0.39      0.36      0.37        25\n",
      "        1521       0.57      0.72      0.64        29\n",
      "        1522       0.67      0.69      0.68        26\n",
      "        1523       0.59      0.45      0.51        29\n",
      "        1524       0.38      0.38      0.38        26\n",
      "        1525       0.17      0.41      0.24        29\n",
      "        1526       0.14      0.30      0.19        27\n",
      "        1527       0.12      0.08      0.10        25\n",
      "        1528       0.73      0.62      0.67        26\n",
      "        1529       0.74      0.65      0.69        26\n",
      "        1531       0.70      0.50      0.58        28\n",
      "        1532       0.40      0.63      0.49        27\n",
      "        1533       0.88      0.79      0.84        29\n",
      "        1534       0.08      0.07      0.08        27\n",
      "        1535       0.82      0.64      0.72        28\n",
      "        1536       0.16      0.12      0.13        26\n",
      "        1537       0.48      0.41      0.44        27\n",
      "        1538       0.17      0.14      0.16        28\n",
      "        1539       0.44      0.39      0.42        28\n",
      "        1540       0.45      0.54      0.49        28\n",
      "        1541       0.36      0.54      0.43        26\n",
      "        1542       0.33      0.29      0.31        28\n",
      "        1545       1.00      0.88      0.94        26\n",
      "        1547       0.45      0.58      0.51        26\n",
      "        1548       0.64      0.67      0.65        27\n",
      "        1550       0.69      0.74      0.71        27\n",
      "        1551       0.30      0.30      0.30        27\n",
      "        1552       0.62      0.19      0.29        26\n",
      "        1553       0.48      0.43      0.45        28\n",
      "        1554       0.19      0.11      0.14        27\n",
      "        1555       0.38      0.29      0.33        28\n",
      "        1556       0.44      0.31      0.36        26\n",
      "        1557       0.47      0.32      0.38        28\n",
      "        1558       0.92      0.85      0.88        27\n",
      "        1559       0.52      0.48      0.50        27\n",
      "        1560       0.61      0.41      0.49        27\n",
      "        1561       0.40      0.54      0.46        26\n",
      "        1563       0.92      0.82      0.87        28\n",
      "        1564       0.95      0.71      0.82        28\n",
      "        1565       0.92      0.41      0.56        27\n",
      "        1566       0.27      0.26      0.26        27\n",
      "        1567       0.82      0.69      0.75        26\n",
      "        1568       0.82      0.52      0.64        27\n",
      "        1569       0.84      0.62      0.71        26\n",
      "        1570       0.50      0.78      0.61        27\n",
      "        1571       0.69      0.64      0.67        28\n",
      "        1572       0.65      0.89      0.75        27\n",
      "        1573       0.79      0.93      0.85        28\n",
      "        1575       0.81      0.65      0.72        26\n",
      "        1576       0.86      0.46      0.60        26\n",
      "        1577       0.86      0.69      0.77        26\n",
      "        1579       0.30      0.27      0.29        26\n",
      "        1580       0.38      0.23      0.29        26\n",
      "        1581       0.29      0.39      0.33        28\n",
      "        1582       0.81      0.78      0.79        27\n",
      "        1583       0.71      0.61      0.65        28\n",
      "        1584       0.58      0.42      0.49        26\n",
      "        1585       0.47      0.59      0.52        27\n",
      "        1586       0.44      0.55      0.49        29\n",
      "        1587       0.16      0.11      0.13        28\n",
      "        1588       0.48      0.36      0.41        28\n",
      "        1589       0.38      0.38      0.38        26\n",
      "        1590       0.78      0.69      0.73        26\n",
      "        1591       0.36      0.56      0.43        27\n",
      "        1592       0.73      0.42      0.54        26\n",
      "        1593       0.83      0.37      0.51        27\n",
      "        1594       0.35      0.41      0.38        27\n",
      "        1595       0.85      0.68      0.76        25\n",
      "        1596       0.80      0.62      0.70        26\n",
      "        1597       0.39      0.32      0.35        28\n",
      "        1598       0.39      0.79      0.52        29\n",
      "        1599       0.52      0.50      0.51        26\n",
      "        1600       0.50      0.63      0.56        27\n",
      "        1601       0.71      0.77      0.74        22\n",
      "        1602       0.57      0.74      0.65        27\n",
      "        1603       0.85      0.61      0.71        28\n",
      "        1604       0.38      0.54      0.45        28\n",
      "        1605       0.38      0.39      0.39        28\n",
      "        1606       0.65      0.42      0.51        26\n",
      "        1607       0.10      0.08      0.09        25\n",
      "        1608       0.74      0.71      0.73        28\n",
      "        1611       0.19      0.19      0.19        27\n",
      "        1612       0.33      0.15      0.21        27\n",
      "        1613       0.62      0.62      0.62        26\n",
      "        1614       0.30      0.12      0.17        26\n",
      "        1615       0.57      0.48      0.52        27\n",
      "        1616       0.90      0.73      0.81        26\n",
      "        1617       0.58      0.67      0.62        27\n",
      "        1618       0.78      0.78      0.78        27\n",
      "        1619       0.95      0.91      0.93        23\n",
      "        1620       0.28      0.41      0.33        27\n",
      "        1621       0.35      0.27      0.30        26\n",
      "        1622       0.37      0.62      0.46        26\n",
      "        1623       0.81      0.63      0.71        27\n",
      "        1624       0.60      0.46      0.52        26\n",
      "        1625       0.68      0.68      0.68        25\n",
      "        1627       0.69      0.41      0.51        27\n",
      "        1628       0.43      0.32      0.37        28\n",
      "        1629       0.29      0.25      0.27        28\n",
      "        1630       0.39      0.54      0.45        26\n",
      "        1631       0.44      0.71      0.55        28\n",
      "        1632       1.00      0.67      0.80        21\n",
      "        1633       0.50      0.18      0.26        28\n",
      "        1634       0.56      0.33      0.42        27\n",
      "        1635       0.37      0.26      0.30        27\n",
      "        1636       0.50      0.25      0.33        28\n",
      "        1638       0.17      0.14      0.16        28\n",
      "        1639       0.38      0.33      0.35        27\n",
      "        1640       0.34      0.71      0.47        28\n",
      "        1641       0.20      0.15      0.17        27\n",
      "        1642       0.38      0.44      0.41        27\n",
      "        1645       0.46      0.22      0.30        27\n",
      "        1646       0.46      0.48      0.47        27\n",
      "        1647       0.67      0.80      0.73        25\n",
      "        1648       0.53      0.70      0.60        27\n",
      "        1649       0.47      0.56      0.51        27\n",
      "        1650       0.61      0.81      0.70        27\n",
      "        1651       0.67      0.85      0.75        26\n",
      "        1652       0.93      0.54      0.68        26\n",
      "        1653       0.75      0.56      0.64        27\n",
      "        1654       0.71      0.38      0.50        26\n",
      "        1656       0.56      0.86      0.68        28\n",
      "        1657       0.32      0.23      0.27        26\n",
      "        1658       0.53      0.65      0.59        26\n",
      "        1659       0.40      0.63      0.49        27\n",
      "        1660       0.67      0.59      0.63        27\n",
      "        1661       0.55      0.43      0.48        28\n",
      "        1662       0.05      0.04      0.04        27\n",
      "        1663       0.71      0.37      0.49        27\n",
      "        1664       0.45      0.37      0.41        27\n",
      "        1665       0.32      0.46      0.38        28\n",
      "        1666       0.10      0.11      0.11        27\n",
      "        1667       0.24      0.23      0.24        26\n",
      "        1668       0.15      0.30      0.20        27\n",
      "        1669       0.57      0.86      0.69        28\n",
      "        1670       0.92      0.88      0.90        26\n",
      "        1671       0.34      0.37      0.36        27\n",
      "        1672       0.64      0.54      0.58        26\n",
      "        1673       0.61      0.52      0.56        27\n",
      "        1674       0.38      0.18      0.24        28\n",
      "        1675       0.51      0.68      0.58        28\n",
      "        1676       0.39      0.54      0.45        28\n",
      "        1677       0.41      0.54      0.47        26\n",
      "        1678       0.18      0.46      0.26        26\n",
      "        1679       0.61      0.42      0.50        26\n",
      "        1680       0.86      0.73      0.79        26\n",
      "        1681       0.35      0.48      0.41        27\n",
      "        1682       0.27      0.41      0.33        29\n",
      "        1683       0.88      0.56      0.68        27\n",
      "        1684       0.33      0.32      0.33        28\n",
      "        1685       0.33      0.48      0.39        27\n",
      "        1686       0.11      0.11      0.11        27\n",
      "        1687       0.60      0.60      0.60        25\n",
      "        1697       0.77      1.00      0.87        27\n",
      "        1698       0.94      0.84      0.89        19\n",
      "        1699       0.68      0.78      0.72        27\n",
      "        1727       0.65      0.54      0.59        24\n",
      "        1728       0.80      0.15      0.26        26\n",
      "        1746       0.56      0.37      0.44        27\n",
      "        1754       0.67      0.36      0.47        28\n",
      "        1755       0.83      0.70      0.76        27\n",
      "        1756       0.40      0.38      0.39        26\n",
      "        1757       0.35      0.52      0.42        27\n",
      "        1758       0.31      0.19      0.23        27\n",
      "        1760       0.70      0.78      0.74        27\n",
      "        1761       0.33      0.58      0.42        26\n",
      "        1762       1.00      1.00      1.00        22\n",
      "        1763       0.64      0.70      0.67        20\n",
      "        1764       0.51      0.73      0.60        26\n",
      "        1765       0.88      0.54      0.67        28\n",
      "        1768       0.54      0.52      0.53        27\n",
      "        1769       0.73      0.68      0.70        28\n",
      "        1771       0.60      0.75      0.67        28\n",
      "        1774       0.72      0.69      0.71        26\n",
      "        1775       0.31      0.32      0.32        28\n",
      "        1777       0.72      0.78      0.75        27\n",
      "        1778       0.62      0.75      0.68        20\n",
      "        1779       0.62      0.82      0.71        28\n",
      "        1780       0.50      0.70      0.58        27\n",
      "        1781       0.41      0.68      0.51        28\n",
      "        1782       0.73      0.68      0.70        28\n",
      "        1783       0.36      0.64      0.46        28\n",
      "        1784       0.50      0.41      0.45        29\n",
      "        1785       0.73      0.70      0.72        27\n",
      "        1786       0.37      0.26      0.30        27\n",
      "        1787       0.90      0.69      0.78        26\n",
      "        1788       0.44      0.57      0.50        28\n",
      "        1789       0.61      0.61      0.61        18\n",
      "        1790       0.72      0.82      0.77        28\n",
      "        1791       0.61      0.79      0.69        14\n",
      "        1792       0.76      0.62      0.68        26\n",
      "        1793       0.39      0.33      0.36        27\n",
      "        1794       0.56      0.81      0.67        27\n",
      "        1795       0.88      0.52      0.65        27\n",
      "        1796       0.57      0.31      0.40        26\n",
      "        1797       0.66      0.68      0.67        28\n",
      "        1798       0.15      0.12      0.13        25\n",
      "        1799       0.15      0.15      0.15        27\n",
      "        1800       0.67      0.71      0.69        28\n",
      "        1801       0.71      1.00      0.83        25\n",
      "        1802       0.24      0.37      0.29        27\n",
      "        1803       0.41      0.62      0.49        26\n",
      "        1804       0.75      0.69      0.72        26\n",
      "        1806       0.90      0.60      0.72        15\n",
      "        1808       0.87      0.52      0.65        25\n",
      "        1809       0.92      0.85      0.88        27\n",
      "        1810       0.55      0.68      0.61        25\n",
      "        1811       0.18      0.15      0.16        27\n",
      "        1812       0.62      0.64      0.63        25\n",
      "        1813       0.82      0.69      0.75        26\n",
      "        1815       0.36      0.59      0.44        27\n",
      "        1816       0.86      0.86      0.86        28\n",
      "        1821       0.74      0.71      0.73        28\n",
      "        1822       0.79      0.68      0.73        22\n",
      "        1824       0.46      0.48      0.47        27\n",
      "        1825       0.57      0.44      0.50        27\n",
      "        1826       0.53      0.75      0.62        28\n",
      "        1827       0.86      0.64      0.73        28\n",
      "        1828       0.42      0.42      0.42        26\n",
      "        1829       0.66      0.78      0.71        27\n",
      "        1830       0.40      0.44      0.42        27\n",
      "        1831       0.54      0.70      0.61        27\n",
      "        1832       0.52      0.52      0.52        27\n",
      "        1833       0.82      0.72      0.77        25\n",
      "        1834       0.68      0.81      0.74        26\n",
      "        1835       0.20      0.15      0.17        26\n",
      "        1836       0.42      0.34      0.38        29\n",
      "        1837       0.30      0.43      0.35        28\n",
      "        1838       0.51      0.68      0.58        28\n",
      "        1839       0.38      0.21      0.27        28\n",
      "        1840       0.70      0.57      0.63        28\n",
      "        1843       0.40      0.36      0.38        28\n",
      "        1844       0.77      0.89      0.83        27\n",
      "        1845       0.50      0.54      0.52        28\n",
      "        1846       0.56      0.74      0.63        27\n",
      "        1847       0.32      0.22      0.26        27\n",
      "        1848       0.61      0.50      0.55        28\n",
      "        1849       0.55      0.39      0.46        28\n",
      "        1851       0.44      0.27      0.33        26\n",
      "        1852       0.65      0.48      0.55        27\n",
      "        1853       0.47      0.27      0.34        26\n",
      "        1854       0.24      0.30      0.26        27\n",
      "        1855       0.44      0.14      0.22        28\n",
      "        1857       0.38      0.37      0.38        27\n",
      "        1858       0.72      0.75      0.74        28\n",
      "        1859       0.74      0.74      0.74        27\n",
      "        1860       0.60      0.22      0.32        27\n",
      "        1861       0.61      0.71      0.66        28\n",
      "        1862       0.10      0.04      0.05        27\n",
      "        1863       0.12      0.07      0.09        28\n",
      "        1864       0.58      0.60      0.59        25\n",
      "        1865       0.67      0.30      0.41        27\n",
      "        1866       0.30      0.11      0.16        28\n",
      "        1867       0.82      0.54      0.65        26\n",
      "        1868       0.24      0.14      0.18        28\n",
      "        1869       0.74      0.54      0.62        26\n",
      "        1870       0.91      0.74      0.82        27\n",
      "        1871       0.89      0.81      0.85        21\n",
      "        1872       0.54      0.84      0.66        25\n",
      "        1873       0.73      0.39      0.51        28\n",
      "        1874       0.00      0.00      0.00        26\n",
      "        1875       0.40      0.37      0.38        27\n",
      "        1876       0.92      0.96      0.94        25\n",
      "        1877       0.54      0.48      0.51        27\n",
      "        1878       0.80      0.48      0.60        25\n",
      "        1879       0.91      0.75      0.82        28\n",
      "        1881       0.81      0.81      0.81        27\n",
      "        1883       0.71      0.89      0.79        28\n",
      "        1884       0.64      0.55      0.59        29\n",
      "        1886       0.61      0.63      0.62        27\n",
      "        1888       0.70      0.52      0.60        27\n",
      "        1889       0.61      0.63      0.62        27\n",
      "        1890       0.77      0.96      0.86        28\n",
      "        1891       0.92      0.82      0.87        28\n",
      "        1893       0.21      0.36      0.27        25\n",
      "        1894       0.91      0.78      0.84        27\n",
      "        1895       0.50      0.43      0.46        28\n",
      "        1896       0.64      0.89      0.75        28\n",
      "        1898       0.69      0.93      0.79        29\n",
      "        1899       0.95      0.72      0.82        29\n",
      "        1900       0.63      0.81      0.71        27\n",
      "        1901       0.24      0.50      0.32        28\n",
      "        1902       0.88      0.78      0.82        27\n",
      "        1903       0.86      0.70      0.78        27\n",
      "        1904       0.89      0.57      0.70        28\n",
      "        1905       0.94      0.62      0.74        26\n",
      "        1909       0.11      0.14      0.12        28\n",
      "        1910       0.71      0.56      0.63        27\n",
      "        1911       0.57      0.65      0.61        26\n",
      "        1912       0.68      0.54      0.60        28\n",
      "        1913       0.69      0.85      0.76        26\n",
      "        1915       0.67      0.50      0.57        28\n",
      "        1916       0.76      0.70      0.73        27\n",
      "        1917       0.67      0.48      0.56        25\n",
      "        1918       0.81      0.93      0.86        27\n",
      "        1919       0.90      0.70      0.79        27\n",
      "        1920       0.48      0.62      0.54        26\n",
      "        1921       0.46      0.75      0.57        28\n",
      "        1922       0.60      0.96      0.74        26\n",
      "        1923       0.76      0.93      0.83        27\n",
      "        1924       0.85      0.61      0.71        28\n",
      "        1925       0.32      0.29      0.30        28\n",
      "        1926       0.89      0.65      0.76        26\n",
      "        1929       0.62      0.54      0.58        28\n",
      "        1930       0.36      0.62      0.45        26\n",
      "        1931       0.58      0.50      0.54        28\n",
      "        1932       0.38      0.35      0.36        26\n",
      "        1933       0.45      0.58      0.51        26\n",
      "        1934       0.33      0.22      0.27        27\n",
      "        1935       0.26      0.37      0.30        27\n",
      "        1936       0.69      0.93      0.79        27\n",
      "        1937       0.54      0.54      0.54        28\n",
      "        1938       0.25      0.30      0.27        27\n",
      "        1939       0.31      0.42      0.36        26\n",
      "        1940       0.57      0.50      0.53        16\n",
      "        1941       0.45      0.71      0.56        28\n",
      "        1942       0.30      0.48      0.37        27\n",
      "        1943       0.26      0.30      0.28        27\n",
      "        1944       0.26      0.19      0.22        27\n",
      "        1945       0.43      0.70      0.54        27\n",
      "        1946       0.42      0.39      0.41        28\n",
      "        1947       0.62      0.18      0.28        28\n",
      "        1948       0.06      0.04      0.05        26\n",
      "        1949       0.38      0.32      0.35        28\n",
      "        1950       0.95      0.71      0.82        28\n",
      "        1951       0.73      0.68      0.70        28\n",
      "        1952       0.50      0.30      0.37        27\n",
      "        1953       0.72      0.72      0.72        25\n",
      "        1954       0.46      0.50      0.48        26\n",
      "        1955       0.43      0.31      0.36        29\n",
      "        1956       0.59      0.65      0.62        26\n",
      "        1957       0.73      0.70      0.72        27\n",
      "        1958       0.80      0.41      0.55        29\n",
      "        1959       0.50      0.42      0.46        26\n",
      "        1960       0.35      0.28      0.31        25\n",
      "        1961       1.00      0.83      0.91        29\n",
      "        1962       0.93      0.89      0.91        28\n",
      "        1963       0.76      0.93      0.84        28\n",
      "        1964       0.65      0.79      0.71        28\n",
      "        1965       0.58      0.78      0.67        27\n",
      "        1966       0.58      0.60      0.59        25\n",
      "        1967       0.76      0.81      0.79        27\n",
      "        1970       0.82      0.67      0.73        27\n",
      "        1972       0.64      0.80      0.71        20\n",
      "        1973       0.79      0.76      0.77        29\n",
      "        1974       0.58      0.60      0.59        25\n",
      "        1975       0.72      0.88      0.79        26\n",
      "        1976       0.88      0.78      0.82        27\n",
      "        1977       0.88      0.56      0.68        27\n",
      "        1978       0.75      0.56      0.64        27\n",
      "        1979       0.38      0.46      0.42        28\n",
      "        1980       0.74      0.89      0.81        28\n",
      "        1981       0.50      0.57      0.53        28\n",
      "        1982       0.84      0.62      0.71        26\n",
      "        1983       0.71      0.58      0.64        26\n",
      "        1984       0.57      0.46      0.51        28\n",
      "        1985       0.96      0.86      0.91        29\n",
      "        1986       0.52      0.62      0.56        26\n",
      "        1987       0.65      0.46      0.54        28\n",
      "        1988       0.50      0.29      0.36        28\n",
      "        1992       0.70      0.85      0.77        27\n",
      "        1994       0.86      0.89      0.88        28\n",
      "        1995       0.69      0.80      0.74        25\n",
      "        1996       0.88      0.50      0.64        14\n",
      "        1999       0.63      0.48      0.55        25\n",
      "        2001       0.85      0.79      0.82        29\n",
      "        2003       0.62      0.81      0.70        26\n",
      "        2006       0.74      0.93      0.83        28\n",
      "        2007       0.75      0.33      0.46        27\n",
      "        2008       0.45      0.45      0.45        29\n",
      "        2009       0.47      0.30      0.36        27\n",
      "        2010       0.54      0.75      0.63        28\n",
      "        2011       0.09      0.07      0.08        27\n",
      "        2012       0.23      0.27      0.25        26\n",
      "        2013       0.44      0.39      0.42        28\n",
      "        2015       0.82      0.50      0.62        28\n",
      "        2016       0.88      0.92      0.90        25\n",
      "        2017       0.81      0.65      0.72        26\n",
      "        2018       0.85      0.63      0.72        27\n",
      "        2021       0.92      0.85      0.88        27\n",
      "        2024       0.90      1.00      0.95        28\n",
      "        2026       0.84      0.78      0.81        27\n",
      "        2035       0.96      0.89      0.92        27\n",
      "        2038       0.50      0.52      0.51        27\n",
      "        2042       0.67      0.58      0.62        24\n",
      "        2043       0.76      0.76      0.76        29\n",
      "        2044       0.87      0.81      0.84        16\n",
      "        2046       0.67      0.70      0.68        23\n",
      "        2051       0.57      0.68      0.62        25\n",
      "        2052       0.58      0.56      0.57        27\n",
      "        2054       0.81      0.59      0.68        29\n",
      "        2055       0.79      0.88      0.84        26\n",
      "        2056       0.64      0.72      0.68        29\n",
      "        2057       0.42      0.30      0.35        27\n",
      "        2058       0.65      0.71      0.68        28\n",
      "        2059       0.58      0.78      0.67        27\n",
      "        2060       0.33      0.28      0.30        29\n",
      "        2061       0.76      0.70      0.73        27\n",
      "        2062       0.79      0.85      0.81        26\n",
      "        2063       0.66      0.70      0.68        27\n",
      "        2064       0.64      0.82      0.72        28\n",
      "        2067       0.65      0.81      0.72        27\n",
      "        2070       0.73      0.66      0.69        29\n",
      "        2071       0.92      0.79      0.85        28\n",
      "        2072       0.36      0.50      0.42        26\n",
      "        2078       0.35      0.68      0.47        25\n",
      "        2079       0.64      0.50      0.56        28\n",
      "        2080       0.78      0.78      0.78        27\n",
      "        2081       0.74      0.52      0.61        27\n",
      "        2084       0.24      0.36      0.29        25\n",
      "        2085       0.74      0.96      0.84        27\n",
      "        2086       0.86      0.96      0.91        26\n",
      "        2087       0.47      0.52      0.49        27\n",
      "        2088       0.41      0.56      0.47        27\n",
      "        2089       0.92      0.39      0.55        28\n",
      "        2091       0.58      0.56      0.57        27\n",
      "        2092       0.50      0.59      0.54        27\n",
      "        2097       0.25      0.28      0.26        25\n",
      "        2098       0.59      0.71      0.65        28\n",
      "        2099       0.76      0.97      0.85        29\n",
      "        2101       1.00      0.46      0.63        13\n",
      "        2102       0.52      0.48      0.50        27\n",
      "        2103       0.68      0.85      0.75        27\n",
      "        2107       0.48      0.54      0.51        26\n",
      "        2108       0.55      0.59      0.57        29\n",
      "        2113       0.31      0.54      0.39        28\n",
      "        2114       0.56      0.54      0.55        26\n",
      "        2115       0.27      0.15      0.20        26\n",
      "        2116       0.83      0.93      0.88        27\n",
      "        2117       0.62      0.71      0.67        28\n",
      "        2118       0.43      0.32      0.37        28\n",
      "        2119       0.71      0.86      0.77        28\n",
      "        2122       0.18      0.19      0.19        26\n",
      "        2123       0.77      0.74      0.76        23\n",
      "        2124       0.45      0.52      0.48        27\n",
      "        2125       0.27      0.32      0.30        28\n",
      "        2126       0.56      0.73      0.63        26\n",
      "        2127       0.81      0.81      0.81        21\n",
      "        2128       0.80      0.48      0.60        25\n",
      "        2129       0.90      0.86      0.88        21\n",
      "        2130       0.73      0.68      0.70        28\n",
      "        2132       0.23      0.41      0.30        27\n",
      "        2134       0.37      0.50      0.42        28\n",
      "        2136       0.29      0.29      0.29        28\n",
      "        2137       0.35      0.30      0.32        27\n",
      "        2140       0.48      0.81      0.60        27\n",
      "        2141       0.50      0.29      0.36        28\n",
      "        2142       0.16      0.21      0.18        24\n",
      "        2146       0.53      0.68      0.60        25\n",
      "        2147       0.67      0.57      0.62        28\n",
      "        2149       0.56      0.70      0.62        27\n",
      "        2151       0.64      0.25      0.36        28\n",
      "        2153       0.91      0.77      0.83        26\n",
      "        2154       0.90      1.00      0.95        27\n",
      "        2159       0.33      0.70      0.45        27\n",
      "        2160       0.39      0.64      0.49        28\n",
      "        2168       0.73      0.79      0.76        28\n",
      "        2169       0.75      0.67      0.71        27\n",
      "        2170       0.30      0.12      0.18        24\n",
      "        2171       0.65      0.74      0.69        27\n",
      "        2172       0.85      0.81      0.83        27\n",
      "        2173       0.65      0.77      0.70        26\n",
      "        2174       0.71      0.63      0.67        27\n",
      "        2175       0.59      0.63      0.61        27\n",
      "        2176       0.52      0.46      0.49        26\n",
      "        2177       0.35      0.39      0.37        28\n",
      "        2178       0.47      0.59      0.52        27\n",
      "        2179       0.67      0.59      0.63        27\n",
      "        2180       0.65      0.68      0.67        25\n",
      "        2182       0.56      0.86      0.68        28\n",
      "        2183       0.63      0.43      0.51        28\n",
      "        2184       0.54      0.71      0.62        28\n",
      "        2185       0.56      0.58      0.57        24\n",
      "        2186       0.49      0.68      0.57        28\n",
      "        2187       0.28      0.40      0.33        25\n",
      "        2188       0.47      0.52      0.49        27\n",
      "        2189       0.37      0.36      0.36        28\n",
      "        2190       0.69      0.36      0.47        25\n",
      "        2192       0.54      0.68      0.60        28\n",
      "        2193       0.60      0.69      0.64        26\n",
      "        2195       0.45      0.52      0.48        29\n",
      "        2196       0.27      0.41      0.32        27\n",
      "        2198       0.27      0.21      0.24        28\n",
      "        2200       0.62      0.18      0.28        28\n",
      "        2201       0.33      0.44      0.38        25\n",
      "        2202       0.33      0.62      0.43        26\n",
      "        2203       0.43      0.35      0.38        26\n",
      "        2205       0.71      0.74      0.73        27\n",
      "        2206       0.82      0.72      0.77        25\n",
      "        2207       0.86      0.35      0.50        17\n",
      "        2211       0.48      0.54      0.51        28\n",
      "        2212       0.12      0.11      0.12        27\n",
      "        2213       0.32      0.29      0.30        28\n",
      "        2214       0.16      0.24      0.19        29\n",
      "        2216       0.35      0.48      0.41        27\n",
      "        2224       0.48      0.59      0.53        27\n",
      "        2225       0.83      0.56      0.67        27\n",
      "        2230       0.59      0.62      0.60        26\n",
      "        2231       0.57      0.46      0.51        26\n",
      "        2243       0.72      0.64      0.68        28\n",
      "        2279       0.31      0.39      0.34        28\n",
      "        2280       0.11      0.04      0.06        27\n",
      "        2286       0.28      0.34      0.31        29\n",
      "        2287       0.20      0.26      0.23        27\n",
      "        2288       0.24      0.27      0.25        26\n",
      "        2289       0.38      0.53      0.44        19\n",
      "        2290       0.46      0.64      0.54        28\n",
      "        2291       0.27      0.27      0.27        26\n",
      "        2292       0.53      0.62      0.57        26\n",
      "        2295       0.81      0.68      0.74        25\n",
      "        2296       0.37      0.37      0.37        27\n",
      "        2297       0.70      0.82      0.75        28\n",
      "        2298       0.31      0.56      0.39        27\n",
      "        2301       0.00      0.00      0.00        27\n",
      "        2306       0.71      0.54      0.61        28\n",
      "        2308       0.41      0.35      0.38        26\n",
      "        2309       0.53      0.68      0.59        28\n",
      "        2310       0.45      0.56      0.50        27\n",
      "        2311       0.63      0.85      0.72        26\n",
      "        2312       0.52      0.59      0.55        27\n",
      "        2313       0.43      0.62      0.51        29\n",
      "        2314       0.40      0.15      0.22        26\n",
      "        2315       0.40      0.44      0.42        27\n",
      "        2316       0.81      0.88      0.84        24\n",
      "        2321       0.55      0.81      0.66        27\n",
      "        2324       0.95      0.69      0.80        26\n",
      "        2325       0.52      0.44      0.48        27\n",
      "        2326       0.16      0.23      0.19        26\n",
      "        2333       0.69      0.69      0.69        26\n",
      "        2334       0.45      0.63      0.52        27\n",
      "        2335       0.80      0.59      0.68        27\n",
      "        2336       0.96      0.82      0.88        28\n",
      "        2337       0.60      0.64      0.62        28\n",
      "        2338       0.88      0.81      0.84        26\n",
      "        2339       0.84      0.78      0.81        27\n",
      "        2340       0.53      0.85      0.66        27\n",
      "        2343       0.90      0.70      0.79        27\n",
      "        2346       1.00      0.95      0.98        21\n",
      "        2347       0.88      0.56      0.68        27\n",
      "        2348       0.61      0.79      0.69        28\n",
      "        2349       0.81      0.84      0.82        25\n",
      "        2350       0.68      0.89      0.77        28\n",
      "        2351       0.56      0.56      0.56        27\n",
      "        2352       0.52      0.61      0.56        18\n",
      "        2353       0.76      0.59      0.67        27\n",
      "        2354       0.48      0.38      0.43        26\n",
      "        2355       0.86      0.73      0.79        26\n",
      "        2356       0.69      0.81      0.75        27\n",
      "        2357       0.88      0.60      0.71        25\n",
      "        2358       0.71      0.57      0.63        21\n",
      "        2360       0.61      0.54      0.57        26\n",
      "        2363       0.94      0.89      0.92        19\n",
      "        2364       0.63      0.43      0.51        28\n",
      "        2365       0.61      0.52      0.56        27\n",
      "        2366       0.67      0.74      0.70        27\n",
      "        2367       0.61      0.50      0.55        28\n",
      "        2368       0.74      0.63      0.68        27\n",
      "        2369       0.76      0.85      0.80        26\n",
      "        2370       0.60      0.33      0.43        27\n",
      "        2371       0.74      0.69      0.71        29\n",
      "        2372       0.96      0.93      0.94        27\n",
      "        2373       0.88      0.88      0.88        26\n",
      "        2377       0.81      0.85      0.83        26\n",
      "        2379       0.90      0.93      0.91        28\n",
      "        2381       0.64      0.84      0.73        19\n",
      "        2383       0.95      0.73      0.83        26\n",
      "        2385       0.82      0.67      0.73        27\n",
      "        2386       0.54      0.71      0.62        28\n",
      "        2387       0.90      0.67      0.77        27\n",
      "        2388       0.92      0.44      0.59        25\n",
      "        2389       0.62      0.92      0.74        26\n",
      "        2390       0.69      0.71      0.70        28\n",
      "        2392       0.81      0.81      0.81        27\n",
      "        2393       0.61      0.41      0.49        27\n",
      "        2394       0.30      0.32      0.31        28\n",
      "        2395       0.65      0.42      0.51        26\n",
      "        2396       0.58      0.75      0.66        28\n",
      "        2397       0.42      0.77      0.54        26\n",
      "        2398       0.46      0.64      0.53        25\n",
      "        2399       0.36      0.61      0.45        28\n",
      "        2400       0.41      0.48      0.44        27\n",
      "        2401       0.69      0.81      0.75        27\n",
      "        2402       0.76      0.50      0.60        26\n",
      "        2403       0.81      0.65      0.72        26\n",
      "        2404       0.71      0.89      0.79        28\n",
      "        2405       0.61      0.65      0.63        26\n",
      "        2531       0.43      0.52      0.47        25\n",
      "        2532       0.80      0.57      0.67        28\n",
      "        2533       0.32      0.41      0.36        27\n",
      "        2534       0.28      0.44      0.34        27\n",
      "        2535       0.35      0.46      0.40        28\n",
      "        2537       0.17      0.19      0.18        26\n",
      "        2538       0.27      0.32      0.29        25\n",
      "        2539       0.69      0.80      0.74        25\n",
      "        2540       0.62      0.71      0.67        28\n",
      "        2638       0.44      0.80      0.57        25\n",
      "        2639       0.38      0.81      0.52        27\n",
      "        2640       0.23      0.41      0.29        27\n",
      "        2641       0.28      0.27      0.27        26\n",
      "        2642       0.38      0.36      0.37        25\n",
      "        2643       0.24      0.43      0.30        28\n",
      "        2644       0.61      0.74      0.67        27\n",
      "        2645       0.66      0.70      0.68        27\n",
      "        2652       0.62      0.88      0.73        26\n",
      "        2653       0.56      0.38      0.45        26\n",
      "        2654       0.92      0.76      0.83        29\n",
      "        2664       0.50      0.67      0.57        27\n",
      "        2665       0.23      0.19      0.20        27\n",
      "        2666       0.34      0.46      0.39        26\n",
      "        2667       0.67      0.67      0.67        27\n",
      "        2781       0.23      0.32      0.27        28\n",
      "        2782       0.83      0.56      0.67        27\n",
      "        2783       0.62      0.31      0.41        26\n",
      "        2784       0.56      0.52      0.54        27\n",
      "        2785       0.61      0.50      0.55        28\n",
      "        2786       0.33      0.22      0.27        27\n",
      "        2787       0.39      0.42      0.41        26\n",
      "        2788       0.68      0.70      0.69        27\n",
      "        2789       0.27      0.46      0.34        26\n",
      "        2790       0.47      0.35      0.40        26\n",
      "        2791       0.25      0.23      0.24        26\n",
      "        2792       0.75      0.75      0.75        28\n",
      "        2793       0.57      0.21      0.31        19\n",
      "        2804       0.91      0.71      0.80        14\n",
      "        2808       0.38      0.44      0.41        27\n",
      "        2809       0.29      0.21      0.24        28\n",
      "        2810       0.79      0.85      0.82        27\n",
      "        2811       0.50      0.68      0.58        28\n",
      "        2813       0.46      0.44      0.45        27\n",
      "        2814       0.62      0.48      0.54        27\n",
      "        2815       0.15      0.21      0.18        28\n",
      "        2818       0.89      0.89      0.89        27\n",
      "        2819       0.94      0.65      0.77        26\n",
      "        2820       0.60      1.00      0.75        27\n",
      "        2821       0.88      0.82      0.85        28\n",
      "        2826       0.56      0.66      0.60        29\n",
      "        2828       0.67      0.81      0.73        27\n",
      "        2830       0.53      0.59      0.56        27\n",
      "        2831       0.56      0.50      0.53        28\n",
      "        2833       0.58      0.73      0.64        26\n",
      "        2835       0.61      0.76      0.68        25\n",
      "        2836       0.69      0.67      0.68        27\n",
      "        2837       0.60      0.52      0.56        29\n",
      "        2838       0.62      0.46      0.53        28\n",
      "        2839       0.64      0.62      0.63        26\n",
      "        2842       0.67      0.44      0.53        27\n",
      "        2843       0.40      0.38      0.39        26\n",
      "        2844       0.23      0.26      0.24        27\n",
      "        2845       0.74      0.85      0.79        27\n",
      "        2847       0.89      0.96      0.93        26\n",
      "        2848       0.35      0.33      0.34        27\n",
      "        2849       1.00      0.81      0.90        27\n",
      "        2850       0.39      0.71      0.51        28\n",
      "        2851       0.58      0.68      0.62        28\n",
      "        2852       1.00      0.86      0.92        28\n",
      "        2853       0.45      0.52      0.48        27\n",
      "        2854       0.80      0.57      0.67        28\n",
      "        2855       0.30      0.11      0.16        27\n",
      "        2856       0.60      0.67      0.63        27\n",
      "        2858       0.29      0.22      0.25        27\n",
      "        2861       0.76      0.48      0.59        27\n",
      "        2862       0.68      0.88      0.77        26\n",
      "        2867       0.86      0.92      0.89        26\n",
      "        2868       0.77      0.85      0.81        27\n",
      "        2869       0.38      0.35      0.36        26\n",
      "        2885       0.41      0.42      0.42        26\n",
      "        2887       0.43      0.46      0.44        26\n",
      "        2889       0.54      0.48      0.51        27\n",
      "        2895       0.75      0.33      0.46        27\n",
      "        2896       0.64      0.59      0.62        27\n",
      "        2897       0.46      0.42      0.44        26\n",
      "        2898       0.40      0.22      0.29        27\n",
      "        2899       0.83      0.56      0.67        27\n",
      "        2900       0.44      0.65      0.52        26\n",
      "        2901       0.19      0.27      0.22        26\n",
      "        2903       0.36      0.31      0.33        26\n",
      "        2904       0.40      0.37      0.38        27\n",
      "        2905       0.38      0.45      0.41        29\n",
      "        2906       0.56      0.81      0.67        27\n",
      "        2907       0.90      0.73      0.81        26\n",
      "        2909       1.00      0.36      0.53        25\n",
      "        2910       0.52      0.68      0.59        25\n",
      "        2911       0.31      0.39      0.35        28\n",
      "        2912       0.76      0.96      0.85        26\n",
      "        2913       0.48      0.57      0.52        28\n",
      "        2914       0.21      0.15      0.18        26\n",
      "        2915       0.30      0.31      0.30        26\n",
      "        2917       0.67      0.62      0.64        26\n",
      "        2918       0.83      0.83      0.83        18\n",
      "        2919       0.44      0.63      0.52        27\n",
      "        2920       0.88      0.64      0.74        22\n",
      "        2921       0.69      0.86      0.76        28\n",
      "        2922       0.78      0.64      0.71        28\n",
      "        2923       0.86      0.69      0.77        26\n",
      "        2924       0.59      0.68      0.63        28\n",
      "        2925       0.90      0.68      0.78        28\n",
      "        2926       0.95      0.72      0.82        25\n",
      "        2927       0.58      0.93      0.71        28\n",
      "        2928       0.68      0.65      0.67        26\n",
      "        2929       0.23      0.48      0.31        27\n",
      "        2930       0.89      0.65      0.76        26\n",
      "        2931       0.47      0.69      0.56        26\n",
      "        6053       0.56      0.37      0.44        27\n",
      "        6054       0.44      0.56      0.49        27\n",
      "        6055       0.72      0.96      0.83        27\n",
      "        6056       0.57      0.62      0.59        26\n",
      "        6057       0.42      0.48      0.45        27\n",
      "        6058       0.73      0.86      0.79        28\n",
      "        6059       0.58      0.93      0.71        27\n",
      "        6060       0.22      0.29      0.25        28\n",
      "        6061       0.44      0.39      0.42        28\n",
      "        6064       0.75      0.89      0.81        27\n",
      "        6065       0.67      0.48      0.56        25\n",
      "        6067       0.48      0.50      0.49        26\n",
      "        6068       0.76      0.70      0.73        27\n",
      "        6069       0.26      0.26      0.26        27\n",
      "        6070       0.34      0.52      0.41        27\n",
      "        6072       0.78      0.69      0.73        26\n",
      "        6074       0.39      0.48      0.43        29\n",
      "        6075       0.54      0.58      0.56        26\n",
      "        6076       0.57      0.46      0.51        26\n",
      "        6077       0.59      0.96      0.73        27\n",
      "        6078       0.54      0.48      0.51        27\n",
      "        6079       0.55      0.42      0.48        26\n",
      "        6080       0.42      0.30      0.35        27\n",
      "        6081       0.69      0.74      0.71        27\n",
      "        6082       0.55      0.69      0.61        26\n",
      "        6083       0.24      0.36      0.29        28\n",
      "        6084       0.38      0.44      0.41        27\n",
      "        6085       0.74      0.80      0.77        25\n",
      "        6086       0.63      0.48      0.55        25\n",
      "        6087       0.51      0.67      0.58        27\n",
      "        6088       0.55      0.59      0.57        27\n",
      "        6089       0.69      0.71      0.70        28\n",
      "        6090       0.60      0.56      0.58        27\n",
      "        6091       0.79      0.70      0.75        27\n",
      "        6093       0.55      0.59      0.57        27\n",
      "        6094       0.89      0.62      0.73        26\n",
      "        6095       0.64      0.89      0.75        28\n",
      "        6096       0.11      0.07      0.09        27\n",
      "        6098       0.75      0.67      0.71        27\n",
      "        6099       0.70      0.75      0.72        28\n",
      "        6100       0.76      0.59      0.67        27\n",
      "        6102       0.35      0.43      0.39        28\n",
      "        6103       0.78      0.50      0.61        28\n",
      "        6104       0.27      0.50      0.35        28\n",
      "        6108       0.57      0.85      0.69        27\n",
      "        6109       0.28      0.38      0.32        26\n",
      "        6110       0.80      0.29      0.42        28\n",
      "        6112       0.78      0.78      0.78        27\n",
      "        6114       0.67      0.41      0.51        29\n",
      "        6115       0.53      0.59      0.56        27\n",
      "        6116       0.72      0.81      0.76        26\n",
      "        6121       0.45      0.37      0.41        27\n",
      "        6122       0.70      0.85      0.77        27\n",
      "        6123       0.83      0.66      0.73        29\n",
      "        6217       1.00      0.93      0.96        28\n",
      "        6218       1.00      0.18      0.30        17\n",
      "        6219       0.80      0.30      0.43        27\n",
      "        6220       0.11      0.15      0.13        26\n",
      "        6221       0.60      0.11      0.19        27\n",
      "        6223       0.96      0.93      0.94        27\n",
      "        6224       0.85      0.63      0.72        27\n",
      "        6225       0.56      0.56      0.56        18\n",
      "        6227       0.74      0.77      0.75        26\n",
      "        6229       0.33      0.50      0.40        26\n",
      "        6231       0.83      0.68      0.75        28\n",
      "        6232       0.81      0.57      0.67        23\n",
      "        6233       0.83      0.38      0.53        26\n",
      "        6234       0.60      0.56      0.58        27\n",
      "        6235       0.62      0.29      0.39        28\n",
      "        6236       0.95      0.70      0.81        27\n",
      "        6237       1.00      0.67      0.80        27\n",
      "        6238       0.74      0.54      0.62        26\n",
      "        6239       0.52      0.41      0.46        29\n",
      "        6240       0.41      0.42      0.42        26\n",
      "        6241       0.73      0.39      0.51        28\n",
      "        6242       0.91      0.74      0.82        27\n",
      "        6243       0.77      0.77      0.77        26\n",
      "        6245       0.79      0.88      0.84        26\n",
      "        6246       0.90      0.35      0.50        26\n",
      "        6248       0.88      0.79      0.83        28\n",
      "        6252       0.90      0.96      0.93        27\n",
      "        6253       0.95      0.84      0.89        25\n",
      "        6255       0.89      0.77      0.83        22\n",
      "        6256       0.88      0.37      0.52        19\n",
      "        6257       0.58      0.44      0.50        25\n",
      "        6258       0.78      0.84      0.81        25\n",
      "        6259       0.85      0.82      0.84        28\n",
      "        6262       0.79      0.93      0.86        29\n",
      "        6264       1.00      0.85      0.92        26\n",
      "        6265       0.74      0.64      0.68        22\n",
      "        6267       0.81      0.61      0.69        28\n",
      "        6268       1.00      0.75      0.86        28\n",
      "        6269       0.57      0.44      0.50        27\n",
      "        6270       0.65      0.83      0.73        29\n",
      "        6271       0.93      0.96      0.95        27\n",
      "        6272       0.62      0.69      0.65        26\n",
      "        6273       0.83      0.89      0.86        27\n",
      "        6274       0.83      0.94      0.88        16\n",
      "        6275       0.78      0.64      0.70        22\n",
      "        6276       0.56      0.50      0.53        28\n",
      "        6277       0.87      0.65      0.74        20\n",
      "        6279       0.68      0.65      0.67        26\n",
      "        6280       0.55      0.84      0.67        25\n",
      "        6281       0.47      0.64      0.55        28\n",
      "        6282       0.53      0.37      0.43        27\n",
      "        6283       0.78      0.67      0.72        27\n",
      "        6284       0.52      0.41      0.46        27\n",
      "        6285       0.64      0.50      0.56        28\n",
      "        6286       0.61      0.71      0.66        28\n",
      "        6287       0.56      0.56      0.56        27\n",
      "        6288       0.73      0.92      0.81        24\n",
      "        6289       0.47      0.52      0.49        27\n",
      "        6290       0.75      0.78      0.76        27\n",
      "        6291       0.57      0.50      0.53        26\n",
      "        6292       0.64      0.67      0.65        27\n",
      "        6293       0.77      0.89      0.83        27\n",
      "        6294       0.79      0.85      0.81        26\n",
      "        6295       0.68      0.65      0.67        26\n",
      "        6296       0.00      0.00      0.00        28\n",
      "        6297       0.70      0.55      0.62        29\n",
      "        6298       0.82      0.64      0.72        28\n",
      "        6299       0.79      0.68      0.73        28\n",
      "        6303       0.48      0.36      0.41        28\n",
      "        6305       0.72      0.75      0.74        28\n",
      "        6306       0.75      0.69      0.72        26\n",
      "        6307       0.59      0.36      0.44        28\n",
      "        6308       0.55      0.44      0.49        27\n",
      "        6312       0.37      0.41      0.39        27\n",
      "        6313       0.52      0.64      0.57        25\n",
      "        6315       0.93      0.96      0.95        28\n",
      "        6316       1.00      0.86      0.92        21\n",
      "        6317       0.67      0.56      0.61        25\n",
      "        6319       0.70      0.70      0.70        27\n",
      "        6320       0.80      0.59      0.68        27\n",
      "        6321       0.58      0.81      0.68        27\n",
      "        6333       0.56      0.58      0.57        26\n",
      "        6335       0.74      0.87      0.80        23\n",
      "        6336       0.51      0.75      0.61        28\n",
      "        6338       0.36      0.33      0.35        27\n",
      "        6339       0.79      0.68      0.73        28\n",
      "        6343       0.95      0.81      0.88        26\n",
      "        6345       0.62      0.58      0.60        26\n",
      "        6346       0.48      0.59      0.53        27\n",
      "        6348       0.54      0.48      0.51        27\n",
      "        6350       0.68      0.75      0.71        28\n",
      "        6352       0.71      0.63      0.67        27\n",
      "        6353       0.84      0.90      0.87        29\n",
      "        6355       0.38      0.32      0.35        25\n",
      "        6356       0.93      0.90      0.91        29\n",
      "        6357       0.96      0.82      0.88        28\n",
      "        6358       0.70      0.79      0.75        24\n",
      "        6359       0.68      0.68      0.68        28\n",
      "        6360       1.00      0.77      0.87        26\n",
      "        6361       0.54      0.48      0.51        29\n",
      "        6362       0.93      0.96      0.94        26\n",
      "        6365       0.60      0.58      0.59        26\n",
      "        6367       0.65      0.65      0.65        17\n",
      "        6368       0.96      0.85      0.90        26\n",
      "        6370       0.80      0.63      0.71        19\n",
      "        6371       0.67      0.53      0.59        19\n",
      "        6372       0.75      0.67      0.71        27\n",
      "        6373       0.42      0.63      0.51        27\n",
      "        6374       0.56      0.45      0.50        20\n",
      "        6375       0.37      0.54      0.44        26\n",
      "        6377       0.71      0.58      0.64        26\n",
      "        6380       0.73      0.81      0.77        27\n",
      "        6381       0.42      0.54      0.47        26\n",
      "        6382       0.86      0.44      0.59        27\n",
      "        6386       0.60      0.69      0.64        26\n",
      "        6387       0.61      0.77      0.68        26\n",
      "        6388       0.73      0.42      0.54        26\n",
      "        6389       0.42      0.41      0.42        27\n",
      "        6391       0.69      0.64      0.67        28\n",
      "        6392       0.91      0.87      0.89        23\n",
      "        6393       0.84      0.84      0.84        25\n",
      "        6394       0.73      0.79      0.76        28\n",
      "        6396       0.33      0.18      0.23        28\n",
      "        6397       0.60      0.23      0.33        26\n",
      "        6398       0.62      0.56      0.59        27\n",
      "        6399       0.95      0.81      0.88        26\n",
      "        6402       0.72      0.90      0.80        29\n",
      "        6404       0.65      0.60      0.63        25\n",
      "        6407       0.84      0.70      0.76        23\n",
      "        6408       0.61      0.42      0.50        26\n",
      "        6410       0.74      0.56      0.64        25\n",
      "        6411       0.62      0.69      0.65        26\n",
      "        6412       0.67      0.29      0.40        21\n",
      "        6415       0.59      0.52      0.55        25\n",
      "        6416       0.58      0.41      0.48        27\n",
      "        6420       0.84      0.78      0.81        27\n",
      "        6422       0.96      1.00      0.98        26\n",
      "        6423       0.59      0.71      0.65        28\n",
      "        6424       0.84      0.93      0.88        28\n",
      "        6426       0.14      0.08      0.10        25\n",
      "        6427       0.27      0.11      0.15        28\n",
      "        6428       0.61      0.74      0.67        27\n",
      "        6429       0.70      0.73      0.72        26\n",
      "        6430       0.68      0.88      0.77        26\n",
      "        6431       0.66      0.82      0.73        28\n",
      "        6432       0.73      0.79      0.76        28\n",
      "        6434       0.61      0.52      0.56        27\n",
      "        6435       0.89      0.92      0.91        26\n",
      "        6436       0.67      0.59      0.63        27\n",
      "        6437       0.96      0.81      0.88        27\n",
      "        6438       0.60      0.78      0.68        27\n",
      "        6439       0.92      0.82      0.87        28\n",
      "        6440       0.67      0.85      0.75        26\n",
      "        6442       0.90      0.73      0.81        26\n",
      "        6443       0.94      0.64      0.76        25\n",
      "        6444       0.40      0.28      0.33        29\n",
      "        6445       0.55      0.42      0.48        26\n",
      "        6450       0.82      0.62      0.71        29\n",
      "        6451       0.40      0.44      0.42        27\n",
      "        6452       0.53      0.65      0.59        26\n",
      "        6453       0.50      0.67      0.57        27\n",
      "        6454       0.71      0.74      0.73        27\n",
      "        6455       0.62      0.30      0.40        27\n",
      "        6464       0.73      0.89      0.80        27\n",
      "        6466       0.89      0.64      0.74        25\n",
      "        6467       0.89      0.96      0.93        26\n",
      "        6468       0.96      0.89      0.92        27\n",
      "        6469       0.74      0.89      0.81        28\n",
      "        6470       0.65      0.74      0.69        27\n",
      "        6472       0.89      0.62      0.73        26\n",
      "        6473       0.63      0.63      0.63        27\n",
      "        6476       0.82      0.72      0.77        25\n",
      "        6477       0.88      0.75      0.81        28\n",
      "        6493       0.44      0.27      0.33        26\n",
      "        6494       0.60      0.43      0.50        28\n",
      "        6495       0.48      0.52      0.50        27\n",
      "        6497       0.76      0.70      0.73        27\n",
      "        6498       0.71      0.89      0.79        28\n",
      "        6499       0.90      0.93      0.91        28\n",
      "        6500       0.43      0.69      0.53        29\n",
      "        6502       0.24      0.38      0.30        26\n",
      "        6503       0.65      0.46      0.54        28\n",
      "        6504       0.57      0.74      0.65        27\n",
      "        6505       0.40      0.37      0.38        27\n",
      "        6506       0.40      0.50      0.44        28\n",
      "        6509       0.76      0.93      0.83        27\n",
      "        6512       0.77      0.65      0.71        26\n",
      "        6531       0.88      0.85      0.86        26\n",
      "        6534       0.84      0.93      0.88        28\n",
      "        6536       0.90      0.68      0.78        28\n",
      "        6540       0.68      0.89      0.77        28\n",
      "        6548       0.73      0.67      0.70        24\n",
      "        6550       0.52      0.63      0.57        27\n",
      "        6551       0.59      0.63      0.61        27\n",
      "        6553       0.56      0.50      0.53        28\n",
      "        6567       0.72      0.78      0.75        27\n",
      "        6576       0.37      0.24      0.29        29\n",
      "        6577       0.67      0.71      0.69        28\n",
      "        6578       0.88      0.82      0.85        28\n",
      "        6579       0.88      1.00      0.93        28\n",
      "        6581       0.90      0.96      0.93        28\n",
      "        6582       0.71      0.61      0.65        28\n",
      "        6584       0.96      1.00      0.98        27\n",
      "        6585       0.33      0.23      0.27        26\n",
      "        6586       0.43      0.40      0.42        25\n",
      "        6589       0.72      0.78      0.75        27\n",
      "        6590       0.94      0.68      0.79        22\n",
      "        6591       0.70      0.59      0.64        27\n",
      "        6592       0.28      0.48      0.35        29\n",
      "        6593       0.50      0.56      0.53        25\n",
      "        6594       0.61      0.39      0.48        28\n",
      "        6595       0.83      0.42      0.56        24\n",
      "        6597       0.94      0.77      0.85        22\n",
      "        6598       0.37      0.26      0.30        27\n",
      "        6599       0.53      0.61      0.57        28\n",
      "        6600       1.00      0.73      0.84        26\n",
      "        6602       0.93      0.90      0.91        29\n",
      "        6604       0.49      0.63      0.55        27\n",
      "        6605       0.92      0.92      0.92        26\n",
      "        6607       0.80      0.71      0.75        28\n",
      "        6611       0.76      0.66      0.70        29\n",
      "        6617       0.67      0.71      0.69        28\n",
      "        6618       0.80      0.71      0.75        28\n",
      "        6619       0.74      0.63      0.68        27\n",
      "        6622       0.77      0.82      0.79        28\n",
      "        6623       0.82      0.96      0.89        28\n",
      "        6625       0.58      0.42      0.49        26\n",
      "        6627       0.63      0.48      0.55        25\n",
      "        6632       0.66      0.78      0.71        27\n",
      "        6636       0.75      0.78      0.76        27\n",
      "        6645       0.92      0.63      0.75        19\n",
      "        6647       0.25      0.27      0.26        26\n",
      "        6648       0.44      0.61      0.51        28\n",
      "        6649       0.35      0.32      0.33        28\n",
      "        6650       0.68      0.54      0.60        28\n",
      "        6651       0.65      0.39      0.49        28\n",
      "        6653       0.96      0.89      0.92        27\n",
      "        6654       0.85      0.82      0.84        28\n",
      "        6655       0.64      0.57      0.60        28\n",
      "        6657       0.69      0.60      0.64        15\n",
      "        6658       0.70      1.00      0.83        19\n",
      "        6659       0.72      0.81      0.76        26\n",
      "        6660       0.65      0.85      0.73        26\n",
      "        6664       0.72      0.48      0.58        27\n",
      "        6665       0.65      0.89      0.75        27\n",
      "        6666       1.00      0.86      0.92        28\n",
      "        6667       0.50      0.48      0.49        27\n",
      "        6668       0.62      0.57      0.59        28\n",
      "        6671       0.53      0.37      0.43        27\n",
      "        6673       0.58      0.78      0.67        27\n",
      "        6674       0.48      0.50      0.49        28\n",
      "        6675       0.69      0.64      0.67        28\n",
      "        6676       0.76      0.70      0.73        27\n",
      "        6677       0.73      0.44      0.55        18\n",
      "        6681       0.89      0.92      0.91        26\n",
      "        6684       0.74      0.74      0.74        27\n",
      "        6685       0.78      0.90      0.84        20\n",
      "        6687       0.39      0.52      0.44        23\n",
      "        6688       0.53      0.64      0.58        28\n",
      "        6690       0.79      0.73      0.76        26\n",
      "        6691       0.57      0.73      0.64        22\n",
      "        6696       0.91      0.78      0.84        27\n",
      "        6704       0.73      0.69      0.71        16\n",
      "        6710       0.67      0.43      0.52        14\n",
      "        6711       0.88      0.41      0.56        17\n",
      "        6712       0.80      0.74      0.77        27\n",
      "        6714       0.50      0.50      0.50        26\n",
      "        6715       0.69      0.71      0.70        28\n",
      "        6716       0.86      0.86      0.86        28\n",
      "        6718       0.80      0.29      0.42        14\n",
      "        6720       0.86      0.89      0.88        28\n",
      "        6723       0.81      0.84      0.82        25\n",
      "        6729       0.52      0.58      0.55        19\n",
      "        6730       0.33      0.26      0.29        23\n",
      "        6751       0.75      0.56      0.64        27\n",
      "        6752       0.70      0.73      0.72        26\n",
      "        6756       0.55      0.22      0.32        27\n",
      "        6758       0.96      0.86      0.91        28\n",
      "        6760       0.61      0.93      0.74        29\n",
      "        6763       0.94      0.63      0.76        27\n",
      "        6764       0.67      0.79      0.72        28\n",
      "        6765       0.68      0.61      0.64        28\n",
      "        6766       0.73      0.73      0.73        26\n",
      "        6767       0.61      0.52      0.56        27\n",
      "        6769       0.50      0.46      0.48        26\n",
      "        6772       0.32      0.68      0.44        28\n",
      "        6782       1.00      0.48      0.65        21\n",
      "        6786       0.62      0.48      0.54        21\n",
      "        6788       0.92      0.73      0.81        15\n",
      "        6789       0.70      0.68      0.69        28\n",
      "        6792       0.81      0.78      0.79        27\n",
      "        6793       0.39      0.27      0.32        26\n",
      "        6794       0.93      0.96      0.94        26\n",
      "        6796       0.83      0.38      0.53        13\n",
      "        6797       0.95      0.77      0.85        26\n",
      "        6798       0.71      0.58      0.64        26\n",
      "        6799       0.71      0.79      0.75        28\n",
      "        6800       0.69      0.71      0.70        28\n",
      "        6801       0.88      0.56      0.68        27\n",
      "        6802       0.88      0.78      0.82        27\n",
      "        6803       0.68      0.73      0.70        26\n",
      "        6804       0.61      0.71      0.66        28\n",
      "        6807       0.92      0.85      0.88        27\n",
      "        6808       0.79      0.79      0.79        28\n",
      "        6809       0.62      0.89      0.73        27\n",
      "        6810       0.58      0.54      0.56        28\n",
      "        6813       0.94      0.67      0.78        24\n",
      "        6814       0.50      0.44      0.47        25\n",
      "        6819       0.67      0.71      0.69        28\n",
      "        6820       0.94      0.94      0.94        16\n",
      "        6823       0.51      0.85      0.64        27\n",
      "        6835       0.89      0.93      0.91        27\n",
      "        6836       0.53      0.69      0.60        29\n",
      "        6837       0.47      0.74      0.57        27\n",
      "        6838       0.76      0.48      0.59        27\n",
      "        6839       0.54      0.52      0.53        29\n",
      "        6840       0.73      0.70      0.72        27\n",
      "        6841       0.55      0.82      0.66        28\n",
      "        6842       0.91      0.77      0.83        26\n",
      "        6843       0.75      0.44      0.56        27\n",
      "        6844       0.29      0.42      0.34        26\n",
      "        6847       0.90      0.93      0.91        28\n",
      "        6851       0.91      0.75      0.82        28\n",
      "        6852       0.39      0.54      0.45        26\n",
      "        6853       0.74      0.74      0.74        27\n",
      "        6854       0.62      0.59      0.60        27\n",
      "        6855       0.56      0.70      0.62        27\n",
      "        6856       0.73      0.81      0.77        27\n",
      "        6858       0.59      0.81      0.69        27\n",
      "        6859       0.63      0.43      0.51        28\n",
      "        6861       0.45      0.58      0.51        26\n",
      "        6862       0.42      0.41      0.42        27\n",
      "        6863       0.71      0.76      0.73        29\n",
      "        6864       0.65      0.77      0.71        22\n",
      "        6865       0.42      0.33      0.37        15\n",
      "        6868       0.62      0.77      0.69        26\n",
      "        6871       0.50      0.54      0.52        28\n",
      "        6874       0.80      0.74      0.77        27\n",
      "        6876       0.68      0.73      0.70        26\n",
      "        6878       0.57      0.74      0.65        27\n",
      "        6882       0.75      0.54      0.63        28\n",
      "        6883       0.89      0.83      0.86        29\n",
      "        6888       0.41      0.68      0.51        28\n",
      "        6889       0.88      0.92      0.90        25\n",
      "        6890       0.76      0.81      0.79        27\n",
      "        6891       0.38      0.43      0.40        28\n",
      "        6894       0.65      0.81      0.72        27\n",
      "        6899       0.90      0.90      0.90        29\n",
      "        6903       0.47      0.54      0.50        28\n",
      "        6905       0.96      0.92      0.94        26\n",
      "        6906       0.56      0.64      0.60        14\n",
      "        6907       0.71      0.81      0.76        27\n",
      "        6911       0.92      0.63      0.75        19\n",
      "        6915       0.73      0.73      0.73        26\n",
      "        6917       0.79      0.85      0.82        27\n",
      "        6918       0.85      0.92      0.88        25\n",
      "        6920       0.45      0.32      0.38        28\n",
      "        6921       0.74      0.85      0.79        27\n",
      "        6923       0.96      1.00      0.98        26\n",
      "        6925       0.95      0.95      0.95        19\n",
      "        6931       0.77      0.74      0.75        27\n",
      "        6932       0.81      0.78      0.79        27\n",
      "        6936       0.67      0.62      0.65        16\n",
      "        6940       0.89      0.53      0.67        15\n",
      "        6943       0.83      0.73      0.78        26\n",
      "        6954       1.00      1.00      1.00        13\n",
      "        6958       0.80      0.89      0.84        27\n",
      "        6961       1.00      0.93      0.96        27\n",
      "        6963       0.60      0.71      0.65        21\n",
      "        6970       0.64      0.43      0.51        21\n",
      "        6971       0.85      0.88      0.86        25\n",
      "        6974       0.71      0.80      0.75        25\n",
      "        6976       0.79      0.85      0.82        27\n",
      "        6982       0.95      0.74      0.83        27\n",
      "        6987       0.90      1.00      0.95        27\n",
      "        6988       0.88      0.61      0.72        23\n",
      "        6989       0.57      0.85      0.69        27\n",
      "        6990       1.00      0.63      0.77        19\n",
      "        6994       1.00      1.00      1.00        14\n",
      "        7020       0.71      0.81      0.76        27\n",
      "        7021       0.94      0.83      0.88        18\n",
      "        7022       1.00      0.74      0.85        27\n",
      "        7023       0.91      0.59      0.71        17\n",
      "        7024       0.68      0.96      0.80        27\n",
      "        7026       0.85      0.94      0.89        18\n",
      "        7027       0.74      0.65      0.69        26\n",
      "        7029       0.53      0.69      0.60        26\n",
      "        7030       0.89      0.92      0.91        26\n",
      "        7032       1.00      0.96      0.98        26\n",
      "        7033       0.56      0.32      0.41        28\n",
      "        7034       0.71      0.37      0.49        27\n",
      "        7035       0.76      0.85      0.80        26\n",
      "        7037       0.81      0.96      0.88        27\n",
      "        7038       0.54      0.75      0.63        28\n",
      "        7041       0.61      0.73      0.67        26\n",
      "        7042       0.76      0.62      0.68        26\n",
      "        7043       1.00      0.88      0.94        26\n",
      "        7045       0.41      0.54      0.47        26\n",
      "        7046       0.59      0.81      0.69        27\n",
      "        7047       0.71      0.71      0.71        21\n",
      "        7050       0.74      0.85      0.79        27\n",
      "        7051       0.72      0.85      0.78        27\n",
      "        7059       0.73      0.73      0.73        26\n",
      "        7061       0.64      0.62      0.63        26\n",
      "        7066       0.82      0.92      0.87        25\n",
      "        7067       0.76      0.85      0.80        26\n",
      "        7069       0.83      0.89      0.86        27\n",
      "        9117       0.55      0.82      0.65        22\n",
      "        9119       0.58      0.44      0.50        25\n",
      "        9121       0.50      0.52      0.51        25\n",
      "        9122       0.38      0.41      0.39        29\n",
      "        9123       0.43      0.56      0.48        27\n",
      "        9124       0.83      0.42      0.56        24\n",
      "        9127       0.81      0.52      0.63        25\n",
      "        9129       0.86      0.80      0.83        15\n",
      "        9132       0.95      0.75      0.84        28\n",
      "        9182       0.95      0.95      0.95        19\n",
      "        9183       0.72      0.88      0.79        26\n",
      "        9185       1.00      0.77      0.87        26\n",
      "        9186       0.82      0.69      0.75        13\n",
      "        9187       0.82      0.93      0.87        29\n",
      "        9188       0.75      0.75      0.75        24\n",
      "        9190       0.51      0.79      0.62        28\n",
      "        9199       1.00      0.81      0.90        16\n",
      "        9202       0.67      0.57      0.62        28\n",
      "        9203       0.61      0.50      0.55        28\n",
      "        9204       0.81      0.85      0.83        26\n",
      "        9205       0.48      0.46      0.47        28\n",
      "        9322       0.75      0.60      0.67        25\n",
      "        9323       0.60      0.89      0.72        27\n",
      "        9326       0.65      0.76      0.70        29\n",
      "        9327       0.73      0.68      0.70        28\n",
      "        9329       0.67      0.62      0.64        26\n",
      "        9331       0.84      0.73      0.78        22\n",
      "        9337       0.71      0.92      0.80        26\n",
      "        9338       0.70      0.70      0.70        27\n",
      "        9339       0.79      0.83      0.81        18\n",
      "       10784       0.58      0.56      0.57        27\n",
      "       10785       0.35      0.64      0.45        28\n",
      "       10797       0.89      0.86      0.87        28\n",
      "       10799       0.38      0.42      0.40        26\n",
      "       10801       0.64      0.88      0.74        16\n",
      "       10802       0.63      0.81      0.71        27\n",
      "       10803       1.00      0.86      0.92        28\n",
      "       10806       0.83      0.80      0.82        25\n",
      "       10809       0.65      0.89      0.75        27\n",
      "       10811       0.64      0.48      0.55        29\n",
      "       10812       0.83      0.73      0.78        26\n",
      "       10813       1.00      0.68      0.81        19\n",
      "       10814       0.88      0.94      0.91        16\n",
      "       10840       0.35      0.23      0.28        26\n",
      "       10841       0.35      0.41      0.38        27\n",
      "       10842       0.62      0.82      0.71        28\n",
      "       10847       0.79      0.68      0.73        28\n",
      "       11110       0.44      0.27      0.33        26\n",
      "       11112       0.26      0.39      0.31        28\n",
      "       11114       0.75      0.64      0.69        28\n",
      "       11115       0.18      0.14      0.16        28\n",
      "       11116       0.43      0.70      0.53        23\n",
      "       11118       0.56      0.67      0.61        27\n",
      "       11119       0.50      0.29      0.36        28\n",
      "       11120       0.52      0.59      0.55        27\n",
      "       11121       0.65      0.81      0.72        27\n",
      "       11122       0.69      0.89      0.77        27\n",
      "       11123       0.59      0.62      0.61        16\n",
      "       11124       0.42      0.62      0.50        29\n",
      "       11131       0.43      0.54      0.48        28\n",
      "       11132       0.67      0.77      0.71        26\n",
      "       11133       0.55      0.46      0.50        26\n",
      "       11134       0.69      0.71      0.70        28\n",
      "       11136       0.32      0.37      0.34        27\n",
      "       11137       0.22      0.26      0.24        27\n",
      "       11138       0.64      0.39      0.49        23\n",
      "       11140       0.33      0.19      0.24        27\n",
      "       11142       0.31      0.53      0.39        15\n",
      "       11143       0.44      0.78      0.56        27\n",
      "       11144       0.43      0.37      0.40        27\n",
      "       11145       0.48      0.48      0.48        27\n",
      "       11146       0.53      0.28      0.36        29\n",
      "       11147       0.34      0.50      0.41        26\n",
      "       11150       0.44      0.52      0.47        27\n",
      "       11151       0.42      0.54      0.47        28\n",
      "       11152       0.52      0.44      0.48        27\n",
      "       11155       0.77      0.43      0.56        23\n",
      "       11161       0.68      0.66      0.67        29\n",
      "       11162       0.75      0.56      0.64        27\n",
      "       11163       0.46      0.42      0.44        26\n",
      "       11164       0.62      0.37      0.47        27\n",
      "       11165       0.15      0.25      0.19        28\n",
      "       11166       0.59      0.36      0.44        28\n",
      "       11169       0.44      0.50      0.47        16\n",
      "       11170       0.46      0.43      0.44        28\n",
      "       11171       0.40      0.30      0.34        27\n",
      "       11173       0.80      0.43      0.56        28\n",
      "       11175       0.47      0.42      0.44        19\n",
      "       11176       0.80      0.60      0.69        20\n",
      "       11178       0.82      0.61      0.70        23\n",
      "       11179       0.71      0.63      0.67        27\n",
      "       11181       0.67      0.70      0.68        20\n",
      "       11182       0.67      0.33      0.44        18\n",
      "       11184       0.59      0.46      0.52        28\n",
      "       11190       0.52      0.57      0.55        21\n",
      "       11195       0.82      0.67      0.73        27\n",
      "       11196       0.89      0.59      0.71        27\n",
      "       11198       0.92      0.82      0.87        28\n",
      "       11199       0.80      0.59      0.68        27\n",
      "       11200       0.62      0.59      0.60        27\n",
      "       11203       0.92      0.55      0.69        22\n",
      "       11204       0.33      0.38      0.35        29\n",
      "       11205       0.17      0.18      0.17        28\n",
      "       11207       0.42      0.41      0.42        27\n",
      "       11208       0.31      0.31      0.31        26\n",
      "       11211       0.53      0.30      0.38        27\n",
      "       11214       0.38      0.32      0.35        28\n",
      "       11216       0.70      0.30      0.42        23\n",
      "       11217       0.35      0.33      0.34        27\n",
      "       11218       0.72      0.50      0.59        26\n",
      "       11219       0.94      0.65      0.77        23\n",
      "       11220       0.86      0.46      0.60        13\n",
      "       11222       0.61      0.63      0.62        27\n",
      "       11223       0.72      0.67      0.69        27\n",
      "       11224       0.79      0.96      0.87        28\n",
      "       11226       0.77      0.89      0.83        27\n",
      "       11228       0.85      0.63      0.72        27\n",
      "       11239       0.72      0.50      0.59        26\n",
      "       11240       0.72      0.78      0.75        27\n",
      "       11241       0.38      0.63      0.47        27\n",
      "       11242       0.00      0.00      0.00        24\n",
      "       11243       0.83      0.73      0.78        26\n",
      "       11244       0.50      0.65      0.57        26\n",
      "       11245       0.87      0.96      0.92        28\n",
      "       11252       0.61      0.93      0.74        29\n",
      "       11253       0.52      0.57      0.54        28\n",
      "       11254       0.00      0.00      0.00        26\n",
      "       11255       0.25      0.12      0.16        26\n",
      "       11256       0.25      0.04      0.06        28\n",
      "       11257       0.50      0.54      0.52        26\n",
      "       11258       0.56      0.83      0.67        29\n",
      "       11259       0.72      0.85      0.78        27\n",
      "       11260       0.26      0.27      0.26        26\n",
      "       11261       0.70      0.25      0.37        28\n",
      "       11262       0.25      0.18      0.21        28\n",
      "       11263       0.46      0.22      0.30        27\n",
      "       11264       0.53      0.36      0.43        28\n",
      "       11265       0.83      0.43      0.57        23\n",
      "       11266       0.48      0.41      0.44        27\n",
      "       11267       0.65      0.46      0.54        28\n",
      "       11268       0.73      0.41      0.52        27\n",
      "       11269       0.60      0.32      0.42        28\n",
      "       11271       0.63      0.41      0.50        29\n",
      "       11272       0.50      0.25      0.33        28\n",
      "       11273       0.92      0.52      0.67        21\n",
      "       11274       0.59      0.79      0.68        24\n",
      "       11275       0.56      0.68      0.61        28\n",
      "       11276       0.58      0.64      0.61        28\n",
      "       11286       0.43      0.58      0.49        26\n",
      "       11296       0.77      0.68      0.72        25\n",
      "       11297       0.68      0.70      0.69        27\n",
      "       11299       0.42      0.38      0.40        26\n",
      "       11315       0.66      0.82      0.73        28\n",
      "       11316       0.75      0.78      0.76        27\n",
      "       11327       0.68      0.70      0.69        27\n",
      "       11334       0.89      0.68      0.77        25\n",
      "       11335       0.85      0.89      0.87        19\n",
      "       11346       0.85      0.97      0.90        29\n",
      "       11347       0.60      0.81      0.69        26\n",
      "       11348       0.84      0.88      0.86        24\n",
      "       11351       0.86      0.89      0.88        28\n",
      "       11352       0.94      0.54      0.68        28\n",
      "       11353       0.60      0.81      0.69        26\n",
      "       11355       0.35      0.30      0.32        27\n",
      "       11356       0.71      0.74      0.73        27\n",
      "       11358       0.84      0.62      0.71        26\n",
      "       11368       0.28      0.29      0.28        28\n",
      "       11486       0.81      0.72      0.76        29\n",
      "       11488       0.50      0.55      0.52        20\n",
      "       11502       0.36      0.72      0.48        29\n",
      "       11556       0.84      0.96      0.90        27\n",
      "       11647       0.82      0.85      0.84        27\n",
      "       11650       0.96      0.88      0.92        26\n",
      "       11837       0.61      0.74      0.67        27\n",
      "       12069       0.80      0.89      0.84        27\n",
      "       12106       0.55      0.64      0.59        28\n",
      "       12108       0.50      0.36      0.42        28\n",
      "       12109       0.37      0.37      0.37        27\n",
      "       12110       0.56      0.35      0.43        26\n",
      "       12112       0.43      0.85      0.58        27\n",
      "       12139       1.00      0.90      0.95        20\n",
      "       12140       0.81      0.96      0.88        26\n",
      "       12149       0.83      0.70      0.76        27\n",
      "       12151       0.79      0.85      0.81        26\n",
      "       12155       0.44      0.54      0.48        28\n",
      "       12162       0.55      0.59      0.57        27\n",
      "       12165       0.80      0.92      0.86        26\n",
      "       12166       0.63      0.83      0.72        29\n",
      "       12167       0.63      0.46      0.53        26\n",
      "       12168       0.89      0.42      0.57        19\n",
      "       12169       0.78      0.93      0.85        27\n",
      "       12170       0.61      0.74      0.67        27\n",
      "       12171       0.49      0.77      0.60        26\n",
      "       12172       0.57      0.74      0.65        27\n",
      "       12173       0.64      0.78      0.70        27\n",
      "       12175       0.67      0.62      0.64        26\n",
      "       12176       0.64      0.81      0.71        26\n",
      "       12178       0.81      0.81      0.81        26\n",
      "       12179       0.70      0.73      0.72        26\n",
      "       12180       0.60      0.32      0.42        28\n",
      "       12181       0.33      0.29      0.31        28\n",
      "       12182       0.50      0.43      0.46        28\n",
      "       12183       0.77      0.82      0.79        28\n",
      "       12184       0.79      0.96      0.87        28\n",
      "       12185       0.68      0.58      0.62        26\n",
      "       12186       0.27      0.28      0.27        29\n",
      "       12189       0.79      0.58      0.67        26\n",
      "       12190       0.50      0.63      0.56        27\n",
      "       12191       0.72      0.64      0.68        28\n",
      "       12192       0.54      0.48      0.51        27\n",
      "       12193       0.67      0.52      0.58        27\n",
      "       12195       0.87      0.96      0.91        27\n",
      "       12196       1.00      0.62      0.76        26\n",
      "       12197       0.60      0.69      0.64        26\n",
      "       12198       0.84      0.84      0.84        25\n",
      "       12200       0.86      0.93      0.89        27\n",
      "       12201       0.89      0.93      0.91        27\n",
      "       12202       0.65      0.58      0.61        26\n",
      "       12204       0.90      0.96      0.93        28\n",
      "       12205       0.89      0.96      0.93        26\n",
      "       12206       0.68      0.54      0.60        28\n",
      "       12207       0.86      0.69      0.77        26\n",
      "       12208       0.96      1.00      0.98        27\n",
      "       12209       0.75      1.00      0.86        27\n",
      "       12210       0.76      0.70      0.73        27\n",
      "       12212       0.60      0.89      0.72        27\n",
      "       12213       0.38      0.54      0.45        28\n",
      "       12215       0.87      0.87      0.87        23\n",
      "       12216       0.89      0.86      0.87        28\n",
      "       12217       0.86      0.86      0.86        28\n",
      "       12218       0.86      0.92      0.89        26\n",
      "       12219       0.54      0.70      0.61        27\n",
      "       12223       0.88      0.54      0.67        13\n",
      "       12224       0.96      0.92      0.94        26\n",
      "       12225       0.68      0.78      0.72        27\n",
      "       12226       0.93      0.93      0.93        28\n",
      "       12227       0.83      0.58      0.68        26\n",
      "       12228       0.87      0.46      0.60        28\n",
      "       12229       0.85      0.85      0.85        26\n",
      "       12230       0.85      0.85      0.85        27\n",
      "       12232       0.71      0.81      0.76        27\n",
      "       12234       0.82      0.92      0.87        25\n",
      "       12235       0.92      0.89      0.91        27\n",
      "       12237       0.59      0.50      0.54        26\n",
      "       12239       0.84      0.62      0.71        26\n",
      "       12240       0.71      0.81      0.76        27\n",
      "       12241       0.88      0.75      0.81        28\n",
      "       12242       0.96      0.93      0.94        27\n",
      "       12243       0.52      0.45      0.48        29\n",
      "       12245       0.82      0.52      0.64        27\n",
      "       12246       0.70      0.92      0.79        25\n",
      "       12313       0.42      0.65      0.51        20\n",
      "       12316       0.69      0.89      0.77        27\n",
      "       12332       0.52      0.85      0.65        27\n",
      "       12348       0.40      0.23      0.29        26\n",
      "       12349       0.28      0.31      0.29        16\n",
      "       12350       0.75      0.81      0.78        26\n",
      "       12351       0.38      0.30      0.33        27\n",
      "       12352       0.44      0.56      0.49        27\n",
      "       12354       0.51      0.77      0.62        26\n",
      "       12356       0.00      0.00      0.00        13\n",
      "       12357       0.74      0.93      0.83        28\n",
      "       12358       1.00      0.68      0.81        19\n",
      "       12360       1.00      0.80      0.89        15\n",
      "       12362       0.68      0.89      0.77        28\n",
      "       12369       0.44      0.57      0.50        28\n",
      "       12370       0.64      0.81      0.71        26\n",
      "       12371       0.31      0.44      0.36        27\n",
      "       12372       0.50      0.36      0.42        25\n",
      "       12376       0.95      0.78      0.86        27\n",
      "       12380       0.60      0.60      0.60        25\n",
      "       12382       0.62      0.93      0.75        27\n",
      "       12387       0.62      0.96      0.75        27\n",
      "       12390       0.96      0.96      0.96        27\n",
      "       12392       0.95      0.84      0.89        25\n",
      "       12394       0.20      0.82      0.33        28\n",
      "       12396       0.58      0.54      0.56        26\n",
      "       12397       0.69      0.89      0.77        27\n",
      "       12403       0.54      0.67      0.60        21\n",
      "       12405       0.44      0.54      0.48        13\n",
      "       12406       0.57      0.92      0.71        26\n",
      "       12408       0.39      0.56      0.46        16\n",
      "       12410       0.67      0.61      0.64        23\n",
      "       12417       0.63      1.00      0.77        29\n",
      "       12419       0.83      0.70      0.76        27\n",
      "       12420       0.68      0.65      0.67        26\n",
      "       12421       0.72      0.96      0.83        27\n",
      "       12422       1.00      0.92      0.96        26\n",
      "       12423       0.88      0.82      0.85        28\n",
      "       12424       0.90      0.96      0.93        27\n",
      "       12425       0.81      0.90      0.85        29\n",
      "       12426       0.69      0.67      0.68        27\n",
      "       12427       0.83      0.71      0.77        28\n",
      "       12428       0.70      0.75      0.72        28\n",
      "       12430       0.87      0.96      0.92        28\n",
      "       12434       0.78      0.81      0.79        26\n",
      "       12437       0.41      0.83      0.55        29\n",
      "       12438       0.85      1.00      0.92        28\n",
      "       12439       0.76      0.89      0.82        28\n",
      "       12440       0.70      0.85      0.77        27\n",
      "       12441       0.56      0.50      0.53        28\n",
      "       12442       0.74      0.82      0.78        28\n",
      "       12443       0.74      0.74      0.74        27\n",
      "       12444       0.82      0.93      0.87        29\n",
      "       12445       0.96      0.82      0.88        28\n",
      "       12446       0.39      0.62      0.48        26\n",
      "       12448       0.45      0.69      0.55        26\n",
      "       12449       0.67      0.69      0.68        26\n",
      "       12450       0.71      0.61      0.65        28\n",
      "       12455       0.57      0.50      0.53        26\n",
      "       12456       0.73      0.62      0.67        26\n",
      "       12457       0.52      0.58      0.55        24\n",
      "       12458       0.92      0.41      0.56        27\n",
      "       12459       0.90      1.00      0.95        26\n",
      "       12461       0.36      0.46      0.41        26\n",
      "       12462       0.70      0.78      0.74        27\n",
      "       12463       0.85      1.00      0.92        22\n",
      "       12464       0.62      0.82      0.71        28\n",
      "       12465       0.71      0.74      0.73        27\n",
      "       12466       0.96      0.92      0.94        26\n",
      "       12468       0.48      0.48      0.48        29\n",
      "       12469       0.65      0.74      0.69        27\n",
      "       12470       0.47      0.58      0.52        26\n",
      "       12471       0.39      0.54      0.45        26\n",
      "       12472       0.50      0.61      0.55        28\n",
      "       12474       0.80      0.92      0.86        26\n",
      "       12475       0.37      0.62      0.46        26\n",
      "       12476       0.33      0.42      0.37        26\n",
      "       12478       0.51      0.78      0.62        27\n",
      "       12479       0.71      0.93      0.81        29\n",
      "       12480       0.62      0.78      0.69        27\n",
      "       12481       0.67      0.50      0.57        28\n",
      "       12482       0.60      0.92      0.73        26\n",
      "       12483       0.68      0.85      0.75        27\n",
      "       12484       0.70      0.73      0.72        26\n",
      "       12485       0.73      1.00      0.84        27\n",
      "       12486       0.54      0.93      0.68        27\n",
      "       12487       0.54      0.96      0.69        28\n",
      "       12490       0.33      0.15      0.21        27\n",
      "       12491       0.24      0.31      0.27        26\n",
      "       12492       0.71      0.81      0.76        27\n",
      "       12493       0.32      0.41      0.36        27\n",
      "\n",
      "    accuracy                           0.57     68888\n",
      "   macro avg       0.59      0.57      0.57     68888\n",
      "weighted avg       0.59      0.57      0.56     68888\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(val_label, val_pred_bottom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns=['product_id','title', 'description', 'tags','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(parquet_files,columns):\n",
    "\n",
    "\n",
    "    df = [\n",
    "\n",
    "        pd.read_parquet(parquet_files, columns=columns)\n",
    "    ]\n",
    "\n",
    "    return pd.concat(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=read_files(test_dir, test_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "required_columns = ['title', 'description', 'tags','type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['combined_text'] = df_test['title'].fillna('') + ' ' + df_test['description'].fillna('') + ' ' + df_test['tags'].fillna('')\n",
    "df_test_combined = df_test['combined_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_nb=nb_model.predict(df_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25514"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction[\"bottom_category_id\"]=test_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction.to_csv('sharjil_etsy_bottom.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_columns=[\"primary_color_id\",\"secondary_color_id\",\"image/encoded\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_data(train_dir,columns=color_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def preprocess_image(encoded_images):\n",
    "    transform_augment_2= transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomRotation(10),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    \n",
    "    processed_images = []\n",
    "    for encoded_image in encoded_images:\n",
    "        \n",
    "        image = Image.open(io.BytesIO(encoded_image))\n",
    "        \n",
    "        \n",
    "        processed_image = transform_augment_2(image)\n",
    "        processed_images.append(processed_image)\n",
    "\n",
    "    \n",
    "    return torch.stack(processed_images)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images = preprocess_image(df_train['image/encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x22a217f21d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_x_image=next(iter(X_images))\n",
    "plt.imshow(img_x_image.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['primary_color_id'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_train['primary_color_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((229624,), torch.Size([229624, 3, 64, 64]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape,X_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataset = TensorDataset(X_images, y_tensor)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "prim_color_model = models.efficientnet_b0(pretrained=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prim_color_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2, 11, 17, 12, 18, 14,  1, 13,  0,  9, 10, 19,  7,  4,  3,  5, 16,\n",
       "        6, 15], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['primary_color_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = prim_color_model.classifier[1].in_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_color_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(num_features, 19)\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.3, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=19, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prim_color_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = torch.optim.Adam(prim_color_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 1.9520, Train Acc: 0.4058, Val Loss: 1.8687, Val Acc: 0.4291\n",
      "Epoch 1: Train Loss: 1.9064, Train Acc: 0.4216, Val Loss: 1.8941, Val Acc: 0.4229\n",
      "Epoch 2: Train Loss: 1.8519, Train Acc: 0.4354, Val Loss: 1.9012, Val Acc: 0.4204\n",
      "Epoch 3: Train Loss: nan, Train Acc: 0.4459, Val Loss: 1.8539, Val Acc: 0.4367\n",
      "Epoch 4: Train Loss: nan, Train Acc: 0.2333, Val Loss: 3.4733, Val Acc: 0.1229\n",
      "Epoch 5: Train Loss: 2.9107, Train Acc: 0.1131, Val Loss: 2.9263, Val Acc: 0.0879\n",
      "Epoch 6: Train Loss: 2.9173, Train Acc: 0.1094, Val Loss: 2.9360, Val Acc: 0.1229\n",
      "Epoch 7: Train Loss: 2.9429, Train Acc: 0.1250, Val Loss: 2.9444, Val Acc: 0.1229\n",
      "Epoch 8: Train Loss: 2.9453, Train Acc: 0.0543, Val Loss: 2.9444, Val Acc: 0.0538\n",
      "Early stopping triggered.\n",
      "Best Validation Accuracy: 0.4367\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "early_stopping_patience = 5\n",
    "min_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "best_model_wts = copy.deepcopy(prim_color_model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "prim_color_model.train()\n",
    "for epoch in range(50):  # Adjust the number of epochs\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = prim_color_model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_acc += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    avg_train_loss = train_loss / total\n",
    "    avg_train_acc = train_acc / total\n",
    "    \n",
    "    # Validation phase\n",
    "    prim_color_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = prim_color_model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_acc += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "    \n",
    "    avg_val_loss = val_loss / total_val\n",
    "    avg_val_acc = val_acc / total_val\n",
    "    \n",
    "    print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "    \n",
    "    # Dynamic Learning Rate Adjustment\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        best_model_wts = copy.deepcopy(prim_color_model.state_dict())\n",
    "        best_acc = avg_val_acc\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "prim_color_model.load_state_dict(best_model_wts)\n",
    "print(f'Best Validation Accuracy: {best_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model's file path\n",
    "model_save_path = \"primary_color_id.pt\"\n",
    "\n",
    "# Save the model state\n",
    "torch.save(prim_color_model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns_color=['image/encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_color = read_data(test_dir,columns=test_columns_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def preprocess_image_test(encoded_images):\n",
    "    transform_augment_2= transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    \n",
    "    processed_images = []\n",
    "    for encoded_image in encoded_images:\n",
    "        \n",
    "        image = Image.open(io.BytesIO(encoded_image))\n",
    "        \n",
    "        \n",
    "        processed_image = transform_augment_2(image)\n",
    "        processed_images.append(processed_image)\n",
    "\n",
    "    \n",
    "    return torch.stack(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images_test = preprocess_image_test(df_test_color['image/encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_val=DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25514"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_images_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test_=[]\n",
    "predicted_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "aa=random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008137746526793"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_color_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        for inputs_tuple in test_loader_val:\n",
    "            inputs = inputs_tuple[0]\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            outputs = prim_color_model(inputs)\n",
    "            _, predicted_test = torch.max(outputs, 1)\n",
    "            predicted_test_.extend(predicted_test.cpu().numpy().tolist())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10,\n",
       " 16,\n",
       " 2,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 13,\n",
       " 1,\n",
       " 10,\n",
       " 4,\n",
       " 13,\n",
       " 13,\n",
       " 10,\n",
       " 0,\n",
       " 2,\n",
       " 17,\n",
       " 0,\n",
       " 17,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 13,\n",
       " 17,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 12,\n",
       " 2,\n",
       " 13,\n",
       " 11,\n",
       " 17,\n",
       " 12,\n",
       " 8,\n",
       " 8,\n",
       " 10,\n",
       " 0,\n",
       " 10,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 7,\n",
       " 12,\n",
       " 17,\n",
       " 0,\n",
       " 16,\n",
       " 13,\n",
       " 2,\n",
       " 0,\n",
       " 11,\n",
       " 18,\n",
       " 17,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 15,\n",
       " 7,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 17,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 17,\n",
       " 8,\n",
       " 13,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 10,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 8,\n",
       " 4,\n",
       " 11,\n",
       " 16,\n",
       " 13,\n",
       " 12,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 11,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 15,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 0,\n",
       " 7,\n",
       " 13,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 18,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 16,\n",
       " 8,\n",
       " 17,\n",
       " 12,\n",
       " 2,\n",
       " 10,\n",
       " 10,\n",
       " 13,\n",
       " 4,\n",
       " 15,\n",
       " 17,\n",
       " 12,\n",
       " 15,\n",
       " 2,\n",
       " 11,\n",
       " 8,\n",
       " 2,\n",
       " 12,\n",
       " 17,\n",
       " 8,\n",
       " 7,\n",
       " 13,\n",
       " 8,\n",
       " 10,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 13,\n",
       " 13,\n",
       " 4,\n",
       " 16,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 17,\n",
       " 2,\n",
       " 18,\n",
       " 1,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 16,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 17,\n",
       " 10,\n",
       " 4,\n",
       " 16,\n",
       " 0,\n",
       " 0,\n",
       " 4,\n",
       " 16,\n",
       " 12,\n",
       " 5,\n",
       " 2,\n",
       " 10,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 17,\n",
       " 15,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 15,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 10,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 16,\n",
       " 11,\n",
       " 10,\n",
       " 1,\n",
       " 13,\n",
       " 4,\n",
       " 2,\n",
       " 8,\n",
       " 15,\n",
       " 2,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 16,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 13,\n",
       " 13,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 12,\n",
       " 15,\n",
       " 10,\n",
       " 15,\n",
       " 2,\n",
       " 0,\n",
       " 16,\n",
       " 13,\n",
       " 10,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 13,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 7,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 13,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 16,\n",
       " 7,\n",
       " 16,\n",
       " 10,\n",
       " 13,\n",
       " 16,\n",
       " 4,\n",
       " 0,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 10,\n",
       " 10,\n",
       " 13,\n",
       " 17,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 13,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 4,\n",
       " 11,\n",
       " 12,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 12,\n",
       " 16,\n",
       " 1,\n",
       " 10,\n",
       " 2,\n",
       " 16,\n",
       " 13,\n",
       " 1,\n",
       " 13,\n",
       " 16,\n",
       " 1,\n",
       " 8,\n",
       " 11,\n",
       " 18,\n",
       " 1,\n",
       " 16,\n",
       " 12,\n",
       " 0,\n",
       " 11,\n",
       " 15,\n",
       " 11,\n",
       " 11,\n",
       " 7,\n",
       " 7,\n",
       " 16,\n",
       " 7,\n",
       " 4,\n",
       " 10,\n",
       " 1,\n",
       " 8,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 7,\n",
       " 16,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 1,\n",
       " 18,\n",
       " 16,\n",
       " 8,\n",
       " 10,\n",
       " 1,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 13,\n",
       " 16,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 18,\n",
       " 17,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 13,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 4,\n",
       " 18,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 2,\n",
       " 17,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 13,\n",
       " 16,\n",
       " 2,\n",
       " 10,\n",
       " 10,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 17,\n",
       " 13,\n",
       " 8,\n",
       " 0,\n",
       " 13,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 9,\n",
       " 16,\n",
       " 0,\n",
       " 7,\n",
       " 16,\n",
       " 11,\n",
       " 4,\n",
       " 0,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 13,\n",
       " 7,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 16,\n",
       " 7,\n",
       " 7,\n",
       " 16,\n",
       " 9,\n",
       " 16,\n",
       " 2,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 7,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 11,\n",
       " 16,\n",
       " 13,\n",
       " 4,\n",
       " 0,\n",
       " 16,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 2,\n",
       " 10,\n",
       " 12,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 16,\n",
       " 12,\n",
       " 8,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 16,\n",
       " 13,\n",
       " 7,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 10,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 13,\n",
       " 1,\n",
       " 4,\n",
       " 11,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 17,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 10,\n",
       " 16,\n",
       " 0,\n",
       " 1,\n",
       " 16,\n",
       " 2,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 7,\n",
       " 5,\n",
       " 16,\n",
       " 4,\n",
       " 2,\n",
       " 16,\n",
       " 11,\n",
       " 8,\n",
       " 8,\n",
       " 13,\n",
       " 13,\n",
       " 16,\n",
       " 0,\n",
       " 8,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 16,\n",
       " 15,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 17,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 0,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 2,\n",
       " 13,\n",
       " 13,\n",
       " 16,\n",
       " 8,\n",
       " 4,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 11,\n",
       " 2,\n",
       " 16,\n",
       " 13,\n",
       " 8,\n",
       " 12,\n",
       " 13,\n",
       " 5,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 15,\n",
       " 17,\n",
       " 0,\n",
       " 16,\n",
       " 16,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 16,\n",
       " 4,\n",
       " 13,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 11,\n",
       " 11,\n",
       " 8,\n",
       " 10,\n",
       " 10,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 11,\n",
       " 2,\n",
       " 16,\n",
       " 1,\n",
       " 10,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 17,\n",
       " 13,\n",
       " 17,\n",
       " 16,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 16,\n",
       " 0,\n",
       " 2,\n",
       " 17,\n",
       " 16,\n",
       " 10,\n",
       " 11,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 13,\n",
       " 18,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 17,\n",
       " 17,\n",
       " 9,\n",
       " 16,\n",
       " 16,\n",
       " 15,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 10,\n",
       " 10,\n",
       " 0,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 15,\n",
       " 4,\n",
       " 1,\n",
       " 16,\n",
       " 4,\n",
       " 4,\n",
       " 16,\n",
       " 0,\n",
       " 10,\n",
       " 9,\n",
       " 16,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 16,\n",
       " 16,\n",
       " 0,\n",
       " 16,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 16,\n",
       " 8,\n",
       " 11,\n",
       " 4,\n",
       " 10,\n",
       " 16,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 16,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 15,\n",
       " 11,\n",
       " 4,\n",
       " 2,\n",
       " 16,\n",
       " 1,\n",
       " 0,\n",
       " 16,\n",
       " 2,\n",
       " 16,\n",
       " 2,\n",
       " 11,\n",
       " 16,\n",
       " 2,\n",
       " 12,\n",
       " 2,\n",
       " 4,\n",
       " 16,\n",
       " 10,\n",
       " 16,\n",
       " 2,\n",
       " 2,\n",
       " 16,\n",
       " 16,\n",
       " 11,\n",
       " 10,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 8,\n",
       " 13,\n",
       " 2,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 1,\n",
       " 16,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 16,\n",
       " 4,\n",
       " 0,\n",
       " 17,\n",
       " 9,\n",
       " 2,\n",
       " 8,\n",
       " 10,\n",
       " 12,\n",
       " 10,\n",
       " 17,\n",
       " 16,\n",
       " 16,\n",
       " 13,\n",
       " 1,\n",
       " 11,\n",
       " 7,\n",
       " 15,\n",
       " 7,\n",
       " 1,\n",
       " 7,\n",
       " 16,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 10,\n",
       " 10,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " ...]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25514"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predicted_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_primary_color=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_primary_color['primary_color_id'] = predicted_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_primary_color.to_csv('sharjil_etsy_primary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_columns=[\"secondary_color_id\",\"image/encoded\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_data(train_dir,columns=color_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  1, 13,  9, 17,  7, 10, 11, 16, 19, 12, 18, 15,  0, 14,  4,  5,\n",
       "        3,  6], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['secondary_color_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def preprocess_image(encoded_images):\n",
    "    transform_augment_2= transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(),  \n",
    "    transforms.RandomRotation(10),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    \n",
    "    processed_images = []\n",
    "    for encoded_image in encoded_images:\n",
    "        \n",
    "        image = Image.open(io.BytesIO(encoded_image))\n",
    "        \n",
    "        \n",
    "        processed_image = transform_augment_2(image)\n",
    "        processed_images.append(processed_image)\n",
    "\n",
    "    \n",
    "    return torch.stack(processed_images)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images = preprocess_image(df_train['image/encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df_train['secondary_color_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tensor=torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "dataset = TensorDataset(X_images, y_tensor)\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [int(0.8 * len(dataset)), len(dataset) - int(0.8 * len(dataset))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader=DataLoader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "sec_color_model = models.efficientnet_b0(pretrained=True).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = sec_color_model.classifier[1].in_features\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_color_model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(num_features, 19)\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sharjil Dhanani\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = torch.optim.Adam(sec_color_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5, min_lr=1e-6, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Train Loss: 2.4334, Train Acc: 0.2183, Val Loss: 2.3496, Val Acc: 0.2401\n",
      "Epoch 1: Train Loss: 2.3678, Train Acc: 0.2356, Val Loss: 2.3195, Val Acc: 0.2470\n",
      "Epoch 2: Train Loss: 2.3142, Train Acc: 0.2510, Val Loss: 2.3099, Val Acc: 0.2543\n",
      "Epoch 3: Train Loss: 2.2840, Train Acc: 0.2607, Val Loss: 2.3097, Val Acc: 0.2495\n",
      "Epoch 4: Train Loss: 2.2631, Train Acc: 0.2674, Val Loss: 2.2857, Val Acc: 0.2562\n",
      "Epoch 5: Train Loss: 2.2442, Train Acc: 0.2739, Val Loss: 2.2850, Val Acc: 0.2643\n",
      "Epoch 6: Train Loss: 2.2281, Train Acc: 0.2785, Val Loss: 2.2852, Val Acc: 0.2621\n",
      "Epoch 7: Train Loss: 2.2124, Train Acc: 0.2837, Val Loss: 2.3153, Val Acc: 0.2558\n",
      "Epoch 8: Train Loss: 2.1976, Train Acc: 0.2871, Val Loss: 2.2692, Val Acc: 0.2620\n",
      "Epoch 9: Train Loss: 2.1836, Train Acc: 0.2924, Val Loss: 2.2821, Val Acc: 0.2640\n",
      "Epoch 10: Train Loss: 2.1697, Train Acc: 0.2963, Val Loss: 2.2689, Val Acc: 0.2682\n",
      "Epoch 11: Train Loss: 2.1546, Train Acc: 0.3006, Val Loss: 2.2830, Val Acc: 0.2661\n",
      "Epoch 12: Train Loss: 2.1421, Train Acc: 0.3039, Val Loss: 2.2937, Val Acc: 0.2615\n",
      "Epoch 13: Train Loss: 2.1302, Train Acc: 0.3086, Val Loss: 2.2828, Val Acc: 0.2660\n",
      "Epoch 14: Train Loss: 2.0386, Train Acc: 0.3362, Val Loss: 2.3070, Val Acc: 0.2660\n",
      "Epoch 15: Train Loss: 1.9997, Train Acc: 0.3485, Val Loss: 2.3283, Val Acc: 0.2652\n",
      "Early stopping triggered.\n",
      "Best Validation Accuracy: 0.2682\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "early_stopping_patience = 5\n",
    "min_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "best_model_wts = copy.deepcopy(sec_color_model.state_dict())\n",
    "best_acc = 0.0\n",
    "\n",
    "prim_color_model.train()\n",
    "for epoch in range(50):  # Adjust the number of epochs\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0\n",
    "    total = 0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = sec_color_model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        train_acc += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "    avg_train_loss = train_loss / total\n",
    "    avg_train_acc = train_acc / total\n",
    "    \n",
    "    # Validation phase\n",
    "    sec_color_model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = sec_color_model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_acc += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "    \n",
    "    avg_val_loss = val_loss / total_val\n",
    "    avg_val_acc = val_acc / total_val\n",
    "    \n",
    "    print(f'Epoch {epoch}: Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.4f}')\n",
    "    \n",
    "    # Dynamic Learning Rate Adjustment\n",
    "    scheduler.step(avg_val_loss)\n",
    "    \n",
    "    # Early Stopping Check\n",
    "    if avg_val_loss < min_val_loss:\n",
    "        min_val_loss = avg_val_loss\n",
    "        best_model_wts = copy.deepcopy(sec_color_model.state_dict())\n",
    "        best_acc = avg_val_acc\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        \n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "sec_color_model.load_state_dict(best_model_wts)\n",
    "print(f'Best Validation Accuracy: {best_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model's file path\n",
    "model_save_path = \"secondary_color_id.pt\"\n",
    "\n",
    "# Save the model state\n",
    "torch.save(sec_color_model.state_dict(), model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns_color=['image/encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_color = read_data(test_dir,columns=test_columns_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "def preprocess_image_test(encoded_images):\n",
    "    transform_augment_2= transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    \n",
    "    processed_images = []\n",
    "    for encoded_image in encoded_images:\n",
    "        \n",
    "        image = Image.open(io.BytesIO(encoded_image))\n",
    "        \n",
    "        \n",
    "        processed_image = transform_augment_2(image)\n",
    "        processed_images.append(processed_image)\n",
    "\n",
    "    \n",
    "    return torch.stack(processed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_images_test = preprocess_image_test(df_test_color['image/encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TensorDataset(X_images_test)\n",
    "test_loader_val=DataLoader(dataset)\n",
    "predicted_test_=[]\n",
    "predicted_test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_color_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "        for inputs_tuple in test_loader_val:\n",
    "            inputs = inputs_tuple[0]\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            \n",
    "            outputs = sec_color_model(inputs)\n",
    "            _, predicted_test = torch.max(outputs, 1)\n",
    "            predicted_test_.extend(predicted_test.cpu().numpy().tolist())\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prediction_sec_color=pd.DataFrame()\n",
    "df_prediction_sec_color['secondary_color_id'] = predicted_test_\n",
    "df_prediction_sec_color.to_csv('sharjil_etsy_sec.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
